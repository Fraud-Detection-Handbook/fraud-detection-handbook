
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3. Model selection &#8212; Machine Learning for Credit Card Fraud detection - Practical handbook</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/book.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/jtag_0.js"></script>
    <script src="../_static/jtag_1.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="canonical" href="https://fraud-detection-handbook.github.io/fraud-detection-handbook/Chapter_5_ModelValidationAndSelection/ModelSelection.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="4. Summary" href="Summary.html" />
    <link rel="prev" title="2. Validation strategies" href="ValidationStrategies.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://fraud-detection-handbook.github.io/fraud-detection-handbook/Chapter_5_ModelValidationAndSelection/ModelSelection.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Model selection" />
<meta property="og:description" content="Model selection  Model selection consists in selecting the prediction model that is expected to provide the best performances on future data. The standard metho" />
<meta property="og:image"       content="https://fraud-detection-handbook.github.io/fraud-detection-handbook/_static/logo.png" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Machine Learning for Credit Card Fraud detection - Practical handbook</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Foreword.html">
   Foreword
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  1. Book overview
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_1_BookContent/BookContent.html">
   1. Book content and intended audience
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_1_BookContent/BookContributions.html">
   2. Book contributions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_1_BookContent/HowToUse.html">
   3. How to use this book
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  2. Background
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_2_Background/Introduction.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_2_Background/CreditCardFraud.html">
   2. Credit card fraud scenarios
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_2_Background/FDS.html">
   3. Credit card fraud detection system
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_2_Background/MachineLearningForFraudDetection.html">
   4. Machine learning for credit card fraud detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_2_Background/Summary.html">
   5. Summary
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  3. Getting started
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_3_GettingStarted/Introduction.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_3_GettingStarted/SimulatedDataset.html">
   2. Transaction data simulator
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_3_GettingStarted/BaselineFeatureTransformation.html">
   3. Baseline feature transformation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_3_GettingStarted/BaselineModeling.html">
   4. Baseline fraud detection system
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_3_GettingStarted/Baseline_RealWorldData.html">
   5. Real-world data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_3_GettingStarted/Summary.html">
   6. Summary
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  4. Performance metrics
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_4_PerformanceMetrics/Introduction.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_4_PerformanceMetrics/ThresholdBased.html">
   2. Threshold-based metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_4_PerformanceMetrics/ThresholdFree.html">
   3. Threshold-free metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_4_PerformanceMetrics/TopKBased.html">
   4. Precision top-k metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_4_PerformanceMetrics/Assessment_RealWorldData.html">
   5. Real-world data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_4_PerformanceMetrics/Summary.html">
   6. Summary
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  5. Model validation and model selection
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ValidationStrategies.html">
   2. Validation strategies
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   3. Model selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Summary.html">
   4. Summary
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_References/shared_functions.html">
   1. Shared functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_References/bibliography.html">
   2. Bibliography
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Chapter_5_ModelValidationAndSelection/ModelSelection.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook/issues/new?title=Issue%20on%20page%20%2FChapter_5_ModelValidationAndSelection/ModelSelection.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook/edit/main/Chapter_5_ModelValidationAndSelection/ModelSelection.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/Fraud-Detection-Handbook/fraud-detection-handbook/main?urlpath=tree/Chapter_5_ModelValidationAndSelection/ModelSelection.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/Fraud-Detection-Handbook/fraud-detection-handbook/blob/main/Chapter_5_ModelValidationAndSelection/ModelSelection.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-selection-decision-trees">
   3.1. Model selection: Decision trees
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-selection-exploration-of-other-model-classes">
   3.2. Model selection: Exploration of other model classes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-regression">
     3.2.1. Logistic regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random-forest">
     3.2.2. Random forest
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#xgboost">
     3.2.3. XGBoost
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#comparison-of-model-performances">
   3.3. Comparison of model performances
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#random-search">
   3.4. Random search
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="model-selection">
<span id="id1"></span><h1><span class="section-number">3. </span>Model selection<a class="headerlink" href="#model-selection" title="Permalink to this headline">¶</a></h1>
<p>Model selection consists in selecting the prediction model that is expected to provide the best performances on future data. The standard methodology consists of four main steps <span id="id2">[<a class="reference internal" href="../Chapter_References/bibliography.html#id21"><span>Bon21</span></a>,<a class="reference internal" href="../Chapter_References/bibliography.html#id20"><span>Bis06</span></a>,<a class="reference internal" href="../Chapter_References/bibliography.html#id19"><span>FHT01</span></a>]</span>:</p>
<ol class="simple">
<li><p>Define a collection of candidate models to be tested. Let <span class="math notranslate nohighlight">\(M\)</span> be the number of models, and <span class="math notranslate nohighlight">\(h_k\)</span>, <span class="math notranslate nohighlight">\(1 \le k \le M\)</span>, be the <span class="math notranslate nohighlight">\(k-\)</span>th model in the collection, parameterized by a set of parameters <span class="math notranslate nohighlight">\(\theta_k\)</span> (also see section <a class="reference internal" href="../Chapter_2_Background/MachineLearningForFraudDetection.html#ml-for-ccfd-baseline-methodology"><span class="std std-ref">Baseline methodology - Supervised learning</span></a>). Given a class of models (such as decision trees, logistic regression, …), a common practice is to define a collection of models of increasing complexity (tree depth for decision trees, regularisation coefficients for logistic regression, …).</p></li>
<li><p>Train each candidate model using the training data. The training of model <span class="math notranslate nohighlight">\(h_k\)</span> identifies the parameters <span class="math notranslate nohighlight">\(\theta_k\)</span> that maximizes the performances of <span class="math notranslate nohighlight">\(h_k\)</span> on the training set.</p></li>
<li><p>Assess the performances of each candidate model by means of a validation procedure (see section <a class="reference internal" href="ValidationStrategies.html#validation-strategies"><span class="std std-ref">Validation Strategies</span></a>). The validation procedure provides an estimate of the generalization performance. Let us denote by <span class="math notranslate nohighlight">\(A_{valid}(h_k(.,\theta_k))\)</span> the validation performance for the <span class="math notranslate nohighlight">\(k\)</span>-th model.</p></li>
<li><p>Select the model that has the highest validation performance. Denoting by <span class="math notranslate nohighlight">\(k^*\)</span> the index of this optimal model, we have:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
k^*= \mathrm{arg\ max}_{k \in \{1,2,...,M\}} A_{valid(h_k(.,\theta_k))}
\]</div>
<p>An illustration of the model selection procedure with its different steps is provided in Fig. 1.</p>
<p><img alt="alt text" src="../_images/model_selection.png" /></p>
<div align="center">Fig. 1. Model selection procedure: A set of models of increasing complexity are trained, and their performances are assessed using a validation procedure. The model that provides the best validation performance is selected.</div>
<p>The rationale for assessing models of increasing complexity is that there is usually a trade-off between the model complexity and its generalization performances (also referred to as the <em>bias/variance trade-off</em>) <span id="id3">[<a class="reference internal" href="../Chapter_References/bibliography.html#id21"><span>Bon21</span></a>,<a class="reference internal" href="../Chapter_References/bibliography.html#id20"><span>Bis06</span></a>,<a class="reference internal" href="../Chapter_References/bibliography.html#id19"><span>FHT01</span></a>]</span>. Models that have too few parameters fail to properly represent the relationship between input and output features (also referred to as <em>underfitting</em>). Models that have many parameters can perfectly represent the relationship between input and output features in the training data (also referred to as <em>overfitting</em>). Training data are however often noisy, and their distribution slightly different from the validation and test data. As a result, overfitting is usually detrimental to the performances on the validation or test data.</p>
<p>A qualitative representation of the trade-off between model complexity and performances is illustrated in Fig. 2. The training performances usually increase with the model complexity. The optimal validation and test performances are found for models of intermediate complexity, that both avoid underfitting and overfitting. This trade-off was experimentally illustrated with decision trees in the previous section on <a class="reference internal" href="ValidationStrategies.html#validation-strategies"><span class="std std-ref">Validation Strategies</span></a>.</p>
<p><img alt="alt text" src="../_images/model_selection_graph.png" /></p>
<div align="center">Fig. 2. Trade-off between model complexity and performances. The optimal validation and test performances are usually found for models of intermediate complexity, that both avoid underfitting and overfitting. </div>
<p>This section aims at refining the <a class="reference internal" href="ValidationStrategies.html#sklearn-validation-pipeline"><span class="std std-ref">sklearn validation pipeline</span></a>, and exploring the trade-offs between model complexity and performances for different classes of models.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialization: Load shared functions and simulated data </span>

<span class="c1"># Load shared functions</span>
<span class="o">!</span>curl -O https://raw.githubusercontent.com/Fraud-Detection-Handbook/fraud-detection-handbook/main/Chapter_References/shared_functions.py
<span class="o">%</span><span class="k">run</span> shared_functions.py

<span class="c1"># Get simulated data from Github repository</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s2">&quot;simulated-data-transformed&quot;</span><span class="p">):</span>
    <span class="o">!</span>git clone https://github.com/Fraud-Detection-Handbook/simulated-data-transformed
        
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 43447  100 43447    0     0   134k      0 --:--:-- --:--:-- --:--:--  134k
</pre></div>
</div>
</div>
</div>
<div class="section" id="model-selection-decision-trees">
<h2><span class="section-number">3.1. </span>Model selection: Decision trees<a class="headerlink" href="#model-selection-decision-trees" title="Permalink to this headline">¶</a></h2>
<p>Let us first reproduce the <a class="reference internal" href="ValidationStrategies.html#sklearn-validation-pipeline"><span class="std std-ref">sklearn prequential validation pipeline</span></a> proposed in the previous section. We load three months of transaction data, and define the output feature as the fraud label <code class="docutils literal notranslate"><span class="pre">TX_FRAUD</span></code>, and the inputs features as the set of features obtained from the <a class="reference internal" href="../Chapter_3_GettingStarted/BaselineFeatureTransformation.html#baseline-feature-transformation"><span class="std std-ref">baseline preprocessing</span></a>.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load data from the 2018-06-11 to the 2018-09-14</span>

<span class="n">DIR_INPUT</span><span class="o">=</span><span class="s1">&#39;simulated-data-transformed/data/&#39;</span> 

<span class="n">BEGIN_DATE</span> <span class="o">=</span> <span class="s2">&quot;2018-06-11&quot;</span>
<span class="n">END_DATE</span> <span class="o">=</span> <span class="s2">&quot;2018-09-14&quot;</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Load  files&quot;</span><span class="p">)</span>
<span class="o">%</span><span class="k">time</span> transactions_df=read_from_files(DIR_INPUT, BEGIN_DATE, END_DATE)
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{0}</span><span class="s2"> transactions loaded, containing </span><span class="si">{1}</span><span class="s2"> fraudulent transactions&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">),</span><span class="n">transactions_df</span><span class="o">.</span><span class="n">TX_FRAUD</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>

<span class="n">output_feature</span><span class="o">=</span><span class="s2">&quot;TX_FRAUD&quot;</span>

<span class="n">input_features</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;TX_AMOUNT&#39;</span><span class="p">,</span><span class="s1">&#39;TX_DURING_WEEKEND&#39;</span><span class="p">,</span> <span class="s1">&#39;TX_DURING_NIGHT&#39;</span><span class="p">,</span> <span class="s1">&#39;CUSTOMER_ID_NB_TX_1DAY_WINDOW&#39;</span><span class="p">,</span>
       <span class="s1">&#39;CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW&#39;</span><span class="p">,</span> <span class="s1">&#39;CUSTOMER_ID_NB_TX_7DAY_WINDOW&#39;</span><span class="p">,</span>
       <span class="s1">&#39;CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW&#39;</span><span class="p">,</span> <span class="s1">&#39;CUSTOMER_ID_NB_TX_30DAY_WINDOW&#39;</span><span class="p">,</span>
       <span class="s1">&#39;CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW&#39;</span><span class="p">,</span> <span class="s1">&#39;TERMINAL_ID_NB_TX_1DAY_WINDOW&#39;</span><span class="p">,</span>
       <span class="s1">&#39;TERMINAL_ID_RISK_1DAY_WINDOW&#39;</span><span class="p">,</span> <span class="s1">&#39;TERMINAL_ID_NB_TX_7DAY_WINDOW&#39;</span><span class="p">,</span>
       <span class="s1">&#39;TERMINAL_ID_RISK_7DAY_WINDOW&#39;</span><span class="p">,</span> <span class="s1">&#39;TERMINAL_ID_NB_TX_30DAY_WINDOW&#39;</span><span class="p">,</span>
       <span class="s1">&#39;TERMINAL_ID_RISK_30DAY_WINDOW&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Load  files
CPU times: user 982 ms, sys: 712 ms, total: 1.69 s
Wall time: 2.13 s
919767 transactions loaded, containing 8195 fraudulent transactions
</pre></div>
</div>
</div>
</div>
<p>The reference starting date for training is set at 2018-07-25, and the deltas to seven days (see <a class="reference internal" href="ValidationStrategies.html#validation-strategies"><span class="std std-ref">Validation Strategies</span></a>).</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Number of folds for the prequential validation</span>
<span class="n">n_folds</span><span class="o">=</span><span class="mi">4</span>

<span class="c1"># Set the starting day for the training period, and the deltas</span>
<span class="n">start_date_training</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">strptime</span><span class="p">(</span><span class="s2">&quot;2018-07-25&quot;</span><span class="p">,</span> <span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">delta_train</span><span class="o">=</span><span class="n">delta_delay</span><span class="o">=</span><span class="n">delta_test</span><span class="o">=</span><span class="n">delta_valid</span><span class="o">=</span><span class="n">delta_assessment</span><span class="o">=</span><span class="mi">7</span>

<span class="n">start_date_training_for_valid</span> <span class="o">=</span> <span class="n">start_date_training</span><span class="o">+</span><span class="n">datetime</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=-</span><span class="p">(</span><span class="n">delta_delay</span><span class="o">+</span><span class="n">delta_valid</span><span class="p">))</span>
<span class="n">start_date_training_for_test</span> <span class="o">=</span> <span class="n">start_date_training</span><span class="o">+</span><span class="n">datetime</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="p">(</span><span class="n">n_folds</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">delta_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The performance metrics are the AUC ROC, the average Precision, and the Card Precision&#64;100.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Only keep columns that are needed as argument to custome scoring function</span>
<span class="c1"># to reduce serialisation time of transaction dataset</span>
<span class="n">transactions_df_scorer</span><span class="o">=</span><span class="n">transactions_df</span><span class="p">[[</span><span class="s1">&#39;CUSTOMER_ID&#39;</span><span class="p">,</span> <span class="s1">&#39;TX_FRAUD&#39;</span><span class="p">,</span><span class="s1">&#39;TX_TIME_DAYS&#39;</span><span class="p">]]</span>

<span class="n">card_precision_top_100</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">make_scorer</span><span class="p">(</span><span class="n">card_precision_top_k_custom</span><span class="p">,</span> 
                                                     <span class="n">needs_proba</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                                     <span class="n">top_k</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
                                                     <span class="n">transactions_df</span><span class="o">=</span><span class="n">transactions_df_scorer</span><span class="p">)</span>

<span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="s1">&#39;average_precision&#39;</span><span class="p">,</span> <span class="s1">&#39;card_precision@100&#39;</span><span class="p">]</span>
<span class="n">performance_metrics_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">,</span> <span class="s1">&#39;Average precision&#39;</span><span class="p">,</span> <span class="s1">&#39;Card Precision@100&#39;</span><span class="p">]</span>

<span class="n">scoring</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">:</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span>
           <span class="s1">&#39;average_precision&#39;</span><span class="p">:</span> <span class="s1">&#39;average_precision&#39;</span><span class="p">,</span>
           <span class="s1">&#39;card_precision@100&#39;</span><span class="p">:</span> <span class="n">card_precision_top_100</span><span class="p">,</span>
           <span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>For the sake of conciseness, let us define a <code class="docutils literal notranslate"><span class="pre">model_selection_wrapper</span></code> function, that will perform prequential validation for both the validation and the test sets.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">model_selection_wrapper</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span> 
                            <span class="n">classifier</span><span class="p">,</span> 
                            <span class="n">input_features</span><span class="p">,</span> <span class="n">output_feature</span><span class="p">,</span>
                            <span class="n">parameters</span><span class="p">,</span> 
                            <span class="n">scoring</span><span class="p">,</span> 
                            <span class="n">start_date_training_for_valid</span><span class="p">,</span>
                            <span class="n">start_date_training_for_test</span><span class="p">,</span>
                            <span class="n">n_folds</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                            <span class="n">delta_train</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> 
                            <span class="n">delta_delay</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> 
                            <span class="n">delta_assessment</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
                            <span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">],</span>
                            <span class="n">performance_metrics_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">],</span>
                            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>

    <span class="c1"># Get performances on the validation set using prequential validation</span>
    <span class="n">performances_df_validation</span><span class="o">=</span><span class="n">prequential_grid_search</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> 
                            <span class="n">input_features</span><span class="p">,</span> <span class="n">output_feature</span><span class="p">,</span>
                            <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> 
                            <span class="n">start_date_training</span><span class="o">=</span><span class="n">start_date_training_for_valid</span><span class="p">,</span>
                            <span class="n">n_folds</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span>
                            <span class="n">expe_type</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">,</span>
                            <span class="n">delta_train</span><span class="o">=</span><span class="n">delta_train</span><span class="p">,</span> 
                            <span class="n">delta_delay</span><span class="o">=</span><span class="n">delta_delay</span><span class="p">,</span> 
                            <span class="n">delta_assessment</span><span class="o">=</span><span class="n">delta_assessment</span><span class="p">,</span>
                            <span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="n">performance_metrics_list_grid</span><span class="p">,</span>
                            <span class="n">performance_metrics_list</span><span class="o">=</span><span class="n">performance_metrics_list</span><span class="p">,</span>
                            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">)</span>
    
    <span class="c1"># Get performances on the test set using prequential validation</span>
    <span class="n">performances_df_test</span><span class="o">=</span><span class="n">prequential_grid_search</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> 
                            <span class="n">input_features</span><span class="p">,</span> <span class="n">output_feature</span><span class="p">,</span>
                            <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> 
                            <span class="n">start_date_training</span><span class="o">=</span><span class="n">start_date_training_for_test</span><span class="p">,</span>
                            <span class="n">n_folds</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span>
                            <span class="n">expe_type</span><span class="o">=</span><span class="s1">&#39;Test&#39;</span><span class="p">,</span>
                            <span class="n">delta_train</span><span class="o">=</span><span class="n">delta_train</span><span class="p">,</span> 
                            <span class="n">delta_delay</span><span class="o">=</span><span class="n">delta_delay</span><span class="p">,</span> 
                            <span class="n">delta_assessment</span><span class="o">=</span><span class="n">delta_assessment</span><span class="p">,</span>
                            <span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="n">performance_metrics_list_grid</span><span class="p">,</span>
                            <span class="n">performance_metrics_list</span><span class="o">=</span><span class="n">performance_metrics_list</span><span class="p">,</span>
                            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">)</span>
    
    <span class="c1"># Bind the two resulting DataFrames</span>
    <span class="n">performances_df_validation</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Parameters&#39;</span><span class="p">,</span><span class="s1">&#39;Execution time&#39;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">performances_df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">performances_df_test</span><span class="p">,</span><span class="n">performances_df_validation</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># And return as a single DataFrame</span>
    <span class="k">return</span> <span class="n">performances_df</span>
</pre></div>
</div>
</div>
</div>
<p>Prequential validation can now be performed with the few following lines of code, by</p>
<ul class="simple">
<li><p>defining which classifier to use</p></li>
<li><p>defining which parameters to test</p></li>
<li><p>fitting the models and assessing the performances</p></li>
</ul>
<p>The implementation using decision trees as predictions models, for maximum depth in <span class="math notranslate nohighlight">\([2,3,4,5,6,7,8,9,10,20,50]\)</span>, is obtained with:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define classifier</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">()</span>

<span class="c1"># Set of parameters for which to assess model performances</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;clf__max_depth&#39;</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">50</span><span class="p">],</span> <span class="s1">&#39;clf__random_state&#39;</span><span class="p">:[</span><span class="mi">0</span><span class="p">]}</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="c1"># Fit models and assess performances for all parameters</span>
<span class="n">performances_df</span><span class="o">=</span><span class="n">model_selection_wrapper</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> 
                                        <span class="n">input_features</span><span class="p">,</span> <span class="n">output_feature</span><span class="p">,</span>
                                        <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> 
                                        <span class="n">start_date_training_for_valid</span><span class="p">,</span>
                                        <span class="n">start_date_training_for_test</span><span class="p">,</span>
                                        <span class="n">n_folds</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span>
                                        <span class="n">delta_train</span><span class="o">=</span><span class="n">delta_train</span><span class="p">,</span> 
                                        <span class="n">delta_delay</span><span class="o">=</span><span class="n">delta_delay</span><span class="p">,</span> 
                                        <span class="n">delta_assessment</span><span class="o">=</span><span class="n">delta_assessment</span><span class="p">,</span>
                                        <span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="n">performance_metrics_list_grid</span><span class="p">,</span>
                                        <span class="n">performance_metrics_list</span><span class="o">=</span><span class="n">performance_metrics_list</span><span class="p">,</span>
                                        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">execution_time_dt</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start_time</span>

<span class="c1"># Select parameter of interest (max_depth)</span>
<span class="n">parameters_dict</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters&#39;</span><span class="p">])</span>
<span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters summary&#39;</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="n">parameters_dict</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;clf__max_depth&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">))]</span>

<span class="c1"># Rename to performances_df_dt for model performance comparison at the end of this notebook</span>
<span class="n">performances_df_dt</span><span class="o">=</span><span class="n">performances_df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">performances_df_dt</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AUC ROC Test</th>
      <th>AUC ROC Test Std</th>
      <th>Average precision Test</th>
      <th>Average precision Test Std</th>
      <th>Card Precision@100 Test</th>
      <th>Card Precision@100 Test Std</th>
      <th>Parameters</th>
      <th>Execution time</th>
      <th>AUC ROC Validation</th>
      <th>AUC ROC Validation Std</th>
      <th>Average precision Validation</th>
      <th>Average precision Validation Std</th>
      <th>Card Precision@100 Validation</th>
      <th>Card Precision@100 Validation Std</th>
      <th>Parameters summary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.791909</td>
      <td>0.017769</td>
      <td>0.541761</td>
      <td>0.031476</td>
      <td>0.265000</td>
      <td>0.019756</td>
      <td>{'clf__max_depth': 2, 'clf__random_state': 0}</td>
      <td>0.433836</td>
      <td>0.790786</td>
      <td>0.012035</td>
      <td>0.549767</td>
      <td>0.022134</td>
      <td>0.256429</td>
      <td>0.014481</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.809012</td>
      <td>0.009125</td>
      <td>0.578885</td>
      <td>0.014434</td>
      <td>0.281429</td>
      <td>0.015940</td>
      <td>{'clf__max_depth': 3, 'clf__random_state': 0}</td>
      <td>0.448277</td>
      <td>0.802717</td>
      <td>0.017607</td>
      <td>0.573414</td>
      <td>0.027186</td>
      <td>0.267143</td>
      <td>0.016067</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.812555</td>
      <td>0.010319</td>
      <td>0.601088</td>
      <td>0.020216</td>
      <td>0.282500</td>
      <td>0.015199</td>
      <td>{'clf__max_depth': 4, 'clf__random_state': 0}</td>
      <td>0.516275</td>
      <td>0.800690</td>
      <td>0.017878</td>
      <td>0.554134</td>
      <td>0.038293</td>
      <td>0.264286</td>
      <td>0.014321</td>
      <td>4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.810138</td>
      <td>0.008586</td>
      <td>0.600306</td>
      <td>0.016797</td>
      <td>0.284286</td>
      <td>0.004286</td>
      <td>{'clf__max_depth': 5, 'clf__random_state': 0}</td>
      <td>0.595820</td>
      <td>0.804218</td>
      <td>0.016505</td>
      <td>0.546094</td>
      <td>0.042197</td>
      <td>0.267857</td>
      <td>0.013869</td>
      <td>5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.804437</td>
      <td>0.007974</td>
      <td>0.585132</td>
      <td>0.005053</td>
      <td>0.281429</td>
      <td>0.007626</td>
      <td>{'clf__max_depth': 6, 'clf__random_state': 0}</td>
      <td>0.757094</td>
      <td>0.798603</td>
      <td>0.024225</td>
      <td>0.537006</td>
      <td>0.037056</td>
      <td>0.264643</td>
      <td>0.008474</td>
      <td>6</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.782710</td>
      <td>0.012483</td>
      <td>0.554860</td>
      <td>0.011771</td>
      <td>0.268929</td>
      <td>0.009813</td>
      <td>{'clf__max_depth': 7, 'clf__random_state': 0}</td>
      <td>0.714120</td>
      <td>0.795636</td>
      <td>0.023144</td>
      <td>0.530609</td>
      <td>0.040323</td>
      <td>0.262500</td>
      <td>0.006804</td>
      <td>7</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.774783</td>
      <td>0.014568</td>
      <td>0.544933</td>
      <td>0.003392</td>
      <td>0.263571</td>
      <td>0.007593</td>
      <td>{'clf__max_depth': 8, 'clf__random_state': 0}</td>
      <td>0.674568</td>
      <td>0.795142</td>
      <td>0.023081</td>
      <td>0.516246</td>
      <td>0.033545</td>
      <td>0.260714</td>
      <td>0.009715</td>
      <td>8</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.761763</td>
      <td>0.012098</td>
      <td>0.520208</td>
      <td>0.012309</td>
      <td>0.258571</td>
      <td>0.009949</td>
      <td>{'clf__max_depth': 9, 'clf__random_state': 0}</td>
      <td>0.702908</td>
      <td>0.785849</td>
      <td>0.026249</td>
      <td>0.505189</td>
      <td>0.040393</td>
      <td>0.260357</td>
      <td>0.009813</td>
      <td>9</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.758138</td>
      <td>0.011140</td>
      <td>0.504909</td>
      <td>0.013154</td>
      <td>0.257500</td>
      <td>0.010467</td>
      <td>{'clf__max_depth': 10, 'clf__random_state': 0}</td>
      <td>0.865949</td>
      <td>0.786784</td>
      <td>0.031165</td>
      <td>0.493543</td>
      <td>0.048307</td>
      <td>0.257143</td>
      <td>0.009949</td>
      <td>10</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.754024</td>
      <td>0.009848</td>
      <td>0.439422</td>
      <td>0.034828</td>
      <td>0.261071</td>
      <td>0.014335</td>
      <td>{'clf__max_depth': 20, 'clf__random_state': 0}</td>
      <td>1.384710</td>
      <td>0.780408</td>
      <td>0.022168</td>
      <td>0.450980</td>
      <td>0.031413</td>
      <td>0.264286</td>
      <td>0.007890</td>
      <td>20</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.797221</td>
      <td>0.005425</td>
      <td>0.334055</td>
      <td>0.020390</td>
      <td>0.258214</td>
      <td>0.012095</td>
      <td>{'clf__max_depth': 50, 'clf__random_state': 0}</td>
      <td>1.383142</td>
      <td>0.822564</td>
      <td>0.013407</td>
      <td>0.341818</td>
      <td>0.026227</td>
      <td>0.265714</td>
      <td>0.008512</td>
      <td>50</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The resulting DataFrame provides the performances in terms of AUC ROC, AP, and CP&#64;100 for both the validation and test sets. Rows correspond to performances for a given maximum depth of a decision tree.</p>
<p>Let us extract from this table the most relevant information, that is, entries that allow to answer the following questions:</p>
<ol class="simple">
<li><p>Which parameter provides the best performances on the validation set?</p></li>
<li><p>What is the performances on the test set using this parameter?</p></li>
<li><p>What parameter would have provided the best performance on the test set?</p></li>
</ol>
<p>Answers to these questions can be organized as a table, using the <code class="docutils literal notranslate"><span class="pre">get_summary_performances</span></code> function.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_summary_performances</span><span class="p">(</span><span class="n">performances_df</span><span class="p">,</span> <span class="n">parameter_column_name</span><span class="o">=</span><span class="s2">&quot;Parameters summary&quot;</span><span class="p">):</span>

    <span class="c1"># Three performance metrics</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">,</span><span class="s1">&#39;Average precision&#39;</span><span class="p">,</span><span class="s1">&#39;Card Precision@100&#39;</span><span class="p">]</span>
    <span class="n">performances_results</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">metrics</span><span class="p">)</span>
    
    <span class="c1"># Reset indices in case a subset of a performane DataFrame is provided as input</span>
    <span class="n">performances_df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Lists of parameters/performances that will be retrieved for the best estimated parameters</span>
    <span class="n">best_estimated_parameters</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">validation_performance</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_performance</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># For each performance metric, get the validation and test performance for the best estimated parameter</span>
    <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">:</span>
    
        <span class="c1"># Find the index which provides the best validation performance</span>
        <span class="n">index_best_validation_performance</span> <span class="o">=</span> <span class="n">performances_df</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">performances_df</span><span class="p">[</span><span class="n">metric</span><span class="o">+</span><span class="s1">&#39; Validation&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)]</span>
    
        <span class="c1"># Retrieve the corresponding parameters</span>
        <span class="n">best_estimated_parameters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">performances_df</span><span class="p">[</span><span class="n">parameter_column_name</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">index_best_validation_performance</span><span class="p">])</span>
        
        <span class="c1"># Add validation performance to the validation_performance list (mean+/-std)</span>
        <span class="n">validation_performance</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">performances_df</span><span class="p">[</span><span class="n">metric</span><span class="o">+</span><span class="s1">&#39; Validation&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">index_best_validation_performance</span><span class="p">],</span><span class="mi">3</span><span class="p">))</span><span class="o">+</span>
                <span class="s1">&#39;+/-&#39;</span><span class="o">+</span>
                <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">performances_df</span><span class="p">[</span><span class="n">metric</span><span class="o">+</span><span class="s1">&#39; Validation&#39;</span><span class="o">+</span><span class="s1">&#39; Std&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">index_best_validation_performance</span><span class="p">],</span><span class="mi">2</span><span class="p">))</span>
        <span class="p">)</span>
        
        <span class="c1"># Add test performance to the test_performance list (mean+/-std)</span>
        <span class="n">test_performance</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">performances_df</span><span class="p">[</span><span class="n">metric</span><span class="o">+</span><span class="s1">&#39; Test&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">index_best_validation_performance</span><span class="p">],</span><span class="mi">3</span><span class="p">))</span><span class="o">+</span>
                <span class="s1">&#39;+/-&#39;</span><span class="o">+</span>
                <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">performances_df</span><span class="p">[</span><span class="n">metric</span><span class="o">+</span><span class="s1">&#39; Test&#39;</span><span class="o">+</span><span class="s1">&#39; Std&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">index_best_validation_performance</span><span class="p">],</span><span class="mi">2</span><span class="p">))</span>
        <span class="p">)</span>
    
    <span class="c1"># Add results to the performances_results DataFrame</span>
    <span class="n">performances_results</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;Best estimated parameters&quot;</span><span class="p">]</span><span class="o">=</span><span class="n">best_estimated_parameters</span>
    <span class="n">performances_results</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;Validation performance&quot;</span><span class="p">]</span><span class="o">=</span><span class="n">validation_performance</span>
    <span class="n">performances_results</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;Test performance&quot;</span><span class="p">]</span><span class="o">=</span><span class="n">test_performance</span>

    <span class="c1"># Lists of parameters/performances that will be retrieved for the optimal parameters</span>
    <span class="n">optimal_test_performance</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">optimal_parameters</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># For each performance metric, get the performance for the optimal parameter</span>
    <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;AUC ROC Test&#39;</span><span class="p">,</span><span class="s1">&#39;Average precision Test&#39;</span><span class="p">,</span><span class="s1">&#39;Card Precision@100 Test&#39;</span><span class="p">]:</span>
    
        <span class="c1"># Find the index which provides the optimal performance</span>
        <span class="n">index_optimal_test_performance</span> <span class="o">=</span> <span class="n">performances_df</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">performances_df</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)]</span>
    
        <span class="c1"># Retrieve the corresponding parameters</span>
        <span class="n">optimal_parameters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">performances_df</span><span class="p">[</span><span class="n">parameter_column_name</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">index_optimal_test_performance</span><span class="p">])</span>
    
        <span class="c1"># Add test performance to the test_performance list (mean+/-std)</span>
        <span class="n">optimal_test_performance</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">performances_df</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">index_optimal_test_performance</span><span class="p">],</span><span class="mi">3</span><span class="p">))</span><span class="o">+</span>
                <span class="s1">&#39;+/-&#39;</span><span class="o">+</span>
                <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">performances_df</span><span class="p">[</span><span class="n">metric</span><span class="o">+</span><span class="s1">&#39; Std&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">index_optimal_test_performance</span><span class="p">],</span><span class="mi">2</span><span class="p">))</span>
        <span class="p">)</span>

    <span class="c1"># Add results to the performances_results DataFrame</span>
    <span class="n">performances_results</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;Optimal parameters&quot;</span><span class="p">]</span><span class="o">=</span><span class="n">optimal_parameters</span>
    <span class="n">performances_results</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;Optimal test performance&quot;</span><span class="p">]</span><span class="o">=</span><span class="n">optimal_test_performance</span>
    
    <span class="k">return</span> <span class="n">performances_results</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary_performances_dt</span><span class="o">=</span><span class="n">get_summary_performances</span><span class="p">(</span><span class="n">performances_df_dt</span><span class="p">,</span> <span class="n">parameter_column_name</span><span class="o">=</span><span class="s2">&quot;Parameters summary&quot;</span><span class="p">)</span>
<span class="n">summary_performances_dt</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AUC ROC</th>
      <th>Average precision</th>
      <th>Card Precision@100</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Best estimated parameters</th>
      <td>50</td>
      <td>3</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Validation performance</th>
      <td>0.823+/-0.01</td>
      <td>0.573+/-0.03</td>
      <td>0.268+/-0.01</td>
    </tr>
    <tr>
      <th>Test performance</th>
      <td>0.797+/-0.01</td>
      <td>0.579+/-0.01</td>
      <td>0.284+/-0.0</td>
    </tr>
    <tr>
      <th>Optimal parameters</th>
      <td>4</td>
      <td>4</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Optimal test performance</th>
      <td>0.813+/-0.01</td>
      <td>0.601+/-0.02</td>
      <td>0.284+/-0.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The first row provides the parameters that maximize the performances on the validation set (best estimated parameters <span class="math notranslate nohighlight">\(k^*\)</span>). The second and third rows provide the corresponding performances on the validation and test sets, respectively. The fourth row provides the actual optimal parameters on the test set (the parameters that maximize the performances on the test set). The fifth row provides the corresponding performances on the test set.</p>
<p>Two important observations can be made from this summary table. First, the optimal parameter depends on the performance metrics: It is a maximum depth of 4 for AUC ROC and AP, while it is a maximum depth of 5 for the CP&#64;100. Second, the best parameters for the validation may not be the optimal parameter for the test set. This is the case for the AUC ROC (maximum depth of 50 for the validation set versus 4 for the test set), and the AP (maximum depth of 3 for the validation set versus 4 for the test set).</p>
<p>Similar to the section <a class="reference internal" href="ValidationStrategies.html#validation-strategies"><span class="std std-ref">Validation Strategies</span></a>, let us plot the performances as a function of the decision tree depth. The vertical dashed line is the tree depth for which the performance is maximized on the validation data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">get_performances_plots</span><span class="p">(</span><span class="n">performances_df_dt</span><span class="p">,</span> 
                       <span class="n">performance_metrics_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">,</span> <span class="s1">&#39;Average precision&#39;</span><span class="p">,</span> <span class="s1">&#39;Card Precision@100&#39;</span><span class="p">],</span> 
                       <span class="n">expe_type_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Test&#39;</span><span class="p">,</span><span class="s1">&#39;Validation&#39;</span><span class="p">],</span> <span class="n">expe_type_color_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;#008000&#39;</span><span class="p">,</span><span class="s1">&#39;#FF0000&#39;</span><span class="p">],</span>
                       <span class="n">summary_performances</span><span class="o">=</span><span class="n">summary_performances_dt</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ModelSelection_18_0.png" src="../_images/ModelSelection_18_0.png" />
</div>
</div>
</div>
<div class="section" id="model-selection-exploration-of-other-model-classes">
<h2><span class="section-number">3.2. </span>Model selection: Exploration of other model classes<a class="headerlink" href="#model-selection-exploration-of-other-model-classes" title="Permalink to this headline">¶</a></h2>
<p>This section explores the performances that can be achieved with model selection using other model classes. We cover logistic regression, random forests, and boosting (as in the section <a class="reference internal" href="../Chapter_3_GettingStarted/BaselineModeling.html#baseline-fds"><span class="std std-ref">Baseline Fraud Detection System</span></a>).</p>
<div class="section" id="logistic-regression">
<h3><span class="section-number">3.2.1. </span>Logistic regression<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">¶</a></h3>
<p>The main hyperparameter of logistic regression is the <a class="reference external" href="https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression">regularization parameter C</a>. The <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression">default value for this parameter is 1</a>. Let us try fitting models with lower and higher values, for example in the set [0.1,1,10,100].</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">classifier</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">()</span>

<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;clf__C&#39;</span><span class="p">:[</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span><span class="p">],</span> <span class="s1">&#39;clf__random_state&#39;</span><span class="p">:[</span><span class="mi">0</span><span class="p">]}</span>

<span class="n">start_time</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">performances_df</span><span class="o">=</span><span class="n">model_selection_wrapper</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> 
                                        <span class="n">input_features</span><span class="p">,</span> <span class="n">output_feature</span><span class="p">,</span>
                                        <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> 
                                        <span class="n">start_date_training_for_valid</span><span class="p">,</span>
                                        <span class="n">start_date_training_for_test</span><span class="p">,</span>
                                        <span class="n">n_folds</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span>
                                        <span class="n">delta_train</span><span class="o">=</span><span class="n">delta_train</span><span class="p">,</span> 
                                        <span class="n">delta_delay</span><span class="o">=</span><span class="n">delta_delay</span><span class="p">,</span> 
                                        <span class="n">delta_assessment</span><span class="o">=</span><span class="n">delta_assessment</span><span class="p">,</span>
                                        <span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="n">performance_metrics_list_grid</span><span class="p">,</span>
                                        <span class="n">performance_metrics_list</span><span class="o">=</span><span class="n">performance_metrics_list</span><span class="p">,</span>
                                        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">execution_time_lr</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start_time</span>

<span class="n">parameters_dict</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters&#39;</span><span class="p">])</span>
<span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters summary&#39;</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="n">parameters_dict</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;clf__C&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">))]</span>

<span class="c1"># Rename to performances_df_lr for model performance comparison at the end of this notebook</span>
<span class="n">performances_df_lr</span><span class="o">=</span><span class="n">performances_df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">performances_df_lr</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AUC ROC Test</th>
      <th>AUC ROC Test Std</th>
      <th>Average precision Test</th>
      <th>Average precision Test Std</th>
      <th>Card Precision@100 Test</th>
      <th>Card Precision@100 Test Std</th>
      <th>Parameters</th>
      <th>Execution time</th>
      <th>AUC ROC Validation</th>
      <th>AUC ROC Validation Std</th>
      <th>Average precision Validation</th>
      <th>Average precision Validation Std</th>
      <th>Card Precision@100 Validation</th>
      <th>Card Precision@100 Validation Std</th>
      <th>Parameters summary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.866971</td>
      <td>0.014856</td>
      <td>0.620227</td>
      <td>0.015979</td>
      <td>0.297143</td>
      <td>0.008207</td>
      <td>{'clf__C': 0.1, 'clf__random_state': 0}</td>
      <td>0.505353</td>
      <td>0.865051</td>
      <td>0.009591</td>
      <td>0.608326</td>
      <td>0.022735</td>
      <td>0.278929</td>
      <td>0.016300</td>
      <td>0.1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.867640</td>
      <td>0.015400</td>
      <td>0.623075</td>
      <td>0.016207</td>
      <td>0.297143</td>
      <td>0.008806</td>
      <td>{'clf__C': 1, 'clf__random_state': 0}</td>
      <td>0.499692</td>
      <td>0.866861</td>
      <td>0.008988</td>
      <td>0.612264</td>
      <td>0.023474</td>
      <td>0.278214</td>
      <td>0.016914</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.867676</td>
      <td>0.015412</td>
      <td>0.623221</td>
      <td>0.016086</td>
      <td>0.297500</td>
      <td>0.008828</td>
      <td>{'clf__C': 10, 'clf__random_state': 0}</td>
      <td>0.511710</td>
      <td>0.867050</td>
      <td>0.008918</td>
      <td>0.612526</td>
      <td>0.023715</td>
      <td>0.277500</td>
      <td>0.016763</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.867676</td>
      <td>0.015413</td>
      <td>0.623249</td>
      <td>0.016076</td>
      <td>0.297500</td>
      <td>0.008828</td>
      <td>{'clf__C': 100, 'clf__random_state': 0}</td>
      <td>0.496295</td>
      <td>0.867071</td>
      <td>0.008912</td>
      <td>0.612537</td>
      <td>0.023712</td>
      <td>0.277500</td>
      <td>0.016763</td>
      <td>100.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">get_summary_performances</span></code> function gives the summary of the best parameters and corresponding performances.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary_performances_lr</span><span class="o">=</span><span class="n">get_summary_performances</span><span class="p">(</span><span class="n">performances_df_lr</span><span class="p">,</span> <span class="n">parameter_column_name</span><span class="o">=</span><span class="s2">&quot;Parameters summary&quot;</span><span class="p">)</span>
<span class="n">summary_performances_lr</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AUC ROC</th>
      <th>Average precision</th>
      <th>Card Precision@100</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Best estimated parameters</th>
      <td>100</td>
      <td>100</td>
      <td>0.1</td>
    </tr>
    <tr>
      <th>Validation performance</th>
      <td>0.867+/-0.01</td>
      <td>0.613+/-0.02</td>
      <td>0.279+/-0.02</td>
    </tr>
    <tr>
      <th>Test performance</th>
      <td>0.868+/-0.02</td>
      <td>0.623+/-0.02</td>
      <td>0.297+/-0.01</td>
    </tr>
    <tr>
      <th>Optimal parameters</th>
      <td>100</td>
      <td>100</td>
      <td>10</td>
    </tr>
    <tr>
      <th>Optimal test performance</th>
      <td>0.868+/-0.02</td>
      <td>0.623+/-0.02</td>
      <td>0.298+/-0.01</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let us plot the performances as a function of the regularization value, together with the value that provides the best estimated performances.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">get_performances_plots</span><span class="p">(</span><span class="n">performances_df_lr</span><span class="p">,</span> 
                       <span class="n">performance_metrics_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">,</span> <span class="s1">&#39;Average precision&#39;</span><span class="p">,</span> <span class="s1">&#39;Card Precision@100&#39;</span><span class="p">],</span> 
                       <span class="n">expe_type_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Test&#39;</span><span class="p">,</span><span class="s1">&#39;Validation&#39;</span><span class="p">],</span> <span class="n">expe_type_color_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;#008000&#39;</span><span class="p">,</span><span class="s1">&#39;#FF0000&#39;</span><span class="p">],</span>
                       <span class="n">parameter_name</span><span class="o">=</span><span class="s2">&quot;Regularization value&quot;</span><span class="p">,</span>
                       <span class="n">summary_performances</span><span class="o">=</span><span class="n">summary_performances_lr</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ModelSelection_26_0.png" src="../_images/ModelSelection_26_0.png" />
</div>
</div>
<p>Performances tend to be a bit lower for a low <span class="math notranslate nohighlight">\(C\)</span> value (0.1). <span class="math notranslate nohighlight">\(C\)</span> values equal or higher than one provide similar performances. The default parameter <span class="math notranslate nohighlight">\(C=1\)</span> seems therefore to be a sensible value for the logistic regression model.</p>
</div>
<div class="section" id="random-forest">
<h3><span class="section-number">3.2.2. </span>Random forest<a class="headerlink" href="#random-forest" title="Permalink to this headline">¶</a></h3>
<p>The two main <a class="reference external" href="https://scikit-learn.org/stable/modules/ensemble.html#forest">hyperparameters of a random forest</a> are the maximum tree depth and the number of trees (parameters <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> and <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>, respectively). <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">By default</a>, the maximum tree depth is <code class="docutils literal notranslate"><span class="pre">None</span></code> (that is, nodes are expanded until all leaves are pure or until all leaves contain less than <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code> samples), and the number of trees is 100. Let us try other values, by combining <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> values in the set [5,10,20,50] and <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> values in the set [25,50,100].</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">classifier</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestClassifier</span><span class="p">()</span>

<span class="c1"># Note: n_jobs set to one for getting true execution times</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;clf__max_depth&#39;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">50</span><span class="p">],</span> <span class="s1">&#39;clf__n_estimators&#39;</span><span class="p">:[</span><span class="mi">25</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">],</span>
              <span class="s1">&#39;clf__random_state&#39;</span><span class="p">:[</span><span class="mi">0</span><span class="p">],</span><span class="s1">&#39;clf__n_jobs&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">]}</span>

<span class="n">start_time</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">performances_df</span><span class="o">=</span><span class="n">model_selection_wrapper</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> 
                                        <span class="n">input_features</span><span class="p">,</span> <span class="n">output_feature</span><span class="p">,</span>
                                        <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> 
                                        <span class="n">start_date_training_for_valid</span><span class="p">,</span>
                                        <span class="n">start_date_training_for_test</span><span class="p">,</span>
                                        <span class="n">n_folds</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span>
                                        <span class="n">delta_train</span><span class="o">=</span><span class="n">delta_train</span><span class="p">,</span> 
                                        <span class="n">delta_delay</span><span class="o">=</span><span class="n">delta_delay</span><span class="p">,</span> 
                                        <span class="n">delta_assessment</span><span class="o">=</span><span class="n">delta_assessment</span><span class="p">,</span>
                                        <span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="n">performance_metrics_list_grid</span><span class="p">,</span>
                                        <span class="n">performance_metrics_list</span><span class="o">=</span><span class="n">performance_metrics_list</span><span class="p">,</span>
                                        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">execution_time_rf</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start_time</span>

<span class="n">parameters_dict</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters&#39;</span><span class="p">])</span>
<span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters summary&#39;</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;clf__n_estimators&#39;</span><span class="p">])</span><span class="o">+</span>
                                   <span class="s1">&#39;/&#39;</span><span class="o">+</span>
                                   <span class="nb">str</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;clf__max_depth&#39;</span><span class="p">])</span>
                                   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">))]</span>

<span class="c1"># Rename to performances_df_rf for model performance comparison at the end of this notebook</span>
<span class="n">performances_df_rf</span><span class="o">=</span><span class="n">performances_df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">performances_df_rf</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AUC ROC Test</th>
      <th>AUC ROC Test Std</th>
      <th>Average precision Test</th>
      <th>Average precision Test Std</th>
      <th>Card Precision@100 Test</th>
      <th>Card Precision@100 Test Std</th>
      <th>Parameters</th>
      <th>Execution time</th>
      <th>AUC ROC Validation</th>
      <th>AUC ROC Validation Std</th>
      <th>Average precision Validation</th>
      <th>Average precision Validation Std</th>
      <th>Card Precision@100 Validation</th>
      <th>Card Precision@100 Validation Std</th>
      <th>Parameters summary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.845289</td>
      <td>0.003870</td>
      <td>0.620915</td>
      <td>0.021970</td>
      <td>0.289286</td>
      <td>0.010570</td>
      <td>{'clf__max_depth': 5, 'clf__n_estimators': 25,...</td>
      <td>1.332392</td>
      <td>0.834147</td>
      <td>0.009100</td>
      <td>0.610413</td>
      <td>0.023740</td>
      <td>0.274286</td>
      <td>0.015551</td>
      <td>25/5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.850969</td>
      <td>0.007507</td>
      <td>0.621135</td>
      <td>0.023615</td>
      <td>0.290714</td>
      <td>0.010996</td>
      <td>{'clf__max_depth': 5, 'clf__n_estimators': 50,...</td>
      <td>2.620222</td>
      <td>0.844140</td>
      <td>0.007473</td>
      <td>0.609801</td>
      <td>0.027459</td>
      <td>0.272857</td>
      <td>0.015085</td>
      <td>50/5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.855230</td>
      <td>0.007315</td>
      <td>0.627005</td>
      <td>0.021874</td>
      <td>0.292500</td>
      <td>0.010850</td>
      <td>{'clf__max_depth': 5, 'clf__n_estimators': 100...</td>
      <td>5.043742</td>
      <td>0.849065</td>
      <td>0.011018</td>
      <td>0.619450</td>
      <td>0.026249</td>
      <td>0.275000</td>
      <td>0.016614</td>
      <td>100/5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.867271</td>
      <td>0.006166</td>
      <td>0.648592</td>
      <td>0.012818</td>
      <td>0.300714</td>
      <td>0.010950</td>
      <td>{'clf__max_depth': 10, 'clf__n_estimators': 25...</td>
      <td>2.537272</td>
      <td>0.865000</td>
      <td>0.002259</td>
      <td>0.651858</td>
      <td>0.020059</td>
      <td>0.285357</td>
      <td>0.012305</td>
      <td>25/10</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.869225</td>
      <td>0.007956</td>
      <td>0.655047</td>
      <td>0.014188</td>
      <td>0.300000</td>
      <td>0.012495</td>
      <td>{'clf__max_depth': 10, 'clf__n_estimators': 50...</td>
      <td>5.074602</td>
      <td>0.871323</td>
      <td>0.004542</td>
      <td>0.659386</td>
      <td>0.021993</td>
      <td>0.286786</td>
      <td>0.015531</td>
      <td>50/10</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.874950</td>
      <td>0.011903</td>
      <td>0.664629</td>
      <td>0.014215</td>
      <td>0.303214</td>
      <td>0.013030</td>
      <td>{'clf__max_depth': 10, 'clf__n_estimators': 10...</td>
      <td>8.804179</td>
      <td>0.872387</td>
      <td>0.005256</td>
      <td>0.663483</td>
      <td>0.024011</td>
      <td>0.286429</td>
      <td>0.017627</td>
      <td>100/10</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.853563</td>
      <td>0.014821</td>
      <td>0.659957</td>
      <td>0.013723</td>
      <td>0.296429</td>
      <td>0.012016</td>
      <td>{'clf__max_depth': 20, 'clf__n_estimators': 25...</td>
      <td>3.257792</td>
      <td>0.869822</td>
      <td>0.005664</td>
      <td>0.680405</td>
      <td>0.016982</td>
      <td>0.285357</td>
      <td>0.014962</td>
      <td>25/20</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.862639</td>
      <td>0.015981</td>
      <td>0.673287</td>
      <td>0.011435</td>
      <td>0.296786</td>
      <td>0.013301</td>
      <td>{'clf__max_depth': 20, 'clf__n_estimators': 50...</td>
      <td>6.083609</td>
      <td>0.876310</td>
      <td>0.006773</td>
      <td>0.690433</td>
      <td>0.019828</td>
      <td>0.287143</td>
      <td>0.016506</td>
      <td>50/20</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.870361</td>
      <td>0.016913</td>
      <td>0.677590</td>
      <td>0.011694</td>
      <td>0.299286</td>
      <td>0.013190</td>
      <td>{'clf__max_depth': 20, 'clf__n_estimators': 10...</td>
      <td>13.117394</td>
      <td>0.879721</td>
      <td>0.006366</td>
      <td>0.694251</td>
      <td>0.020535</td>
      <td>0.288571</td>
      <td>0.016690</td>
      <td>100/20</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.858526</td>
      <td>0.008785</td>
      <td>0.651904</td>
      <td>0.009460</td>
      <td>0.296429</td>
      <td>0.010996</td>
      <td>{'clf__max_depth': 50, 'clf__n_estimators': 25...</td>
      <td>3.690854</td>
      <td>0.869955</td>
      <td>0.003716</td>
      <td>0.674015</td>
      <td>0.021355</td>
      <td>0.284286</td>
      <td>0.016690</td>
      <td>25/50</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.865994</td>
      <td>0.013416</td>
      <td>0.663228</td>
      <td>0.009270</td>
      <td>0.296071</td>
      <td>0.011401</td>
      <td>{'clf__max_depth': 50, 'clf__n_estimators': 50...</td>
      <td>8.848500</td>
      <td>0.875153</td>
      <td>0.003630</td>
      <td>0.683129</td>
      <td>0.020881</td>
      <td>0.286429</td>
      <td>0.014932</td>
      <td>50/50</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.870231</td>
      <td>0.014166</td>
      <td>0.671542</td>
      <td>0.011224</td>
      <td>0.298929</td>
      <td>0.013491</td>
      <td>{'clf__max_depth': 50, 'clf__n_estimators': 10...</td>
      <td>18.136816</td>
      <td>0.878360</td>
      <td>0.002900</td>
      <td>0.691421</td>
      <td>0.019576</td>
      <td>0.287857</td>
      <td>0.015698</td>
      <td>100/50</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">get_summary_performances</span></code> function gives the summary of the best parameters and corresponding performances.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary_performances_rf</span><span class="o">=</span><span class="n">get_summary_performances</span><span class="p">(</span><span class="n">performances_df_rf</span><span class="p">,</span> <span class="n">parameter_column_name</span><span class="o">=</span><span class="s2">&quot;Parameters summary&quot;</span><span class="p">)</span>
<span class="n">summary_performances_rf</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AUC ROC</th>
      <th>Average precision</th>
      <th>Card Precision@100</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Best estimated parameters</th>
      <td>100/20</td>
      <td>100/20</td>
      <td>100/20</td>
    </tr>
    <tr>
      <th>Validation performance</th>
      <td>0.88+/-0.01</td>
      <td>0.694+/-0.02</td>
      <td>0.289+/-0.02</td>
    </tr>
    <tr>
      <th>Test performance</th>
      <td>0.87+/-0.02</td>
      <td>0.678+/-0.01</td>
      <td>0.299+/-0.01</td>
    </tr>
    <tr>
      <th>Optimal parameters</th>
      <td>100/10</td>
      <td>100/20</td>
      <td>100/10</td>
    </tr>
    <tr>
      <th>Optimal test performance</th>
      <td>0.875+/-0.01</td>
      <td>0.678+/-0.01</td>
      <td>0.303+/-0.01</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The best performances are obtained with forests containing 100 trees, with a maximum depth of 10 or 20. The optimal parameters differ from the best estimated parameters for the AUC and CP&#64;100. The difference in terms of performances is however low, and the best estimated parameters can be considered close to the optimal ones.</p>
<p>The visualization of the performances as a function of the model parameters is trickier since two parameters are varied. Let us first fix the number of trees, and then vary the maximum tree depth.</p>
<p>Fixing the number of trees to 100, we get:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">performances_df_rf_fixed_number_of_trees</span><span class="o">=</span><span class="n">performances_df_rf</span><span class="p">[</span><span class="n">performances_df_rf</span><span class="p">[</span><span class="s2">&quot;Parameters summary&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;100&quot;</span><span class="p">)]</span>

<span class="n">summary_performances_fixed_number_of_trees</span><span class="o">=</span><span class="n">get_summary_performances</span><span class="p">(</span><span class="n">performances_df_rf_fixed_number_of_trees</span><span class="p">,</span> <span class="n">parameter_column_name</span><span class="o">=</span><span class="s2">&quot;Parameters summary&quot;</span><span class="p">)</span>

<span class="n">get_performances_plots</span><span class="p">(</span><span class="n">performances_df_rf_fixed_number_of_trees</span><span class="p">,</span> 
                       <span class="n">performance_metrics_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">,</span> <span class="s1">&#39;Average precision&#39;</span><span class="p">,</span> <span class="s1">&#39;Card Precision@100&#39;</span><span class="p">],</span> 
                       <span class="n">expe_type_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Test&#39;</span><span class="p">,</span><span class="s1">&#39;Validation&#39;</span><span class="p">],</span> <span class="n">expe_type_color_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;#008000&#39;</span><span class="p">,</span><span class="s1">&#39;#FF0000&#39;</span><span class="p">],</span>
                       <span class="n">parameter_name</span><span class="o">=</span><span class="s2">&quot;Number of trees/Maximum tree depth&quot;</span><span class="p">,</span>
                       <span class="n">summary_performances</span><span class="o">=</span><span class="n">summary_performances_fixed_number_of_trees</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ModelSelection_34_0.png" src="../_images/ModelSelection_34_0.png" />
</div>
</div>
<p>A maximum tree depth of 5 provides the lowest peformances. Performances increase with maximum tree depth, until a tree depth of 10 to 20 where they reach a plateau then slightly decrease.</p>
<p>Let us then fix the maximum tree depth, and the vary the number of estimators. Fixing the maximum tree depth to 20, we get:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">performances_df_rf_fixed_max_tree_depth</span><span class="o">=</span><span class="n">performances_df_rf</span><span class="p">[</span><span class="n">performances_df_rf</span><span class="p">[</span><span class="s2">&quot;Parameters summary&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;20&quot;</span><span class="p">)]</span>

<span class="n">summary_performances_fixed_max_tree_depth</span><span class="o">=</span><span class="n">get_summary_performances</span><span class="p">(</span><span class="n">performances_df_rf_fixed_max_tree_depth</span><span class="p">,</span> <span class="n">parameter_column_name</span><span class="o">=</span><span class="s2">&quot;Parameters summary&quot;</span><span class="p">)</span>

<span class="n">get_performances_plots</span><span class="p">(</span><span class="n">performances_df_rf_fixed_max_tree_depth</span><span class="p">,</span> 
                       <span class="n">performance_metrics_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">,</span> <span class="s1">&#39;Average precision&#39;</span><span class="p">,</span> <span class="s1">&#39;Card Precision@100&#39;</span><span class="p">],</span> 
                       <span class="n">expe_type_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Test&#39;</span><span class="p">,</span><span class="s1">&#39;Validation&#39;</span><span class="p">],</span> <span class="n">expe_type_color_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;#008000&#39;</span><span class="p">,</span><span class="s1">&#39;#FF0000&#39;</span><span class="p">],</span>
                       <span class="n">parameter_name</span><span class="o">=</span><span class="s2">&quot;Number of trees/Maximum tree depth&quot;</span><span class="p">,</span>
                       <span class="n">summary_performances</span><span class="o">=</span><span class="n">summary_performances_fixed_max_tree_depth</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ModelSelection_36_0.png" src="../_images/ModelSelection_36_0.png" />
</div>
</div>
<p>For all performance metrics, the common trend is an increase in performances as the number of trees is increased. The added performance gains however decrease with the number of added trees.</p>
<p>It is worth noting that the execution times for training random forests linearly increases with the number of trees. This can be illustrated by plotting the execution times as a function of the number of trees.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the performance plot for a single performance metric</span>
<span class="k">def</span> <span class="nf">get_execution_times_plot</span><span class="p">(</span><span class="n">performances_df</span><span class="p">,</span>
                             <span class="n">title</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
                             <span class="n">parameter_name</span><span class="o">=</span><span class="s2">&quot;Tree maximum depth&quot;</span><span class="p">):</span>
    
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
    
    <span class="c1"># Plot data on graph</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters summary&#39;</span><span class="p">],</span> <span class="n">performances_df</span><span class="p">[</span><span class="s2">&quot;Execution time&quot;</span><span class="p">],</span> 
            <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
        
    <span class="c1"># Set title, and x and y axes labels</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span> <span class="o">=</span> <span class="n">parameter_name</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Execution time (seconds)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">get_execution_times_plot</span><span class="p">(</span><span class="n">performances_df_rf_fixed_max_tree_depth</span><span class="p">,</span> 
                         <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Execution times with varying </span><span class="se">\n</span><span class="s2"> number of trees&quot;</span><span class="p">,</span>
                         <span class="n">parameter_name</span><span class="o">=</span><span class="s2">&quot;Number of trees/Maximum tree depth&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ModelSelection_39_0.png" src="../_images/ModelSelection_39_0.png" />
</div>
</div>
<p>The execution times also increases with the maximum tree depth, as illustrated below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">get_execution_times_plot</span><span class="p">(</span><span class="n">performances_df_rf_fixed_number_of_trees</span><span class="p">,</span> 
                         <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Execution times with varying </span><span class="se">\n</span><span class="s2"> maximum tree depth&quot;</span><span class="p">,</span>
                         <span class="n">parameter_name</span><span class="o">=</span><span class="s2">&quot;Number of trees/Maximum tree depth&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ModelSelection_41_0.png" src="../_images/ModelSelection_41_0.png" />
</div>
</div>
<p>All in all, the model selection procedure above took about 10 minutes to complete on one core, although only a small number of parameter combinations were tested (12 in total: 4 different parameters for the maximum tree depth, and 3 different parameters for the number of trees).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total execution time for the model selection procedure: &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">execution_time_rf</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">+</span><span class="s2">&quot;s&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total execution time for the model selection procedure: 627.54s
</pre></div>
</div>
</div>
</div>
<p>This toy example illustrates the trade-off between performance and computation times in the search for optimal parameters. Computational resources are usually constrained, and one must carefully consider which hyperparameter combinations can be tested given the available resources.</p>
</div>
<div class="section" id="xgboost">
<h3><span class="section-number">3.2.3. </span>XGBoost<a class="headerlink" href="#xgboost" title="Permalink to this headline">¶</a></h3>
<p>XGBoost is a powerful learning algorithm whose tuning however relies <a class="reference external" href="https://xgboost.readthedocs.io/en/latest/python/python_api.html">on many hyperparameters</a>. The most important ones are arguably the tree maximum depth (<code class="docutils literal notranslate"><span class="pre">max_depth</span></code>), the number of trees (<code class="docutils literal notranslate"><span class="pre">n_estimtors</span></code>), and the learning rate (<code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>). By default, the maximum tree depth is set to 2, the number of trees to 100, and the learning rate to 0.1. Let us try other combinations, with <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> in the set [2,3,5], <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> in the set [25,10,100], and <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> in the set [0.05, 0.1].</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">classifier</span> <span class="o">=</span> <span class="n">xgboost</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">()</span>

<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;clf__max_depth&#39;</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="s1">&#39;clf__n_estimators&#39;</span><span class="p">:[</span><span class="mi">25</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">],</span> <span class="s1">&#39;clf__learning_rate&#39;</span><span class="p">:[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
              <span class="s1">&#39;clf__random_state&#39;</span><span class="p">:[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;clf__n_jobs&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;clf__verbosity&#39;</span><span class="p">:[</span><span class="mi">0</span><span class="p">]}</span>

<span class="n">start_time</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">performances_df</span><span class="o">=</span><span class="n">model_selection_wrapper</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> 
                                        <span class="n">input_features</span><span class="p">,</span> <span class="n">output_feature</span><span class="p">,</span>
                                        <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> 
                                        <span class="n">start_date_training_for_valid</span><span class="p">,</span>
                                        <span class="n">start_date_training_for_test</span><span class="p">,</span>
                                        <span class="n">n_folds</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span>
                                        <span class="n">delta_train</span><span class="o">=</span><span class="n">delta_train</span><span class="p">,</span> 
                                        <span class="n">delta_delay</span><span class="o">=</span><span class="n">delta_delay</span><span class="p">,</span> 
                                        <span class="n">delta_assessment</span><span class="o">=</span><span class="n">delta_assessment</span><span class="p">,</span>
                                        <span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="n">performance_metrics_list_grid</span><span class="p">,</span>
                                        <span class="n">performance_metrics_list</span><span class="o">=</span><span class="n">performance_metrics_list</span><span class="p">,</span>
                                        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">execution_time_boosting</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start_time</span>

<span class="n">parameters_dict</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters&#39;</span><span class="p">])</span>
<span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters summary&#39;</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;clf__n_estimators&#39;</span><span class="p">])</span><span class="o">+</span>
                                   <span class="s1">&#39;/&#39;</span><span class="o">+</span>
                                   <span class="nb">str</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;clf__learning_rate&#39;</span><span class="p">])</span><span class="o">+</span>
                                   <span class="s1">&#39;/&#39;</span><span class="o">+</span>
                                   <span class="nb">str</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;clf__max_depth&#39;</span><span class="p">])</span>
                                   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">))]</span>

<span class="c1"># Rename to performances_df_xgboost for model performance comparison at the end of this notebook</span>
<span class="n">performances_df_xgboost</span><span class="o">=</span><span class="n">performances_df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">performances_df_xgboost</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AUC ROC Test</th>
      <th>AUC ROC Test Std</th>
      <th>Average precision Test</th>
      <th>Average precision Test Std</th>
      <th>Card Precision@100 Test</th>
      <th>Card Precision@100 Test Std</th>
      <th>Parameters</th>
      <th>Execution time</th>
      <th>AUC ROC Validation</th>
      <th>AUC ROC Validation Std</th>
      <th>Average precision Validation</th>
      <th>Average precision Validation Std</th>
      <th>Card Precision@100 Validation</th>
      <th>Card Precision@100 Validation Std</th>
      <th>Parameters summary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.804691</td>
      <td>0.014233</td>
      <td>0.588738</td>
      <td>0.027855</td>
      <td>0.277143</td>
      <td>0.012080</td>
      <td>{'clf__learning_rate': 0.05, 'clf__max_depth':...</td>
      <td>1.381555</td>
      <td>0.800513</td>
      <td>0.014902</td>
      <td>0.582041</td>
      <td>0.018621</td>
      <td>0.263929</td>
      <td>0.012263</td>
      <td>25/0.05/2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.830872</td>
      <td>0.010601</td>
      <td>0.622804</td>
      <td>0.021647</td>
      <td>0.295714</td>
      <td>0.015152</td>
      <td>{'clf__learning_rate': 0.05, 'clf__max_depth':...</td>
      <td>2.414702</td>
      <td>0.815454</td>
      <td>0.009721</td>
      <td>0.608627</td>
      <td>0.021724</td>
      <td>0.275357</td>
      <td>0.013339</td>
      <td>50/0.05/2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.848894</td>
      <td>0.011078</td>
      <td>0.637512</td>
      <td>0.017503</td>
      <td>0.299286</td>
      <td>0.014304</td>
      <td>{'clf__learning_rate': 0.05, 'clf__max_depth':...</td>
      <td>4.477899</td>
      <td>0.839563</td>
      <td>0.006613</td>
      <td>0.628430</td>
      <td>0.024998</td>
      <td>0.278929</td>
      <td>0.013901</td>
      <td>100/0.05/2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.820873</td>
      <td>0.007643</td>
      <td>0.618053</td>
      <td>0.020612</td>
      <td>0.288929</td>
      <td>0.010708</td>
      <td>{'clf__learning_rate': 0.05, 'clf__max_depth':...</td>
      <td>1.724567</td>
      <td>0.811389</td>
      <td>0.011432</td>
      <td>0.605400</td>
      <td>0.026931</td>
      <td>0.271786</td>
      <td>0.014441</td>
      <td>25/0.05/3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.833103</td>
      <td>0.012269</td>
      <td>0.636696</td>
      <td>0.023064</td>
      <td>0.296071</td>
      <td>0.014859</td>
      <td>{'clf__learning_rate': 0.05, 'clf__max_depth':...</td>
      <td>3.526706</td>
      <td>0.828770</td>
      <td>0.008527</td>
      <td>0.619382</td>
      <td>0.025261</td>
      <td>0.277857</td>
      <td>0.014196</td>
      <td>50/0.05/3</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.864374</td>
      <td>0.006577</td>
      <td>0.666651</td>
      <td>0.012084</td>
      <td>0.302143</td>
      <td>0.012717</td>
      <td>{'clf__learning_rate': 0.05, 'clf__max_depth':...</td>
      <td>9.786538</td>
      <td>0.862599</td>
      <td>0.003400</td>
      <td>0.651390</td>
      <td>0.031014</td>
      <td>0.281786</td>
      <td>0.014962</td>
      <td>100/0.05/3</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.828379</td>
      <td>0.009684</td>
      <td>0.627986</td>
      <td>0.020924</td>
      <td>0.292143</td>
      <td>0.011845</td>
      <td>{'clf__learning_rate': 0.05, 'clf__max_depth':...</td>
      <td>2.709496</td>
      <td>0.821080</td>
      <td>0.012536</td>
      <td>0.610315</td>
      <td>0.017708</td>
      <td>0.275714</td>
      <td>0.015320</td>
      <td>25/0.05/5</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.840545</td>
      <td>0.010335</td>
      <td>0.636732</td>
      <td>0.026156</td>
      <td>0.293571</td>
      <td>0.013646</td>
      <td>{'clf__learning_rate': 0.05, 'clf__max_depth':...</td>
      <td>5.801920</td>
      <td>0.831552</td>
      <td>0.012443</td>
      <td>0.634336</td>
      <td>0.028856</td>
      <td>0.277500</td>
      <td>0.016487</td>
      <td>50/0.05/5</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.871393</td>
      <td>0.016108</td>
      <td>0.685460</td>
      <td>0.012231</td>
      <td>0.303571</td>
      <td>0.011451</td>
      <td>{'clf__learning_rate': 0.05, 'clf__max_depth':...</td>
      <td>9.421408</td>
      <td>0.873190</td>
      <td>0.004527</td>
      <td>0.693422</td>
      <td>0.018965</td>
      <td>0.287857</td>
      <td>0.015600</td>
      <td>100/0.05/5</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.830388</td>
      <td>0.009841</td>
      <td>0.621413</td>
      <td>0.021088</td>
      <td>0.295714</td>
      <td>0.015152</td>
      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': ...</td>
      <td>1.321278</td>
      <td>0.815454</td>
      <td>0.009723</td>
      <td>0.608477</td>
      <td>0.021612</td>
      <td>0.275357</td>
      <td>0.013339</td>
      <td>25/0.1/2</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.848309</td>
      <td>0.010490</td>
      <td>0.637862</td>
      <td>0.017787</td>
      <td>0.299286</td>
      <td>0.014304</td>
      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': ...</td>
      <td>2.329923</td>
      <td>0.839086</td>
      <td>0.006005</td>
      <td>0.628894</td>
      <td>0.023866</td>
      <td>0.278929</td>
      <td>0.015629</td>
      <td>50/0.1/2</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.871571</td>
      <td>0.014418</td>
      <td>0.680005</td>
      <td>0.009581</td>
      <td>0.303929</td>
      <td>0.013339</td>
      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': ...</td>
      <td>4.463066</td>
      <td>0.875828</td>
      <td>0.005009</td>
      <td>0.689009</td>
      <td>0.016551</td>
      <td>0.290714</td>
      <td>0.015988</td>
      <td>100/0.1/2</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.833094</td>
      <td>0.012257</td>
      <td>0.635603</td>
      <td>0.022225</td>
      <td>0.296071</td>
      <td>0.014859</td>
      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': ...</td>
      <td>1.774995</td>
      <td>0.825157</td>
      <td>0.009026</td>
      <td>0.617990</td>
      <td>0.025069</td>
      <td>0.278214</td>
      <td>0.015563</td>
      <td>25/0.1/3</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.864766</td>
      <td>0.006604</td>
      <td>0.666130</td>
      <td>0.012722</td>
      <td>0.301429</td>
      <td>0.013439</td>
      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': ...</td>
      <td>3.213233</td>
      <td>0.863627</td>
      <td>0.003203</td>
      <td>0.651369</td>
      <td>0.030279</td>
      <td>0.280714</td>
      <td>0.014932</td>
      <td>50/0.1/3</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.870728</td>
      <td>0.012343</td>
      <td>0.693917</td>
      <td>0.008547</td>
      <td>0.303929</td>
      <td>0.012305</td>
      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': ...</td>
      <td>5.909937</td>
      <td>0.878438</td>
      <td>0.009221</td>
      <td>0.705235</td>
      <td>0.019756</td>
      <td>0.288214</td>
      <td>0.015694</td>
      <td>100/0.1/3</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.840549</td>
      <td>0.010335</td>
      <td>0.637267</td>
      <td>0.025976</td>
      <td>0.293929</td>
      <td>0.014228</td>
      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': ...</td>
      <td>2.918710</td>
      <td>0.832045</td>
      <td>0.011923</td>
      <td>0.634660</td>
      <td>0.028241</td>
      <td>0.277143</td>
      <td>0.016690</td>
      <td>25/0.1/5</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.870980</td>
      <td>0.016694</td>
      <td>0.686214</td>
      <td>0.012601</td>
      <td>0.304286</td>
      <td>0.012164</td>
      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': ...</td>
      <td>6.725632</td>
      <td>0.870487</td>
      <td>0.002778</td>
      <td>0.693645</td>
      <td>0.018728</td>
      <td>0.287500</td>
      <td>0.016331</td>
      <td>50/0.1/5</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.872081</td>
      <td>0.010353</td>
      <td>0.691773</td>
      <td>0.010572</td>
      <td>0.300357</td>
      <td>0.012469</td>
      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': ...</td>
      <td>13.230606</td>
      <td>0.886075</td>
      <td>0.004126</td>
      <td>0.707456</td>
      <td>0.017731</td>
      <td>0.287500</td>
      <td>0.016016</td>
      <td>100/0.1/5</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">get_summary_performances</span></code> function gives the summary of the best parameters and corresponding performances.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary_performances_xgboost</span><span class="o">=</span><span class="n">get_summary_performances</span><span class="p">(</span><span class="n">performances_df_xgboost</span><span class="p">,</span> <span class="n">parameter_column_name</span><span class="o">=</span><span class="s2">&quot;Parameters summary&quot;</span><span class="p">)</span>
<span class="n">summary_performances_xgboost</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AUC ROC</th>
      <th>Average precision</th>
      <th>Card Precision@100</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Best estimated parameters</th>
      <td>100/0.1/5</td>
      <td>100/0.1/5</td>
      <td>100/0.1/2</td>
    </tr>
    <tr>
      <th>Validation performance</th>
      <td>0.886+/-0.0</td>
      <td>0.707+/-0.02</td>
      <td>0.291+/-0.02</td>
    </tr>
    <tr>
      <th>Test performance</th>
      <td>0.872+/-0.01</td>
      <td>0.692+/-0.01</td>
      <td>0.304+/-0.01</td>
    </tr>
    <tr>
      <th>Optimal parameters</th>
      <td>100/0.1/5</td>
      <td>100/0.1/3</td>
      <td>50/0.1/5</td>
    </tr>
    <tr>
      <th>Optimal test performance</th>
      <td>0.872+/-0.01</td>
      <td>0.694+/-0.01</td>
      <td>0.304+/-0.01</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The best parameters obtained by validation are the same for ROC AUC, and slightly differ for the average precision and CP&#64;100. The corresponding test performances are however on par.</p>
<p>Let us plot the performances as a function of the maximum tree depth, for a number of trees set to 100. Increasing the maximum tree depth does not clearly affect the performances. It slightly increases performances for AUC ROC and AP, but slightly decreases it for CP&#64;100.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">performances_df_xgboost_fixed_number_of_trees</span><span class="o">=</span><span class="n">performances_df_xgboost</span><span class="p">[</span><span class="n">performances_df_xgboost</span><span class="p">[</span><span class="s2">&quot;Parameters summary&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;100/0.1&quot;</span><span class="p">)]</span>

<span class="n">summary_performances_fixed_number_of_trees</span><span class="o">=</span><span class="n">get_summary_performances</span><span class="p">(</span><span class="n">performances_df_xgboost_fixed_number_of_trees</span><span class="p">,</span> <span class="n">parameter_column_name</span><span class="o">=</span><span class="s2">&quot;Parameters summary&quot;</span><span class="p">)</span>

<span class="n">get_performances_plots</span><span class="p">(</span><span class="n">performances_df_xgboost_fixed_number_of_trees</span><span class="p">,</span> 
                       <span class="n">performance_metrics_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">,</span> <span class="s1">&#39;Average precision&#39;</span><span class="p">,</span> <span class="s1">&#39;Card Precision@100&#39;</span><span class="p">],</span> 
                       <span class="n">expe_type_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Test&#39;</span><span class="p">,</span><span class="s1">&#39;Validation&#39;</span><span class="p">],</span> <span class="n">expe_type_color_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;#008000&#39;</span><span class="p">,</span><span class="s1">&#39;#FF0000&#39;</span><span class="p">],</span>
                       <span class="n">parameter_name</span><span class="o">=</span><span class="s2">&quot;Number of trees/Maximum tree depth&quot;</span><span class="p">,</span>
                       <span class="n">summary_performances</span><span class="o">=</span><span class="n">summary_performances_fixed_number_of_trees</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ModelSelection_51_0.png" src="../_images/ModelSelection_51_0.png" />
</div>
</div>
<p>Let us then plot the performances as a function of the number of trees, for a maximum tree depth set to 5.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">performances_df_xgboost_fixed_max_tree_depth</span><span class="o">=</span><span class="n">performances_df_xgboost</span><span class="p">[</span><span class="n">performances_df_xgboost</span><span class="p">[</span><span class="s2">&quot;Parameters summary&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;0.1/5&quot;</span><span class="p">)]</span>

<span class="n">summary_performances_fixed_max_tree_depth</span><span class="o">=</span><span class="n">get_summary_performances</span><span class="p">(</span><span class="n">performances_df_xgboost_fixed_max_tree_depth</span><span class="p">,</span> <span class="n">parameter_column_name</span><span class="o">=</span><span class="s2">&quot;Parameters summary&quot;</span><span class="p">)</span>

<span class="n">get_performances_plots</span><span class="p">(</span><span class="n">performances_df_xgboost_fixed_max_tree_depth</span><span class="p">,</span> 
                       <span class="n">performance_metrics_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">,</span> <span class="s1">&#39;Average precision&#39;</span><span class="p">,</span> <span class="s1">&#39;Card Precision@100&#39;</span><span class="p">],</span> 
                       <span class="n">expe_type_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Test&#39;</span><span class="p">,</span><span class="s1">&#39;Validation&#39;</span><span class="p">],</span> <span class="n">expe_type_color_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;#008000&#39;</span><span class="p">,</span><span class="s1">&#39;#FF0000&#39;</span><span class="p">],</span>
                       <span class="n">parameter_name</span><span class="o">=</span><span class="s2">&quot;Number of trees/Maximum tree depth&quot;</span><span class="p">,</span>
                       <span class="n">summary_performances</span><span class="o">=</span><span class="n">summary_performances_fixed_max_tree_depth</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ModelSelection_53_0.png" src="../_images/ModelSelection_53_0.png" />
</div>
</div>
<p>Increasing the number of trees from 25 to 50 allow to increase the performances for all performance metrics. Adding more trees however only provides slightly higher performances for AUC ROC and AP, and slightly decreases performances for CP&#64;100.</p>
<p>Similar to random forests, increasing the maximum tree depth and the number of trees comes at a cost in terms of execution times. This is illustrated in the two figures below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">get_execution_times_plot</span><span class="p">(</span><span class="n">performances_df_xgboost_fixed_max_tree_depth</span><span class="p">,</span> 
                         <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Execution times with varying </span><span class="se">\n</span><span class="s2"> number of trees&quot;</span><span class="p">,</span>
                         <span class="n">parameter_name</span><span class="o">=</span><span class="s2">&quot;Number of trees/Learning rate/Maximum tree depth&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ModelSelection_55_0.png" src="../_images/ModelSelection_55_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">get_execution_times_plot</span><span class="p">(</span><span class="n">performances_df_xgboost_fixed_number_of_trees</span><span class="p">,</span> 
                         <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Execution times with varying </span><span class="se">\n</span><span class="s2"> maximum tree depth&quot;</span><span class="p">,</span>
                         <span class="n">parameter_name</span><span class="o">=</span><span class="s2">&quot;Number of trees/Learning rate/Maximum tree depth&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ModelSelection_56_0.png" src="../_images/ModelSelection_56_0.png" />
</div>
</div>
<p>The total execution time was more than 10 minutes using one core.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total execution time for the model selection procedure: &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">execution_time_boosting</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">+</span><span class="s2">&quot;s&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total execution time for the model selection procedure: 666.28s
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="comparison-of-model-performances">
<h2><span class="section-number">3.3. </span>Comparison of model performances<a class="headerlink" href="#comparison-of-model-performances" title="Permalink to this headline">¶</a></h2>
<p>The previous section detailed the performances of different model classes. Let us compare these performances in order to determine which model class provides the best performances.</p>
<p>For each model class, let us retrieve the performance for three types of parameters:</p>
<ul class="simple">
<li><p>Default parameters: Default parameters that <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> gives to a model class. The default parameters for each model class are:</p>
<ul>
<li><p>Decision tree: <code class="docutils literal notranslate"><span class="pre">max_depth=None</span></code>.</p></li>
<li><p>Logistic regression: <code class="docutils literal notranslate"><span class="pre">C=1</span></code>.</p></li>
<li><p>Random forest: <code class="docutils literal notranslate"><span class="pre">n_estimators=100</span></code>, <code class="docutils literal notranslate"><span class="pre">max_depth=None</span></code>.</p></li>
<li><p>XGBoost: <code class="docutils literal notranslate"><span class="pre">n_estimators=100</span></code>, <code class="docutils literal notranslate"><span class="pre">max_depth=2</span></code>, <code class="docutils literal notranslate"><span class="pre">learning_rate=0.1</span></code>.</p></li>
</ul>
</li>
<li><p>Best estimated parameters: Parameters that provide the highest performances on the validation set.</p></li>
<li><p>Optimal parameters: Parameters that provide the highest performances on the test set.</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">model_selection_performances</span></code> function below takes a dictionary of performance DataFrames and a performance metric, and retrieves the corresponding performances (mean together with standard deviation).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">performances_df_dictionary</span><span class="o">=</span><span class="p">{</span>
    <span class="s2">&quot;Decision Tree&quot;</span><span class="p">:</span> <span class="n">performances_df_dt</span><span class="p">,</span>
    <span class="s2">&quot;Logstic Regression&quot;</span><span class="p">:</span> <span class="n">performances_df_lr</span><span class="p">,</span>
    <span class="s2">&quot;Random Forest&quot;</span><span class="p">:</span> <span class="n">performances_df_rf</span><span class="p">,</span>
    <span class="s2">&quot;XGBoost&quot;</span><span class="p">:</span> <span class="n">performances_df_xgboost</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">model_selection_performances</span><span class="p">(</span><span class="n">performances_df_dictionary</span><span class="p">,</span>
                                 <span class="n">performance_metric</span><span class="o">=</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">):</span>
    
    <span class="c1"># Note: max_depth of 50 is similar to None</span>
    <span class="n">default_parameters_dictionary</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;Decision Tree&quot;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
        <span class="s2">&quot;Logstic Regression&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s2">&quot;Random Forest&quot;</span><span class="p">:</span> <span class="s2">&quot;100/50&quot;</span><span class="p">,</span>
        <span class="s2">&quot;XGBoost&quot;</span><span class="p">:</span> <span class="s2">&quot;100/0.1/2&quot;</span>
    <span class="p">}</span>
    
    <span class="n">mean_performances_dictionary</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;Default parameters&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;Best validation parameters&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;Optimal parameters&quot;</span><span class="p">:</span> <span class="p">[]</span>
    <span class="p">}</span>
    
    <span class="n">std_performances_dictionary</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;Default parameters&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;Best validation parameters&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;Optimal parameters&quot;</span><span class="p">:</span> <span class="p">[]</span>
    <span class="p">}</span>
    
    <span class="c1"># For each model class</span>
    <span class="k">for</span> <span class="n">model_class</span><span class="p">,</span> <span class="n">performances_df</span> <span class="ow">in</span> <span class="n">performances_df_dictionary</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        
        <span class="c1"># Get the performances for the default paramaters</span>
        <span class="n">default_performances</span><span class="o">=</span><span class="n">performances_df</span><span class="p">[</span><span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters summary&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">default_parameters_dictionary</span><span class="p">[</span><span class="n">model_class</span><span class="p">]]</span>
        <span class="n">default_performances</span><span class="o">=</span><span class="n">default_performances</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">decimals</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
        
        <span class="n">mean_performances_dictionary</span><span class="p">[</span><span class="s2">&quot;Default parameters&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">default_performances</span><span class="p">[</span><span class="n">performance_metric</span><span class="o">+</span><span class="s2">&quot; Test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">std_performances_dictionary</span><span class="p">[</span><span class="s2">&quot;Default parameters&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">default_performances</span><span class="p">[</span><span class="n">performance_metric</span><span class="o">+</span><span class="s2">&quot; Test Std&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        
        <span class="c1"># Get the performances for the best estimated parameters</span>
        <span class="n">performances_summary</span><span class="o">=</span><span class="n">get_summary_performances</span><span class="p">(</span><span class="n">performances_df</span><span class="p">,</span> <span class="n">parameter_column_name</span><span class="o">=</span><span class="s2">&quot;Parameters summary&quot;</span><span class="p">)</span>
        <span class="n">mean_std_performances</span><span class="o">=</span><span class="n">performances_summary</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="s2">&quot;Test performance&quot;</span><span class="p">]][</span><span class="n">performance_metric</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">mean_std_performances</span><span class="o">=</span><span class="n">mean_std_performances</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;+/-&quot;</span><span class="p">)</span>
        <span class="n">mean_performances_dictionary</span><span class="p">[</span><span class="s2">&quot;Best validation parameters&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">mean_std_performances</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">std_performances_dictionary</span><span class="p">[</span><span class="s2">&quot;Best validation parameters&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">mean_std_performances</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        
        <span class="c1"># Get the performances for the boptimal parameters</span>
        <span class="n">mean_std_performances</span><span class="o">=</span><span class="n">performances_summary</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="s2">&quot;Optimal test performance&quot;</span><span class="p">]][</span><span class="n">performance_metric</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">mean_std_performances</span><span class="o">=</span><span class="n">mean_std_performances</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;+/-&quot;</span><span class="p">)</span>
        <span class="n">mean_performances_dictionary</span><span class="p">[</span><span class="s2">&quot;Optimal parameters&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">mean_std_performances</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">std_performances_dictionary</span><span class="p">[</span><span class="s2">&quot;Optimal parameters&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">mean_std_performances</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        
    <span class="c1"># Return the mean performances and their standard deviations    </span>
    <span class="k">return</span> <span class="p">(</span><span class="n">mean_performances_dictionary</span><span class="p">,</span><span class="n">std_performances_dictionary</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>For examples, executing the function for the AUC ROC metric returns:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_selection_performances</span><span class="p">(</span><span class="n">performances_df_dictionary</span><span class="p">,</span>
                             <span class="n">performance_metric</span><span class="o">=</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>({&#39;Default parameters&#39;: [0.797, 0.868, 0.87, 0.872],
  &#39;Best validation parameters&#39;: [0.797, 0.868, 0.87, 0.872],
  &#39;Optimal parameters&#39;: [0.813, 0.868, 0.875, 0.872]},
 {&#39;Default parameters&#39;: [0.005, 0.015, 0.014, 0.014],
  &#39;Best validation parameters&#39;: [0.01, 0.02, 0.02, 0.01],
  &#39;Optimal parameters&#39;: [0.01, 0.02, 0.01, 0.01]})
</pre></div>
</div>
</div>
</div>
<p>For better visualization, let us plot the performances for the four model classes and for each performance metric as bar charts. The implementation is provided with the <code class="docutils literal notranslate"><span class="pre">get_model_selection_performance_plot</span></code> and <code class="docutils literal notranslate"><span class="pre">get_model_selection_performances_plots</span></code> below.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the performance plot for a single performance metric</span>
<span class="k">def</span> <span class="nf">get_model_selection_performance_plot</span><span class="p">(</span><span class="n">performances_df_dictionary</span><span class="p">,</span> 
                                         <span class="n">ax</span><span class="p">,</span> 
                                         <span class="n">performance_metric</span><span class="p">,</span>
                                         <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
                                        <span class="p">):</span>
    
    
    <span class="p">(</span><span class="n">mean_performances_dictionary</span><span class="p">,</span><span class="n">std_performances_dictionary</span><span class="p">)</span> <span class="o">=</span> \
        <span class="n">model_selection_performances</span><span class="p">(</span><span class="n">performances_df_dictionary</span><span class="o">=</span><span class="n">performances_df_dictionary</span><span class="p">,</span>
                                     <span class="n">performance_metric</span><span class="o">=</span><span class="n">performance_metric</span><span class="p">)</span>
    
    
    <span class="n">model_classes</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">performances_df_dictionary</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    
    <span class="c1"># width of the bars</span>
    <span class="n">barWidth</span> <span class="o">=</span> <span class="mf">0.3</span>
    <span class="c1"># The x position of bars</span>
    <span class="n">r1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model_classes</span><span class="p">))</span>
    <span class="n">r2</span> <span class="o">=</span> <span class="n">r1</span><span class="o">+</span><span class="n">barWidth</span>
    <span class="n">r3</span> <span class="o">=</span> <span class="n">r1</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">barWidth</span>
    
    <span class="c1"># Create Default parameters bars (Orange)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">r1</span><span class="p">,</span> <span class="n">mean_performances_dictionary</span><span class="p">[</span><span class="s1">&#39;Default parameters&#39;</span><span class="p">],</span> 
           <span class="n">width</span> <span class="o">=</span> <span class="n">barWidth</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;#CA8035&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> 
           <span class="n">yerr</span><span class="o">=</span><span class="n">std_performances_dictionary</span><span class="p">[</span><span class="s1">&#39;Default parameters&#39;</span><span class="p">],</span> <span class="n">capsize</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Default parameters&#39;</span><span class="p">)</span>
 
    <span class="c1"># Create Best validation parameters bars (Red)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">r2</span><span class="p">,</span> <span class="n">mean_performances_dictionary</span><span class="p">[</span><span class="s1">&#39;Best validation parameters&#39;</span><span class="p">],</span> 
           <span class="n">width</span> <span class="o">=</span> <span class="n">barWidth</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;#008000&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> 
           <span class="n">yerr</span><span class="o">=</span><span class="n">std_performances_dictionary</span><span class="p">[</span><span class="s1">&#39;Best validation parameters&#39;</span><span class="p">],</span> <span class="n">capsize</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Best validation parameters&#39;</span><span class="p">)</span>

    <span class="c1"># Create Optimal parameters bars (Green)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">r3</span><span class="p">,</span> <span class="n">mean_performances_dictionary</span><span class="p">[</span><span class="s1">&#39;Optimal parameters&#39;</span><span class="p">],</span> 
           <span class="n">width</span> <span class="o">=</span> <span class="n">barWidth</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;#2F4D7E&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> 
           <span class="n">yerr</span><span class="o">=</span><span class="n">std_performances_dictionary</span><span class="p">[</span><span class="s1">&#39;Optimal parameters&#39;</span><span class="p">],</span> <span class="n">capsize</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Optimal parameters&#39;</span><span class="p">)</span>
 

    <span class="c1"># Set title, and x and y axes labels</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">ylim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">ylim</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">r2</span><span class="o">+</span><span class="n">barWidth</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">model_classes</span><span class="p">,</span> <span class="n">rotation</span> <span class="o">=</span> <span class="mi">45</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">performance_metric</span><span class="o">+</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Model class&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">performance_metric</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_model_selection_performances_plots</span><span class="p">(</span><span class="n">performances_df_dictionary</span><span class="p">,</span> 
                                           <span class="n">performance_metrics_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">,</span> <span class="s1">&#39;Average precision&#39;</span><span class="p">,</span> <span class="s1">&#39;Card Precision@100&#39;</span><span class="p">]):</span>
    
    <span class="c1"># Create as many graphs as there are performance metrics to display</span>
    <span class="n">n_performance_metrics</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">performance_metrics_list</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_performance_metrics</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="o">*</span><span class="n">n_performance_metrics</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
    
    <span class="n">parameter_types</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Default parameters&#39;</span><span class="p">,</span><span class="s1">&#39;Best validation parameters&#39;</span><span class="p">,</span><span class="s1">&#39;Optimal parameters&#39;</span><span class="p">]</span>
    
    <span class="n">ylim_list</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.6</span><span class="p">,</span><span class="mf">0.9</span><span class="p">],[</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.8</span><span class="p">],[</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.35</span><span class="p">]]</span>
    
    <span class="c1"># Plot performance metric for each metric in performance_metrics_list</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_performance_metrics</span><span class="p">):</span>
    
        <span class="n">get_model_selection_performance_plot</span><span class="p">(</span><span class="n">performances_df_dictionary</span><span class="p">,</span> 
                                             <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> 
                                             <span class="n">performance_metrics_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                                             <span class="n">ylim</span><span class="o">=</span><span class="n">ylim_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                                            <span class="p">)</span>
    
    <span class="n">ax</span><span class="p">[</span><span class="n">n_performance_metrics</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">,</span> 
                                       <span class="n">labels</span><span class="o">=</span><span class="n">parameter_types</span><span class="p">,</span> 
                                       <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.05</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                                       <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Parameter type&quot;</span><span class="p">,</span>
                                       <span class="n">prop</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="mi">12</span><span class="p">},</span>
                                       <span class="n">title_fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> 
                        <span class="n">hspace</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This gives:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">get_model_selection_performances_plots</span><span class="p">(</span><span class="n">performances_df_dictionary</span><span class="p">,</span> 
                                       <span class="n">performance_metrics_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">,</span> <span class="s1">&#39;Average precision&#39;</span><span class="p">,</span> <span class="s1">&#39;Card Precision@100&#39;</span><span class="p">])</span>
    
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ModelSelection_68_0.png" src="../_images/ModelSelection_68_0.png" />
</div>
</div>
<p>On this simulated dataset, XGBoost provides the highest performances, followed by random forest, logistic regression, and finally decision trees which have the lowest performances. The gap in terms of performance is most visible with the average precision metric. The performances of logistic regression, random forest, and XGBoost are very similar in terms of AUC ROC.</p>
<p>Let us plot the total execution times of the model selection procedure for each model class.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">execution_times</span><span class="o">=</span><span class="p">[</span><span class="n">execution_time_dt</span><span class="p">,</span><span class="n">execution_time_lr</span><span class="p">,</span>
                 <span class="n">execution_time_rf</span><span class="p">,</span><span class="n">execution_time_boosting</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span>

<span class="n">fig_model_selection_execution_times_for_each_model_class</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="n">model_classes</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">performances_df_dictionary</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    
<span class="c1"># width of the bars</span>
<span class="n">barWidth</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="c1"># The x position of bars</span>
<span class="n">r1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model_classes</span><span class="p">))</span>
    
<span class="c1"># Create execution times bars</span>
<span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">r1</span><span class="p">,</span> <span class="n">execution_times</span><span class="p">,</span> 
        <span class="n">width</span> <span class="o">=</span> <span class="n">barWidth</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> 
        <span class="n">capsize</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">r1</span><span class="o">+</span><span class="n">barWidth</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">model_classes</span><span class="p">,</span> <span class="n">rotation</span> <span class="o">=</span> <span class="mi">45</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Model selection execution times </span><span class="se">\n</span><span class="s1"> for different model classes&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Model class&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Execution times (s)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig_model_selection_execution_times_for_each_model_class</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ModelSelection_72_0.png" src="../_images/ModelSelection_72_0.png" />
</div>
</div>
<p>The comparison in terms of execution times is mostly qualitative since they depend to a large extent on the number of parameter combinations that were considered in the model selection procedure. It however illustrates that model selection for complex models such as random forests or boosting usually requires more computational resources, since they require tuning a higher number of hyperparameters.</p>
</div>
<div class="section" id="random-search">
<h2><span class="section-number">3.4. </span>Random search<a class="headerlink" href="#random-search" title="Permalink to this headline">¶</a></h2>
<p>Grid search is a widely used strategy for hyperparameter optimization. It however quickly becomes intractable when the number of hyperparameters is high since the number of parameter combinations grows exponentially with the number of parameters.</p>
<p>An alternative to grid search is random search, where random combinations of parameters are assessed for a fixed number of combinations. Besides allowing to limit the number of tested parameter combinations, random combinations have been shown both empirically and theoretically to be more efficient for hyperparameter optimization than grid search <span id="id4">[<a class="reference internal" href="../Chapter_References/bibliography.html#id49"><span>BB12</span></a>]</span>.</p>
<p>The intuition for the efficiency of random search is illustrated in Fig. 3. Essentially, random search allows to more efficiently explore the space of important hyperparameters.</p>
<p><img alt="alt text" src="../_images/random_search.png" /></p>
<div align="center">Fig. 3.  Grid and random search of nine parameter combinations, on a two-parameter space. Performance as a function of parameter's values is given in green (top - important parameter) and yellow (left, unimportant parameter). Grid search only assesses the important parameter for three different values, while random search explores the important parameter for nine different values (Figure taken from {cite}`bergstra2012random`).</div>
<p>The implementation of random search in <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> can be performed by relying on <code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code> instead of <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> in the prequential search. Let us modify the <code class="docutils literal notranslate"><span class="pre">prequential_grid_search</span></code> into a more generic <code class="docutils literal notranslate"><span class="pre">prequential_parameters_search</span></code> function, by adding three new parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">type_search</span></code>: Either ‘grid’ for grid search, or ‘random’ for random search.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_iter</span></code>: Number of iterations (parameter combinations) for the random search.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">random_state</span></code>: Random state for reproducibility of the random search.</p></li>
</ul>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prequential_parameters_search</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span> 
                            <span class="n">classifier</span><span class="p">,</span> 
                            <span class="n">input_features</span><span class="p">,</span> <span class="n">output_feature</span><span class="p">,</span> 
                            <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> 
                            <span class="n">start_date_training</span><span class="p">,</span> 
                            <span class="n">n_folds</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                            <span class="n">expe_type</span><span class="o">=</span><span class="s1">&#39;Test&#39;</span><span class="p">,</span>
                            <span class="n">delta_train</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> 
                            <span class="n">delta_delay</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> 
                            <span class="n">delta_assessment</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
                            <span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">],</span>
                            <span class="n">performance_metrics_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">],</span>
                            <span class="n">type_search</span><span class="o">=</span><span class="s1">&#39;grid&#39;</span><span class="p">,</span>
                            <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                            <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
    
    <span class="n">estimators</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">()),</span> <span class="p">(</span><span class="s1">&#39;clf&#39;</span><span class="p">,</span> <span class="n">classifier</span><span class="p">)]</span>
    <span class="n">pipe</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">estimators</span><span class="p">)</span>
    
    <span class="n">prequential_split_indices</span><span class="o">=</span><span class="n">prequentialSplit</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span>
                                               <span class="n">start_date_training</span><span class="o">=</span><span class="n">start_date_training</span><span class="p">,</span> 
                                               <span class="n">n_folds</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span> 
                                               <span class="n">delta_train</span><span class="o">=</span><span class="n">delta_train</span><span class="p">,</span> 
                                               <span class="n">delta_delay</span><span class="o">=</span><span class="n">delta_delay</span><span class="p">,</span> 
                                               <span class="n">delta_assessment</span><span class="o">=</span><span class="n">delta_assessment</span><span class="p">)</span>
    
    <span class="n">parameters_search</span> <span class="o">=</span> <span class="kc">None</span>
    
    <span class="k">if</span> <span class="n">type_search</span><span class="o">==</span><span class="s2">&quot;grid&quot;</span><span class="p">:</span>
        
        <span class="n">parameters_search</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">model_selection</span><span class="o">.</span><span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">prequential_split_indices</span><span class="p">,</span> 
                                         <span class="n">refit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">type_search</span><span class="o">==</span><span class="s2">&quot;random&quot;</span><span class="p">:</span>
        
        <span class="n">parameters_search</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">model_selection</span><span class="o">.</span><span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">prequential_split_indices</span><span class="p">,</span> 
                                     <span class="n">refit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span><span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>

    
    <span class="n">X</span><span class="o">=</span><span class="n">transactions_df</span><span class="p">[</span><span class="n">input_features</span><span class="p">]</span>
    <span class="n">y</span><span class="o">=</span><span class="n">transactions_df</span><span class="p">[</span><span class="n">output_feature</span><span class="p">]</span>

    <span class="n">parameters_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    
    <span class="n">performances_df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">performance_metrics_list_grid</span><span class="p">)):</span>
        <span class="n">performances_df</span><span class="p">[</span><span class="n">performance_metrics_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="s1">&#39; &#39;</span><span class="o">+</span><span class="n">expe_type</span><span class="p">]</span><span class="o">=</span><span class="n">parameters_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_&#39;</span><span class="o">+</span><span class="n">performance_metrics_list_grid</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
        <span class="n">performances_df</span><span class="p">[</span><span class="n">performance_metrics_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="s1">&#39; &#39;</span><span class="o">+</span><span class="n">expe_type</span><span class="o">+</span><span class="s1">&#39; Std&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">parameters_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;std_test_&#39;</span><span class="o">+</span><span class="n">performance_metrics_list_grid</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>

    <span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">parameters_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]</span>
    <span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Execution time&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">parameters_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_fit_time&#39;</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">performances_df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">model_selection_wrapper</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span> 
                            <span class="n">classifier</span><span class="p">,</span> 
                            <span class="n">input_features</span><span class="p">,</span> <span class="n">output_feature</span><span class="p">,</span>
                            <span class="n">parameters</span><span class="p">,</span> 
                            <span class="n">scoring</span><span class="p">,</span> 
                            <span class="n">start_date_training_for_valid</span><span class="p">,</span>
                            <span class="n">start_date_training_for_test</span><span class="p">,</span>
                            <span class="n">n_folds</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                            <span class="n">delta_train</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> 
                            <span class="n">delta_delay</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> 
                            <span class="n">delta_assessment</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
                            <span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">],</span>
                            <span class="n">performance_metrics_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">],</span>
                            <span class="n">type_search</span><span class="o">=</span><span class="s1">&#39;grid&#39;</span><span class="p">,</span>
                            <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                            <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>

    <span class="c1"># Get performances on the validation set using prequential validation</span>
    <span class="n">performances_df_validation</span><span class="o">=</span><span class="n">prequential_parameters_search</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> 
                            <span class="n">input_features</span><span class="p">,</span> <span class="n">output_feature</span><span class="p">,</span>
                            <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> 
                            <span class="n">start_date_training</span><span class="o">=</span><span class="n">start_date_training_for_valid</span><span class="p">,</span>
                            <span class="n">n_folds</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span>
                            <span class="n">expe_type</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">,</span>
                            <span class="n">delta_train</span><span class="o">=</span><span class="n">delta_train</span><span class="p">,</span> 
                            <span class="n">delta_delay</span><span class="o">=</span><span class="n">delta_delay</span><span class="p">,</span> 
                            <span class="n">delta_assessment</span><span class="o">=</span><span class="n">delta_assessment</span><span class="p">,</span>
                            <span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="n">performance_metrics_list_grid</span><span class="p">,</span>
                            <span class="n">performance_metrics_list</span><span class="o">=</span><span class="n">performance_metrics_list</span><span class="p">,</span>
                            <span class="n">type_search</span><span class="o">=</span><span class="n">type_search</span><span class="p">,</span>
                            <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span>
                            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
                            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">)</span>
    
    <span class="c1"># Get performances on the test set using prequential validation</span>
    <span class="n">performances_df_test</span><span class="o">=</span><span class="n">prequential_parameters_search</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> 
                            <span class="n">input_features</span><span class="p">,</span> <span class="n">output_feature</span><span class="p">,</span>
                            <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> 
                            <span class="n">start_date_training</span><span class="o">=</span><span class="n">start_date_training_for_test</span><span class="p">,</span>
                            <span class="n">n_folds</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span>
                            <span class="n">expe_type</span><span class="o">=</span><span class="s1">&#39;Test&#39;</span><span class="p">,</span>
                            <span class="n">delta_train</span><span class="o">=</span><span class="n">delta_train</span><span class="p">,</span> 
                            <span class="n">delta_delay</span><span class="o">=</span><span class="n">delta_delay</span><span class="p">,</span> 
                            <span class="n">delta_assessment</span><span class="o">=</span><span class="n">delta_assessment</span><span class="p">,</span>
                            <span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="n">performance_metrics_list_grid</span><span class="p">,</span>
                            <span class="n">performance_metrics_list</span><span class="o">=</span><span class="n">performance_metrics_list</span><span class="p">,</span>
                            <span class="n">type_search</span><span class="o">=</span><span class="n">type_search</span><span class="p">,</span>
                            <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span>
                            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
                            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">)</span>
    
    <span class="c1"># Bind the two resulting DataFrames</span>
    <span class="n">performances_df_validation</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Parameters&#39;</span><span class="p">,</span><span class="s1">&#39;Execution time&#39;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">performances_df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">performances_df_test</span><span class="p">,</span><span class="n">performances_df_validation</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># And return as a single DataFrame</span>
    <span class="k">return</span> <span class="n">performances_df</span>
</pre></div>
</div>
</div>
</div>
<p>Let us rerun the model selection for boosting, but using random search, with 10 parameter combinations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">classifier</span> <span class="o">=</span> <span class="n">xgboost</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">()</span>

<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;clf__max_depth&#39;</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="s1">&#39;clf__n_estimators&#39;</span><span class="p">:[</span><span class="mi">25</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">],</span><span class="s1">&#39;clf__learning_rate&#39;</span><span class="p">:[</span><span class="mf">0.05</span><span class="p">,</span><span class="mf">0.1</span><span class="p">],</span>
              <span class="s1">&#39;clf__random_state&#39;</span><span class="p">:[</span><span class="mi">0</span><span class="p">],</span><span class="s1">&#39;clf__n_jobs&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;clf__n_verbosity&#39;</span><span class="p">:[</span><span class="mi">0</span><span class="p">]}</span>

<span class="n">start_time</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">performances_df</span><span class="o">=</span><span class="n">model_selection_wrapper</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> 
                                        <span class="n">input_features</span><span class="p">,</span> <span class="n">output_feature</span><span class="p">,</span>
                                        <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> 
                                        <span class="n">start_date_training_for_valid</span><span class="p">,</span>
                                        <span class="n">start_date_training_for_test</span><span class="p">,</span>
                                        <span class="n">n_folds</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span>
                                        <span class="n">delta_train</span><span class="o">=</span><span class="n">delta_train</span><span class="p">,</span> 
                                        <span class="n">delta_delay</span><span class="o">=</span><span class="n">delta_delay</span><span class="p">,</span> 
                                        <span class="n">delta_assessment</span><span class="o">=</span><span class="n">delta_assessment</span><span class="p">,</span>
                                        <span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="n">performance_metrics_list_grid</span><span class="p">,</span>
                                        <span class="n">performance_metrics_list</span><span class="o">=</span><span class="n">performance_metrics_list</span><span class="p">,</span>
                                        <span class="n">type_search</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">,</span>
                                        <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                        <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">execution_time_boosting_random</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start_time</span>

<span class="n">parameters_dict</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters&#39;</span><span class="p">])</span>
<span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters summary&#39;</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;clf__n_estimators&#39;</span><span class="p">])</span><span class="o">+</span>
                                   <span class="s1">&#39;/&#39;</span><span class="o">+</span>
                                   <span class="nb">str</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;clf__learning_rate&#39;</span><span class="p">])</span><span class="o">+</span>
                                   <span class="s1">&#39;/&#39;</span><span class="o">+</span>
                                   <span class="nb">str</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;clf__max_depth&#39;</span><span class="p">])</span>
                                   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">))]</span>

<span class="c1"># Rename to performances_df_xgboost_random for model performance comparison</span>
<span class="n">performances_df_xgboost_random</span><span class="o">=</span><span class="n">performances_df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">performances_df_xgboost_random</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AUC ROC Test</th>
      <th>AUC ROC Test Std</th>
      <th>Average precision Test</th>
      <th>Average precision Test Std</th>
      <th>Card Precision@100 Test</th>
      <th>Card Precision@100 Test Std</th>
      <th>Parameters</th>
      <th>Execution time</th>
      <th>AUC ROC Validation</th>
      <th>AUC ROC Validation Std</th>
      <th>Average precision Validation</th>
      <th>Average precision Validation Std</th>
      <th>Card Precision@100 Validation</th>
      <th>Card Precision@100 Validation Std</th>
      <th>Parameters summary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.830872</td>
      <td>0.010601</td>
      <td>0.622804</td>
      <td>0.021647</td>
      <td>0.295714</td>
      <td>0.015152</td>
      <td>{'clf__random_state': 0, 'clf__n_verbosity': 0...</td>
      <td>2.743754</td>
      <td>0.815454</td>
      <td>0.009721</td>
      <td>0.608627</td>
      <td>0.021724</td>
      <td>0.275357</td>
      <td>0.013339</td>
      <td>50/0.05/2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.828379</td>
      <td>0.009684</td>
      <td>0.627986</td>
      <td>0.020924</td>
      <td>0.292143</td>
      <td>0.011845</td>
      <td>{'clf__random_state': 0, 'clf__n_verbosity': 0...</td>
      <td>3.059411</td>
      <td>0.821080</td>
      <td>0.012536</td>
      <td>0.610315</td>
      <td>0.017708</td>
      <td>0.275714</td>
      <td>0.015320</td>
      <td>25/0.05/5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.871393</td>
      <td>0.016108</td>
      <td>0.685460</td>
      <td>0.012231</td>
      <td>0.303571</td>
      <td>0.011451</td>
      <td>{'clf__random_state': 0, 'clf__n_verbosity': 0...</td>
      <td>12.370115</td>
      <td>0.873190</td>
      <td>0.004527</td>
      <td>0.693422</td>
      <td>0.018965</td>
      <td>0.287857</td>
      <td>0.015600</td>
      <td>100/0.05/5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.848309</td>
      <td>0.010490</td>
      <td>0.637862</td>
      <td>0.017787</td>
      <td>0.299286</td>
      <td>0.014304</td>
      <td>{'clf__random_state': 0, 'clf__n_verbosity': 0...</td>
      <td>3.169141</td>
      <td>0.839086</td>
      <td>0.006005</td>
      <td>0.628894</td>
      <td>0.023866</td>
      <td>0.278929</td>
      <td>0.015629</td>
      <td>50/0.1/2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.870728</td>
      <td>0.012343</td>
      <td>0.693917</td>
      <td>0.008547</td>
      <td>0.303929</td>
      <td>0.012305</td>
      <td>{'clf__random_state': 0, 'clf__n_verbosity': 0...</td>
      <td>8.901414</td>
      <td>0.878438</td>
      <td>0.009221</td>
      <td>0.705235</td>
      <td>0.019756</td>
      <td>0.288214</td>
      <td>0.015694</td>
      <td>100/0.1/3</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.833103</td>
      <td>0.012269</td>
      <td>0.636696</td>
      <td>0.023064</td>
      <td>0.296071</td>
      <td>0.014859</td>
      <td>{'clf__random_state': 0, 'clf__n_verbosity': 0...</td>
      <td>6.386794</td>
      <td>0.828770</td>
      <td>0.008527</td>
      <td>0.619382</td>
      <td>0.025261</td>
      <td>0.277857</td>
      <td>0.014196</td>
      <td>50/0.05/3</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.848894</td>
      <td>0.011078</td>
      <td>0.637512</td>
      <td>0.017503</td>
      <td>0.299286</td>
      <td>0.014304</td>
      <td>{'clf__random_state': 0, 'clf__n_verbosity': 0...</td>
      <td>6.957635</td>
      <td>0.839563</td>
      <td>0.006613</td>
      <td>0.628430</td>
      <td>0.024998</td>
      <td>0.278929</td>
      <td>0.013901</td>
      <td>100/0.05/2</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.870980</td>
      <td>0.016694</td>
      <td>0.686214</td>
      <td>0.012601</td>
      <td>0.304286</td>
      <td>0.012164</td>
      <td>{'clf__random_state': 0, 'clf__n_verbosity': 0...</td>
      <td>6.018764</td>
      <td>0.870487</td>
      <td>0.002778</td>
      <td>0.693645</td>
      <td>0.018728</td>
      <td>0.287500</td>
      <td>0.016331</td>
      <td>50/0.1/5</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.872081</td>
      <td>0.010353</td>
      <td>0.691773</td>
      <td>0.010572</td>
      <td>0.300357</td>
      <td>0.012469</td>
      <td>{'clf__random_state': 0, 'clf__n_verbosity': 0...</td>
      <td>12.286434</td>
      <td>0.886075</td>
      <td>0.004126</td>
      <td>0.707456</td>
      <td>0.017731</td>
      <td>0.287500</td>
      <td>0.016016</td>
      <td>100/0.1/5</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.830388</td>
      <td>0.009841</td>
      <td>0.621413</td>
      <td>0.021088</td>
      <td>0.295714</td>
      <td>0.015152</td>
      <td>{'clf__random_state': 0, 'clf__n_verbosity': 0...</td>
      <td>1.876480</td>
      <td>0.815454</td>
      <td>0.009723</td>
      <td>0.608477</td>
      <td>0.021612</td>
      <td>0.275357</td>
      <td>0.013339</td>
      <td>25/0.1/2</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">get_summary_performances</span></code> function gives the summary of the best parameters and corresponding performances.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary_performances_xgboost_random</span><span class="o">=</span><span class="n">get_summary_performances</span><span class="p">(</span><span class="n">performances_df_xgboost_random</span><span class="p">,</span> <span class="n">parameter_column_name</span><span class="o">=</span><span class="s2">&quot;Parameters summary&quot;</span><span class="p">)</span>
<span class="n">summary_performances_xgboost_random</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AUC ROC</th>
      <th>Average precision</th>
      <th>Card Precision@100</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Best estimated parameters</th>
      <td>100/0.1/5</td>
      <td>100/0.1/5</td>
      <td>100/0.1/3</td>
    </tr>
    <tr>
      <th>Validation performance</th>
      <td>0.886+/-0.0</td>
      <td>0.707+/-0.02</td>
      <td>0.288+/-0.02</td>
    </tr>
    <tr>
      <th>Test performance</th>
      <td>0.872+/-0.01</td>
      <td>0.692+/-0.01</td>
      <td>0.304+/-0.01</td>
    </tr>
    <tr>
      <th>Optimal parameters</th>
      <td>100/0.1/5</td>
      <td>100/0.1/3</td>
      <td>50/0.1/5</td>
    </tr>
    <tr>
      <th>Optimal test performance</th>
      <td>0.872+/-0.01</td>
      <td>0.694+/-0.01</td>
      <td>0.304+/-0.01</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The performances are essentially the same as those obtained with the grid search.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Performances with grid search</span>
<span class="n">summary_performances_xgboost</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AUC ROC</th>
      <th>Average precision</th>
      <th>Card Precision@100</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Best estimated parameters</th>
      <td>100/0.1/5</td>
      <td>100/0.1/5</td>
      <td>100/0.1/2</td>
    </tr>
    <tr>
      <th>Validation performance</th>
      <td>0.886+/-0.0</td>
      <td>0.707+/-0.02</td>
      <td>0.291+/-0.02</td>
    </tr>
    <tr>
      <th>Test performance</th>
      <td>0.872+/-0.01</td>
      <td>0.692+/-0.01</td>
      <td>0.304+/-0.01</td>
    </tr>
    <tr>
      <th>Optimal parameters</th>
      <td>100/0.1/5</td>
      <td>100/0.1/3</td>
      <td>50/0.1/5</td>
    </tr>
    <tr>
      <th>Optimal test performance</th>
      <td>0.872+/-0.01</td>
      <td>0.694+/-0.01</td>
      <td>0.304+/-0.01</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The execution time was however significantly faster.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total execution time for XGBoost with grid search: &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">execution_time_boosting</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">+</span><span class="s2">&quot;s&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total execution time for XGBoost with random search: &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">execution_time_boosting_random</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">+</span><span class="s2">&quot;s&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total execution time for XGBoost with grid search: 666.28s
Total execution time for XGBoost with random search: 484.81s
</pre></div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Chapter_5_ModelValidationAndSelection"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="ValidationStrategies.html" title="previous page"><span class="section-number">2. </span>Validation strategies</a>
    <a class='right-next' id="next-link" href="Summary.html" title="next page"><span class="section-number">4. </span>Summary</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By <a href="https://mlg.ulb.ac.be/wordpress/">Machine Learning Group (Université Libre de Bruxelles - ULB)</a>.<br/>
        
          <div class="extra_footer">
            <p>
Code released under a <a href="https://www.gnu.org/licenses/gpl-3.0.en.html">GNU GPL v3.0 license</a>. 
Prose and pictures released under a <a href="https://creativecommons.org/licenses/by-sa/4.0/"> CC BY-SA 4.0 license</a>.
</p>

          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>