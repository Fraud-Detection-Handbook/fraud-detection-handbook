
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3. Resampling strategies &#8212; Reproducible Machine Learning for Credit Card Fraud detection - Practical handbook</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/book.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/jtag_0.js"></script>
    <script src="../_static/jtag_1.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://fraud-detection-handbook.github.io/fraud-detection-handbook/Chapter_6_ImbalancedLearning/Resampling.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="4. Ensemble methods" href="Ensembling.html" />
    <link rel="prev" title="2. Cost-sensitive learning" href="CostSensitive.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Reproducible Machine Learning for Credit Card Fraud detection - Practical handbook</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Foreword.html">
   Foreword
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  1. Book overview
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_1_BookContent/BookContent.html">
   1. Book content and intended audience
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_1_BookContent/BookContributions.html">
   2. Book contributions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_1_BookContent/HowToUse.html">
   3. How to use this book
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  2. Background
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_2_Background/Introduction.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_2_Background/CreditCardFraud.html">
   2. Credit card fraud scenarios
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_2_Background/FDS.html">
   3. Credit card fraud detection system
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_2_Background/MachineLearningForFraudDetection.html">
   4. Machine learning for credit card fraud detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_2_Background/Summary.html">
   5. Summary
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  3. Getting started
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_3_GettingStarted/Introduction.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_3_GettingStarted/SimulatedDataset.html">
   2. Transaction data simulator
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_3_GettingStarted/BaselineFeatureTransformation.html">
   3. Baseline feature transformation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_3_GettingStarted/BaselineModeling.html">
   4. Baseline fraud detection system
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_3_GettingStarted/Baseline_RealWorldData.html">
   5. Real-world data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_3_GettingStarted/Summary.html">
   6. Summary
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  4. Performance metrics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_4_PerformanceMetrics/Introduction.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_4_PerformanceMetrics/ThresholdBased.html">
   2. Threshold-based metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_4_PerformanceMetrics/ThresholdFree.html">
   3. Threshold-free metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_4_PerformanceMetrics/TopKBased.html">
   4. Precision top-k metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_4_PerformanceMetrics/Assessment_RealWorldData.html">
   5. Real-world data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_4_PerformanceMetrics/Summary.html">
   6. Summary
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  5. Model validation and model selection
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_5_ModelValidationAndSelection/Introduction.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_5_ModelValidationAndSelection/ValidationStrategies.html">
   2. Validation strategies
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_5_ModelValidationAndSelection/ModelSelection.html">
   3. Model selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_5_ModelValidationAndSelection/ModelSelection_RealWorldData.html">
   4. Real-world data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_5_ModelValidationAndSelection/Summary.html">
   5. Summary
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  6. Imbalanced learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="CostSensitive.html">
   2. Cost-sensitive learning
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   3. Resampling strategies
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Ensembling.html">
   4. Ensemble methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Imbalanced_RealWorldData.html">
   5. Real-world data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Summary.html">
   6. Summary
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  7. Deep learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_7_DeepLearning/Introduction.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_7_DeepLearning/FeedForwardNeuralNetworks.html">
   2. Feed-forward neural network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_7_DeepLearning/Autoencoders.html">
   3. Autoencoders and anomaly detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_7_DeepLearning/SequentialModeling.html">
   4. Sequential models and representation learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_7_DeepLearning/RealWorldData.html">
   5. Real-world data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_7_DeepLearning/Summary.html">
   6. Summary
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_References/shared_functions.html">
   1. Shared functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_References/bibliography.html">
   2. Bibliography
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Chapter_6_ImbalancedLearning/Resampling.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook/issues/new?title=Issue%20on%20page%20%2FChapter_6_ImbalancedLearning/Resampling.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook/edit/main/Chapter_6_ImbalancedLearning/Resampling.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/Fraud-Detection-Handbook/fraud-detection-handbook/main?urlpath=tree/Chapter_6_ImbalancedLearning/Resampling.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/Fraud-Detection-Handbook/fraud-detection-handbook/blob/main/Chapter_6_ImbalancedLearning/Resampling.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#illustrative-example">
   3.1. Illustrative example
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#oversampling">
     3.1.1. Oversampling
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#random-oversampling">
       3.1.1.1. Random oversampling
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#smote">
       3.1.1.2. SMOTE
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#other-oversampling-strategies">
       3.1.1.3. Other oversampling strategies
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#undersampling">
     3.1.2. Undersampling
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#random-undersampling">
       3.1.2.1. Random undersampling
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#edited-nearest-neighbor">
       3.1.2.2. Edited Nearest Neighbor
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#other-undersampling-strategies">
       3.1.2.3. Other undersampling strategies
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#combining-over-and-undersampling">
     3.1.3. Combining over and undersampling
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transaction-data">
   3.2. Transaction data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#load-data">
     3.2.1. Load data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prequential-validation-with-resampling">
     3.2.2. Prequential validation with resampling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#resampling-strategies-transaction-data-oversampling">
     3.2.3. Oversampling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#resampling-strategies-transaction-data-rus">
     3.2.4. Undersampling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#combining">
     3.2.5. Combining
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   3.3. Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#saving-of-results">
   3.4. Saving of results
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="resampling-strategies">
<span id="id1"></span><h1><span class="section-number">3. </span>Resampling strategies<a class="headerlink" href="#resampling-strategies" title="Permalink to this headline">¶</a></h1>
<p>Resampling strategies address class imbalance at the data level, by resampling the dataset to reduce the imbalance ratio. The resampling of an imbalanced dataset occurs before the training of the prediction model and can be seen as a data preprocessing step. Numerous methods have been proposed for resampling imbalanced datasets, which can be categorized into three main strategies: <em>oversampling</em>, <em>undersampling</em>, and <em>hybrid</em> strategies <span id="id2">[<a class="reference internal" href="../Chapter_References/bibliography.html#id74">Cha09</a>, <a class="reference internal" href="../Chapter_References/bibliography.html#id39">FernandezGarciaG+18</a>, <a class="reference internal" href="../Chapter_References/bibliography.html#id41">LemaitreNA17</a>]</span>.</p>
<p>Oversampling consists in artificially increasing the proportion of samples from the minority class. The most naive approach is <em>random oversampling</em> (ROS), in which samples from the minority class are randomly duplicated <span id="id3">[<a class="reference internal" href="../Chapter_References/bibliography.html#id39">FernandezGarciaG+18</a>]</span>. More sophisticated approaches consist in generating synthetic data by interpolating samples from the minority class. Two standard methods based on interpolation are <em>SMOTE</em> (Synthetic Minority Oversampling Technique) <span id="id4">[<a class="reference internal" href="../Chapter_References/bibliography.html#id56">CBHK02</a>]</span> and <em>ADASYN</em> (Adaptive Synthetic Sampling) <span id="id5">[<a class="reference internal" href="../Chapter_References/bibliography.html#id47">HBGL08</a>]</span>.</p>
<p>Undersampling, on the contrary, consists in reducing the imbalance ratio by removing samples from the majority class. Samples may be simply randomly removed, as in <em>random undersampling</em> (RUS) <span id="id6">[<a class="reference internal" href="../Chapter_References/bibliography.html#id39">FernandezGarciaG+18</a>]</span>. RUS is a fast and easy way to balance a dataset and is therefore widely used. A significant drawback of the method is that samples that are useful for the learning process may be discarded <span id="id7">[<a class="reference internal" href="../Chapter_References/bibliography.html#id37">ASH+19</a>]</span>. More advanced strategies aim at removing samples from overlapping regions (such as NearMiss <span id="id8">[<a class="reference internal" href="../Chapter_References/bibliography.html#id55">MZ03</a>]</span>, Tomek Links <span id="id9">[<a class="reference internal" href="../Chapter_References/bibliography.html#id62">T+76</a>]</span> or Edited Nearest-Neighbors (ENN) <span id="id10">[<a class="reference internal" href="../Chapter_References/bibliography.html#id63">Wil72</a>]</span>), or by replacing subsets of samples by their centroids <span id="id11">[<a class="reference internal" href="../Chapter_References/bibliography.html#id46">YL09</a>]</span>.</p>
<p>The ability of oversampling or undersampling techniques to improve classification performances largely depends on the characteristics of a dataset. As summarized in <span id="id12">[<a class="reference internal" href="../Chapter_References/bibliography.html#id43">HYS+17</a>]</span>, oversampling techniques tend to be particularly effective when the number of samples from the minority class is very low. Undersampling techniques, on the other hand, are well-suited for large datasets. In particular, they allow to speed up the training times by reducing the dataset size.</p>
<p>Oversampling and undersampling techniques can also be combined, resulting in <em>hybrid</em> resampling techniques. Hybridization of undersampling and oversampling has been shown to almost always increase the classification performances (Chapter 5, Section 6 in <span id="id13">[<a class="reference internal" href="../Chapter_References/bibliography.html#id39">FernandezGarciaG+18</a>]</span>). Popular combinations involve SMOTE, together with nearest neighbors based undersampling techniques such as Tomek Links <span id="id14">[<a class="reference internal" href="../Chapter_References/bibliography.html#id53">BPM04</a>, <a class="reference internal" href="../Chapter_References/bibliography.html#id62">T+76</a>]</span> or Edited Nearest-Neighbors (ENN) <span id="id15">[<a class="reference internal" href="../Chapter_References/bibliography.html#id54">BBM+03</a>, <a class="reference internal" href="../Chapter_References/bibliography.html#id63">Wil72</a>]</span>.</p>
<p>This section explores the use of some popular resampling techniques and discusses their benefits and limitations. The proposed implementation relies on the <code class="docutils literal notranslate"><span class="pre">imblearn</span></code> Python library, which is the most complete and up-to-date Python library for imbalanced learning. The library provides a wide range of resampling techniques that can be easily integrated with the <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> library <span id="id16">[<a class="reference internal" href="../Chapter_References/bibliography.html#id85">Imb21</a>]</span>.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialization: Load shared functions and simulated data </span>

<span class="c1"># Load shared functions</span>
<span class="o">!</span>curl -O https://raw.githubusercontent.com/Fraud-Detection-Handbook/fraud-detection-handbook/main/Chapter_References/shared_functions.py
<span class="o">%</span><span class="k">run</span> shared_functions.py
<span class="c1">#%run ../Chapter_References/shared_functions.ipynb</span>

<span class="c1"># Get simulated data from Github repository</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s2">&quot;simulated-data-transformed&quot;</span><span class="p">):</span>
    <span class="o">!</span>git clone https://github.com/Fraud-Detection-Handbook/simulated-data-transformed
        
</pre></div>
</div>
</div>
</div>
<div class="section" id="illustrative-example">
<h2><span class="section-number">3.1. </span>Illustrative example<a class="headerlink" href="#illustrative-example" title="Permalink to this headline">¶</a></h2>
<p>For illustrative purposes, we reuse the same simple classification task as in the <a class="reference internal" href="CostSensitive.html#imbalanced-learning-illustrative-example"><span class="std std-ref">cost-sensitive learning section</span></a>.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                            <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_repeated</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                            <span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                            <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span>
                                            <span class="n">class_sep</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">dataset_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;X1&#39;</span><span class="p">:</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="s1">&#39;X2&#39;</span><span class="p">:</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;Y&#39;</span><span class="p">:</span><span class="n">y</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span>
<span class="n">fig_distribution</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="n">groups</span> <span class="o">=</span> <span class="n">dataset_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">groups</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">group</span><span class="o">.</span><span class="n">X1</span><span class="p">,</span> <span class="n">group</span><span class="o">.</span><span class="n">X2</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">name</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>
    
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">,</span> 
          <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.05</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
          <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Class&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The dataset contains 5000 samples with two classes, labeled 0 and 1. 95% of the samples are associated to the class 0, and 5% of the samples to the class 1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig_distribution</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Resampling_7_0.png" src="../_images/Resampling_7_0.png" />
</div>
</div>
<p>Following the same methodology as in the <a class="reference internal" href="CostSensitive.html#imbalanced-learning-illustrative-example"><span class="std std-ref">cost-sensitive learning section</span></a>, the performances of a baseline classifier without resampling is obtained with the <code class="docutils literal notranslate"><span class="pre">kfold_cv_with_classifier</span></code> function. A decision tree of depth five and a 5-fold stratified cross-validation gives us the following baseline classification performances.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="p">(</span><span class="n">results_df_dt_baseline</span><span class="p">,</span> <span class="n">classifier_0</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span> <span class="o">=</span> <span class="n">kfold_cv_with_classifier</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> 
                                                                                     <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
                                                                                     <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                                                                     <span class="n">strategy_name</span><span class="o">=</span><span class="s2">&quot;Decision tree - Baseline&quot;</span><span class="p">)</span>

<span class="n">fig_decision_boundary</span> <span class="o">=</span> <span class="n">plot_decision_boundary</span><span class="p">(</span><span class="n">classifier_0</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results_df_dt_baseline</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fit time (s)</th>
      <th>Score time (s)</th>
      <th>AUC ROC</th>
      <th>Average Precision</th>
      <th>Balanced accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Decision tree - Baseline</th>
      <td>0.008+/-0.002</td>
      <td>0.008+/-0.005</td>
      <td>0.906+/-0.025</td>
      <td>0.528+/-0.072</td>
      <td>0.786+/-0.046</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The decision boundary of the first classifier of the cross-validation is reported below. Due to class imbalance, the classifier tends to return equal probabilities for the two classes in the overlapping region.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig_decision_boundary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Resampling_12_0.png" src="../_images/Resampling_12_0.png" />
</div>
</div>
<div class="section" id="oversampling">
<h3><span class="section-number">3.1.1. </span>Oversampling<a class="headerlink" href="#oversampling" title="Permalink to this headline">¶</a></h3>
<p>Oversampling techniques aim at rebalancing the dataset by creating new samples for the minority class. The two most widely-used methods are <em>random oversampling</em> and <em>SMOTE</em> <span id="id17">[<a class="reference internal" href="../Chapter_References/bibliography.html#id56">CBHK02</a>, <a class="reference internal" href="../Chapter_References/bibliography.html#id39">FernandezGarciaG+18</a>, <a class="reference internal" href="../Chapter_References/bibliography.html#id43">HYS+17</a>]</span>. The next two subsections show how these methods can be implemented, and illustrate their ability to move the decision boundaries towards the minority class.</p>
<div class="section" id="random-oversampling">
<h4><span class="section-number">3.1.1.1. </span>Random oversampling<a class="headerlink" href="#random-oversampling" title="Permalink to this headline">¶</a></h4>
<p>Let us first briefly cover how the <code class="docutils literal notranslate"><span class="pre">imblearn</span></code> library allows to resample datasets. A more complete introduction can be found on the library’s website, at <a class="reference external" href="https://imbalanced-learn.org/dev/introduction.html">https://imbalanced-learn.org/dev/introduction.html</a>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">imblearn</span></code> library provides objects called <em>samplers</em>, which take as input a dataset and a set of parameters that are specific to the sampler, and return a resampled dataset.</p>
<p>For example, the <code class="docutils literal notranslate"><span class="pre">imblearn</span></code> sampler for random oversampling is called <a class="reference external" href="https://imbalanced-learn.org/dev/references/generated/imblearn.over_sampling.RandomOverSampler.html"><code class="docutils literal notranslate"><span class="pre">RandomOverSampler</span></code></a>. Its main parameter is the <code class="docutils literal notranslate"><span class="pre">sampling_strategy</span></code>, which determines the desired imbalance ratio after random oversampling.</p>
<p>Let us for example create a sampler for random oversampling, where the resampled dataset should have an imbalance ratio of 1 (that is, where samples from the minority class are duplicated until their number equals the number of samples in the majority class).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># random_state is set to 0 for reproducibility</span>
<span class="n">ROS</span> <span class="o">=</span> <span class="n">imblearn</span><span class="o">.</span><span class="n">over_sampling</span><span class="o">.</span><span class="n">RandomOverSampler</span><span class="p">(</span><span class="n">sampling_strategy</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let us apply this sampler on the <code class="docutils literal notranslate"><span class="pre">train_df</span></code> DataFrame, which is the set of training data in the first fold of the cross-validation performed above. The DataFrame contains 3784 samples of class 0 and 216 samples of class 1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    3784
1     216
Name: Y, dtype: int64
</pre></div>
</div>
</div>
</div>
<p>The resampling of the dataset is performed by calling the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method of the sampler object. Let <code class="docutils literal notranslate"><span class="pre">train_df_ROS</span></code> be the resampled DataFrame.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_resampled</span><span class="p">,</span> <span class="n">Y_resampled</span> <span class="o">=</span> <span class="n">ROS</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">train_df</span><span class="p">[[</span><span class="s1">&#39;X1&#39;</span><span class="p">,</span><span class="s1">&#39;X2&#39;</span><span class="p">]],</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">])</span>
<span class="n">train_df_ROS</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;X1&#39;</span><span class="p">:</span><span class="n">X_resampled</span><span class="p">[</span><span class="s1">&#39;X1&#39;</span><span class="p">],</span><span class="s1">&#39;X2&#39;</span><span class="p">:</span><span class="n">X_resampled</span><span class="p">[</span><span class="s1">&#39;X2&#39;</span><span class="p">],</span> <span class="s1">&#39;Y&#39;</span><span class="p">:</span><span class="n">Y_resampled</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<p>The resampled DataFrame now contains as many samples of class 1 as of class 0.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df_ROS</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    3784
1    3784
Name: Y, dtype: int64
</pre></div>
</div>
</div>
</div>
<p>Samplers can be combined with <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> estimators using pipelines. The addition of a sampling step in the cross-validation procedure is therefore simple and consists in creating a pipeline made of a sampler, and an estimator.</p>
<p>The implementation is provided below, in the <code class="docutils literal notranslate"><span class="pre">kfold_cv_with_sampler_and_classifier</span></code> function.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">kfold_cv_with_sampler_and_classifier</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span>
                                         <span class="n">sampler_list</span><span class="p">,</span>
                                         <span class="n">X</span><span class="p">,</span>
                                         <span class="n">y</span><span class="p">,</span>
                                         <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                         <span class="n">strategy_name</span><span class="o">=</span><span class="s2">&quot;Baseline classifier&quot;</span><span class="p">):</span>
    
    <span class="c1"># Create a pipeline with the list of samplers, and the estimator</span>
    <span class="n">estimators</span> <span class="o">=</span> <span class="n">sampler_list</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">estimators</span><span class="o">.</span><span class="n">extend</span><span class="p">([(</span><span class="s1">&#39;clf&#39;</span><span class="p">,</span> <span class="n">classifier</span><span class="p">)])</span>
    
    <span class="n">pipe</span> <span class="o">=</span> <span class="n">imblearn</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">estimators</span><span class="p">)</span>
    
    <span class="n">cv</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">model_selection</span><span class="o">.</span><span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="n">cv_results_</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">model_selection</span><span class="o">.</span><span class="n">cross_validate</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
                                                         <span class="n">scoring</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span>
                                                                  <span class="s1">&#39;average_precision&#39;</span><span class="p">,</span>
                                                                  <span class="s1">&#39;balanced_accuracy&#39;</span><span class="p">],</span>
                                                         <span class="n">return_estimator</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">results</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cv_results_</span><span class="p">),</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">results_mean</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">results_std</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">results_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([[</span><span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">results_mean</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="mi">3</span><span class="p">))</span><span class="o">+</span><span class="s1">&#39;+/-&#39;</span><span class="o">+</span>
                                <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">results_std</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="mi">3</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">))]],</span>
                              <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Fit time (s)&#39;</span><span class="p">,</span><span class="s1">&#39;Score time (s)&#39;</span><span class="p">,</span>
                                       <span class="s1">&#39;AUC ROC&#39;</span><span class="p">,</span><span class="s1">&#39;Average Precision&#39;</span><span class="p">,</span><span class="s1">&#39;Balanced accuracy&#39;</span><span class="p">])</span>
    <span class="n">results_df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="n">strategy_name</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">classifier_0</span> <span class="o">=</span> <span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;estimator&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="p">(</span><span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
    <span class="n">X_resampled</span><span class="p">,</span> <span class="n">Y_resampled</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_index</span><span class="p">,:],</span> <span class="n">y</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sampler_list</span><span class="p">)):</span>
        <span class="n">X_resampled</span><span class="p">,</span> <span class="n">Y_resampled</span> <span class="o">=</span> <span class="n">sampler_list</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X_resampled</span><span class="p">,</span> <span class="n">Y_resampled</span><span class="p">)</span>
    
    <span class="n">test_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;X1&#39;</span><span class="p">:</span><span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span><span class="s1">&#39;X2&#39;</span><span class="p">:</span><span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;Y&#39;</span><span class="p">:</span><span class="n">y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]})</span>
    <span class="n">train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;X1&#39;</span><span class="p">:</span><span class="n">X_resampled</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="s1">&#39;X2&#39;</span><span class="p">:</span><span class="n">X_resampled</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;Y&#39;</span><span class="p">:</span><span class="n">Y_resampled</span><span class="p">})</span>
    
    <span class="k">return</span> <span class="p">(</span><span class="n">results_df</span><span class="p">,</span> <span class="n">classifier_0</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let us assess the performances of the baseline classifier combined with random oversampling.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span>

<span class="n">sampler_list</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;sampler&#39;</span><span class="p">,</span><span class="n">imblearn</span><span class="o">.</span><span class="n">over_sampling</span><span class="o">.</span><span class="n">RandomOverSampler</span><span class="p">(</span><span class="n">sampling_strategy</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">))]</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="p">(</span><span class="n">results_df_ROS</span><span class="p">,</span> <span class="n">classifier_0</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span> <span class="o">=</span> <span class="n">kfold_cv_with_sampler_and_classifier</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> 
                                                                                         <span class="n">sampler_list</span><span class="p">,</span> 
                                                                                         <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
                                                                                         <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                                                                         <span class="n">strategy_name</span><span class="o">=</span><span class="s2">&quot;Decision tree - ROS&quot;</span><span class="p">)</span>

<span class="n">fig_decision_boundary</span> <span class="o">=</span> <span class="n">plot_decision_boundary</span><span class="p">(</span><span class="n">classifier_0</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As a sanity check, we can verify that the training set size contains the same number of samples for the two classes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    3784
1    3784
Name: Y, dtype: int64
</pre></div>
</div>
</div>
</div>
<p>The resampling allowed to shift the decision boundary towards the minority class, as can be seen in the figure below. Note that the training data for the minority class looks the same as the baseline classifier. Most instances have however been duplicated many times to reach an imbalance ratio of one.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig_decision_boundary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Resampling_28_0.png" src="../_images/Resampling_28_0.png" />
</div>
</div>
<p>The classification performances show an increase in terms of balanced accuracy. We however note a decrease in terms of AUC ROC and Average Precision, due to the shift of the decision boundary which significantly increased the number of false positives.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">results_df_dt_baseline</span><span class="p">,</span> 
           <span class="n">results_df_ROS</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fit time (s)</th>
      <th>Score time (s)</th>
      <th>AUC ROC</th>
      <th>Average Precision</th>
      <th>Balanced accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Decision tree - Baseline</th>
      <td>0.008+/-0.002</td>
      <td>0.008+/-0.005</td>
      <td>0.906+/-0.025</td>
      <td>0.528+/-0.072</td>
      <td>0.786+/-0.046</td>
    </tr>
    <tr>
      <th>Decision tree - ROS</th>
      <td>0.019+/-0.01</td>
      <td>0.008+/-0.003</td>
      <td>0.88+/-0.038</td>
      <td>0.456+/-0.062</td>
      <td>0.888+/-0.03</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="smote">
<h4><span class="section-number">3.1.1.2. </span>SMOTE<a class="headerlink" href="#smote" title="Permalink to this headline">¶</a></h4>
<p>SMOTE <span id="id18">[<a class="reference internal" href="../Chapter_References/bibliography.html#id56">CBHK02</a>]</span> oversamples the minority class by generating synthetic examples in the neighborhood of observed ones. The idea is to form new minority examples by interpolating between samples of the same class. This has the effect of creating clusters around each minority observation. By creating synthetic observations, the classifier builds larger decision regions that contain nearby instances from the minority class. SMOTE has been shown to improve the performances of a base classifier in many applications <span id="id19">[<a class="reference internal" href="../Chapter_References/bibliography.html#id56">CBHK02</a>, <a class="reference internal" href="../Chapter_References/bibliography.html#id34">DP15</a>]</span></p>
<p>The <code class="docutils literal notranslate"><span class="pre">imblearn</span></code> sampler for SMOTE is <a class="reference external" href="https://imbalanced-learn.org/dev/references/generated/imblearn.over_sampling.SMOTE.html"><code class="docutils literal notranslate"><span class="pre">imblearn.over_sampling.SMOTE</span></code></a>. Let us illustrate the use of SMOTE, and its impact on the classifier decision boundary and the classification performances.</p>
<p>The implementation follows the same structure as the random oversampling. The only difference is to change the sampler to SMOTE.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span>

<span class="n">sampler_list</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;sampler&#39;</span><span class="p">,</span> <span class="n">imblearn</span><span class="o">.</span><span class="n">over_sampling</span><span class="o">.</span><span class="n">SMOTE</span><span class="p">(</span><span class="n">sampling_strategy</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">))]</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="p">(</span><span class="n">results_df_SMOTE</span><span class="p">,</span> <span class="n">classifier_0</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span> <span class="o">=</span> <span class="n">kfold_cv_with_sampler_and_classifier</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> 
                                                                                           <span class="n">sampler_list</span><span class="p">,</span> 
                                                                                           <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
                                                                                           <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                                                                           <span class="n">strategy_name</span><span class="o">=</span><span class="s2">&quot;Decision tree - SMOTE&quot;</span><span class="p">)</span>


<span class="n">fig_decision_boundary</span> <span class="o">=</span> <span class="n">plot_decision_boundary</span><span class="p">(</span><span class="n">classifier_0</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As with random oversampling, the number of samples in the minority class is increased to match the number of samples in the majority class (<code class="docutils literal notranslate"><span class="pre">sampling_strategy=1</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    3784
1    3784
Name: Y, dtype: int64
</pre></div>
</div>
</div>
</div>
<p>The decision boundary is also shifted towards the minority class. We note that, contrary to random oversampling, new examples have been generated for the minority class.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig_decision_boundary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Resampling_36_0.png" src="../_images/Resampling_36_0.png" />
</div>
</div>
<p>SMOTE provides higher performances than random oversampling for the three metrics. The Average Precision however remains lower than the baseline classifier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">results_df_dt_baseline</span><span class="p">,</span> 
           <span class="n">results_df_ROS</span><span class="p">,</span>
           <span class="n">results_df_SMOTE</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fit time (s)</th>
      <th>Score time (s)</th>
      <th>AUC ROC</th>
      <th>Average Precision</th>
      <th>Balanced accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Decision tree - Baseline</th>
      <td>0.008+/-0.002</td>
      <td>0.008+/-0.005</td>
      <td>0.906+/-0.025</td>
      <td>0.528+/-0.072</td>
      <td>0.786+/-0.046</td>
    </tr>
    <tr>
      <th>Decision tree - ROS</th>
      <td>0.019+/-0.01</td>
      <td>0.008+/-0.003</td>
      <td>0.88+/-0.038</td>
      <td>0.456+/-0.062</td>
      <td>0.888+/-0.03</td>
    </tr>
    <tr>
      <th>Decision tree - SMOTE</th>
      <td>0.022+/-0.012</td>
      <td>0.008+/-0.003</td>
      <td>0.913+/-0.032</td>
      <td>0.499+/-0.056</td>
      <td>0.91+/-0.019</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="other-oversampling-strategies">
<h4><span class="section-number">3.1.1.3. </span>Other oversampling strategies<a class="headerlink" href="#other-oversampling-strategies" title="Permalink to this headline">¶</a></h4>
<p>There exists a range of more sophisticated strategies for oversampling, whose details go beyond the scope of this book. We refer the reader to <span id="id20">[<a class="reference internal" href="../Chapter_References/bibliography.html#id39">FernandezGarciaG+18</a>]</span> for a review and to the <a class="reference external" href="https://imbalanced-learn.org/stable/references/over_sampling.html"><code class="docutils literal notranslate"><span class="pre">imblearn</span></code> page on oversampling methods</a> for their implementations in Python. In particular the <code class="docutils literal notranslate"><span class="pre">imblearn</span></code> library provides the following additional oversampling methods: <code class="docutils literal notranslate"><span class="pre">SMOTENC</span></code> <span id="id21">[<a class="reference internal" href="../Chapter_References/bibliography.html#id56">CBHK02</a>]</span>, <code class="docutils literal notranslate"><span class="pre">SMOTEN</span></code> <span id="id22">[<a class="reference internal" href="../Chapter_References/bibliography.html#id56">CBHK02</a>]</span>, <code class="docutils literal notranslate"><span class="pre">ADASYN</span></code> <span id="id23">[<a class="reference internal" href="../Chapter_References/bibliography.html#id47">HBGL08</a>]</span>, <code class="docutils literal notranslate"><span class="pre">BorderlineSMOTE</span></code> <span id="id24">[<a class="reference internal" href="../Chapter_References/bibliography.html#id50">HWM05</a>]</span>, <code class="docutils literal notranslate"><span class="pre">KMeansSMOTE</span></code> <span id="id25">[<a class="reference internal" href="../Chapter_References/bibliography.html#id42">LDB17</a>]</span>, and <code class="docutils literal notranslate"><span class="pre">SVMSMOTE</span></code> <span id="id26">[<a class="reference internal" href="../Chapter_References/bibliography.html#id44">NCK11</a>]</span>. These methods can be used by simply replacing the sampler with the desired method in the code above.</p>
</div>
</div>
<div class="section" id="undersampling">
<span id="resampling-strategies-undersampling"></span><h3><span class="section-number">3.1.2. </span>Undersampling<a class="headerlink" href="#undersampling" title="Permalink to this headline">¶</a></h3>
<p>Undersampling refers to the process of reducing the number of samples in the majority class. The naive approach, called <em>random undersampling</em> (RUS), consists in randomly removing samples from the majority class until the desired imbalance ratio is achieved.</p>
<p>The major drawback of RUS is that the method may discard samples that are important for identifying the decision boundary. A range of more advanced techniques have been proposed that aim at removing samples in a more principled way <span id="id27">[<a class="reference internal" href="../Chapter_References/bibliography.html#id39">FernandezGarciaG+18</a>]</span>. Besides RUS, the <code class="docutils literal notranslate"><span class="pre">imblearn</span></code> package proposes no less than ten different methods for undersampling <span id="id28">[<a class="reference internal" href="../Chapter_References/bibliography.html#id85">Imb21</a>]</span>. Most of these methods rely on nearest neighbors heuristics that remove samples when they either lie close or far away from other samples. We refer the reader to <span id="id29">[<a class="reference internal" href="../Chapter_References/bibliography.html#id39">FernandezGarciaG+18</a>, <a class="reference internal" href="../Chapter_References/bibliography.html#id85">Imb21</a>]</span> for the detailed algorithms underlying more advanced undersampling methods.</p>
<p>The next two subsections show how two of these methods can be implemented, and illustrate their ability to move the decision boundary towards the minority class. As examples, we rely on RUS, and Edited Nearest Neighbor (ENN).</p>
<div class="section" id="random-undersampling">
<span id="resampling-strategies-rus"></span><h4><span class="section-number">3.1.2.1. </span>Random undersampling<a class="headerlink" href="#random-undersampling" title="Permalink to this headline">¶</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">imblearn</span></code> sampler for RUS is <a class="reference external" href="https://imbalanced-learn.org/dev/references/generated/imblearn.under_sampling.RandomUnderSampler.html"><code class="docutils literal notranslate"><span class="pre">imblearn.under_sampling.RandomUnderSampler</span></code></a>. Let us illustrate its use and its impact on the classifier decision boundary and the classification performances.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span>

<span class="n">sampler_list</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;sampler&#39;</span><span class="p">,</span> <span class="n">imblearn</span><span class="o">.</span><span class="n">under_sampling</span><span class="o">.</span><span class="n">RandomUnderSampler</span><span class="p">(</span><span class="n">sampling_strategy</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">))]</span>

<span class="n">classifier</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="p">(</span><span class="n">results_df_RUS</span><span class="p">,</span> <span class="n">classifier_0</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span> <span class="o">=</span> <span class="n">kfold_cv_with_sampler_and_classifier</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> 
                                                                                         <span class="n">sampler_list</span><span class="p">,</span> 
                                                                                         <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
                                                                                         <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                                                                         <span class="n">strategy_name</span><span class="o">=</span><span class="s2">&quot;Decision tree - RUS&quot;</span><span class="p">)</span>

<span class="n">fig_decision_boundary</span> <span class="o">=</span> <span class="n">plot_decision_boundary</span><span class="p">(</span><span class="n">classifier_0</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>With a <code class="docutils literal notranslate"><span class="pre">sampling_strategy</span></code> set to one, RUS randomly removes samples from the majority class until their number reaches that of the minority class. After resampling, each class contains 216 samples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    216
1    216
Name: Y, dtype: int64
</pre></div>
</div>
</div>
</div>
<p>The plotting of training samples shows that the number of samples from the majority class was significantly reduced, allowing a shift of the decision boundary towards the minority class. Contrary to oversampling techniques, the region located at the bottom right is now associated with the minority class, since all samples of class 0 from this region have been removed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig_decision_boundary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Resampling_45_0.png" src="../_images/Resampling_45_0.png" />
</div>
</div>
<p>The performances in terms of AUC ROC and balanced accuracy are on par with oversampling techniques. We however note a loss of performance in terms of Average Precision.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">results_df_dt_baseline</span><span class="p">,</span> 
           <span class="n">results_df_ROS</span><span class="p">,</span>
           <span class="n">results_df_SMOTE</span><span class="p">,</span>
           <span class="n">results_df_RUS</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fit time (s)</th>
      <th>Score time (s)</th>
      <th>AUC ROC</th>
      <th>Average Precision</th>
      <th>Balanced accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Decision tree - Baseline</th>
      <td>0.008+/-0.002</td>
      <td>0.008+/-0.005</td>
      <td>0.906+/-0.025</td>
      <td>0.528+/-0.072</td>
      <td>0.786+/-0.046</td>
    </tr>
    <tr>
      <th>Decision tree - ROS</th>
      <td>0.019+/-0.01</td>
      <td>0.008+/-0.003</td>
      <td>0.88+/-0.038</td>
      <td>0.456+/-0.062</td>
      <td>0.888+/-0.03</td>
    </tr>
    <tr>
      <th>Decision tree - SMOTE</th>
      <td>0.022+/-0.012</td>
      <td>0.008+/-0.003</td>
      <td>0.913+/-0.032</td>
      <td>0.499+/-0.056</td>
      <td>0.91+/-0.019</td>
    </tr>
    <tr>
      <th>Decision tree - RUS</th>
      <td>0.005+/-0.001</td>
      <td>0.006+/-0.002</td>
      <td>0.913+/-0.02</td>
      <td>0.408+/-0.058</td>
      <td>0.896+/-0.023</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>It is worth noting that the training time with RUS is faster. This results from the simple undersampling procedure and the smaller training set size. The method is therefore useful not only for reducing the imbalance ratio but also for speeding up the execution time of the modeling procedure.</p>
</div>
<div class="section" id="edited-nearest-neighbor">
<h4><span class="section-number">3.1.2.2. </span>Edited Nearest Neighbor<a class="headerlink" href="#edited-nearest-neighbor" title="Permalink to this headline">¶</a></h4>
<p>The Edited Nearest Neighbor rule is an undersampling technique that removes samples from the majority class in overlapping regions of the dataset <span id="id30">[<a class="reference internal" href="../Chapter_References/bibliography.html#id58">Lau01</a>, <a class="reference internal" href="../Chapter_References/bibliography.html#id63">Wil72</a>]</span>. It is based on a nearest neighbor rule, that removes majority class samples as follows <span id="id31">[<a class="reference internal" href="../Chapter_References/bibliography.html#id39">FernandezGarciaG+18</a>]</span> (Chapter 5, Page 84):</p>
<ul class="simple">
<li><p>For each majority class sample, the k-nearest neighbors are found. If the majority of these samples are from the minority class, the majority class sample is removed.</p></li>
<li><p>For each minority class sample, the k-nearest neighbors are found. If the majority of these samples are from the majority class, the majority class sample(s) is (are) removed.</p></li>
</ul>
<p>The number of neighbors <span class="math notranslate nohighlight">\(k\)</span> is by default set to <span class="math notranslate nohighlight">\(k=3\)</span>. It is worth noting that, contrary to RUS, the number of majority class samples that are removed depends on the degree of overlap between the two classes. The method does not allow to specify an imbalanced ratio.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">imblearn</span></code> sampler for RUS is <a class="reference external" href="https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.EditedNearestNeighbours.html"><code class="docutils literal notranslate"><span class="pre">imblearn.under_sampling.EditedNearestNeighbours</span></code></a>. Let us illustrate its use and its impact on the classifier decision boundary and the classification performances.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span>

<span class="n">sampler_list</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;sampler&#39;</span><span class="p">,</span> <span class="n">imblearn</span><span class="o">.</span><span class="n">under_sampling</span><span class="o">.</span><span class="n">EditedNearestNeighbours</span><span class="p">(</span><span class="n">sampling_strategy</span><span class="o">=</span><span class="s1">&#39;majority&#39;</span><span class="p">,</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">))]</span>

<span class="n">classifier</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="p">(</span><span class="n">results_df_ENN</span><span class="p">,</span> <span class="n">classifier_0</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span> <span class="o">=</span> <span class="n">kfold_cv_with_sampler_and_classifier</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> 
                                                                                         <span class="n">sampler_list</span><span class="p">,</span> 
                                                                                         <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
                                                                                         <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                                                                         <span class="n">strategy_name</span><span class="o">=</span><span class="s2">&quot;Decision tree - ENN&quot;</span><span class="p">)</span>

<span class="n">fig_decision_boundary</span> <span class="o">=</span> <span class="n">plot_decision_boundary</span><span class="p">(</span><span class="n">classifier_0</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>With a number of neighbors <code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code> set to three, ENN only removes around 200 samples out of the 3784 samples of the majority class. The number of samples from the minority class is unchanged.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    3572
1     216
Name: Y, dtype: int64
</pre></div>
</div>
</div>
</div>
<p>The plotting of training samples shows that the distributions of the two classes are similar to the original distributions. The samples that were removed lied in the overlapping region, and their removal is therefore not visible due to the large amount of remaining samples. We however observe a shift in the decicision boundary, since the decision tree now classifies samples from the overlapping region into the minority class.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig_decision_boundary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Resampling_54_0.png" src="../_images/Resampling_54_0.png" />
</div>
</div>
<p>On this dataset, the performances of ENN are poor compared to the previsouly tested techniques. The balanced accuracy was slightly improved compared to the baseline classifier. The performance in terms of AP is however lower than the baseline, and the AUC ROC is the worst of all tested tecniques (and on par with ROS).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">results_df_dt_baseline</span><span class="p">,</span> 
           <span class="n">results_df_ROS</span><span class="p">,</span>
           <span class="n">results_df_SMOTE</span><span class="p">,</span>
           <span class="n">results_df_RUS</span><span class="p">,</span>
           <span class="n">results_df_ENN</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fit time (s)</th>
      <th>Score time (s)</th>
      <th>AUC ROC</th>
      <th>Average Precision</th>
      <th>Balanced accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Decision tree - Baseline</th>
      <td>0.008+/-0.002</td>
      <td>0.008+/-0.005</td>
      <td>0.906+/-0.025</td>
      <td>0.528+/-0.072</td>
      <td>0.786+/-0.046</td>
    </tr>
    <tr>
      <th>Decision tree - ROS</th>
      <td>0.019+/-0.01</td>
      <td>0.008+/-0.003</td>
      <td>0.88+/-0.038</td>
      <td>0.456+/-0.062</td>
      <td>0.888+/-0.03</td>
    </tr>
    <tr>
      <th>Decision tree - SMOTE</th>
      <td>0.022+/-0.012</td>
      <td>0.008+/-0.003</td>
      <td>0.913+/-0.032</td>
      <td>0.499+/-0.056</td>
      <td>0.91+/-0.019</td>
    </tr>
    <tr>
      <th>Decision tree - RUS</th>
      <td>0.005+/-0.001</td>
      <td>0.006+/-0.002</td>
      <td>0.913+/-0.02</td>
      <td>0.408+/-0.058</td>
      <td>0.896+/-0.023</td>
    </tr>
    <tr>
      <th>Decision tree - ENN</th>
      <td>0.023+/-0.004</td>
      <td>0.009+/-0.005</td>
      <td>0.879+/-0.038</td>
      <td>0.474+/-0.08</td>
      <td>0.857+/-0.041</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="other-undersampling-strategies">
<h4><span class="section-number">3.1.2.3. </span>Other undersampling strategies<a class="headerlink" href="#other-undersampling-strategies" title="Permalink to this headline">¶</a></h4>
<p>As for ovesampling techniques, we refer the reader to <span id="id32">[<a class="reference internal" href="../Chapter_References/bibliography.html#id39">FernandezGarciaG+18</a>]</span> for a review of more sophisticated undersampling techniques and to the <a class="reference external" href="https://imbalanced-learn.org/stable/references/under_sampling.html"><code class="docutils literal notranslate"><span class="pre">imblearn</span></code> page on undersampling methods</a> for their implementations in Python. In particular the <code class="docutils literal notranslate"><span class="pre">imblearn</span></code> library provides ten other undersampling methods, which can be tested by simply replacing the sampler with the desired method in the code above.</p>
</div>
</div>
<div class="section" id="combining-over-and-undersampling">
<h3><span class="section-number">3.1.3. </span>Combining over and undersampling<a class="headerlink" href="#combining-over-and-undersampling" title="Permalink to this headline">¶</a></h3>
<p>Oversampling and undersampling are often complementary. On the one hand, oversampling techniques allow to generate synthetic samples from the minority class, and help a classifier in identifying more precisely the decision boundary between the two classes. On the other hand, undersampling techniques reduce the size of the training set, and allow to speed-up the classifier training time.  Combining over and undersampling techniques has often been reported to successfully improve the classifier performances (Chapter 5, Section 6 in {cite}fernandez2018learning).</p>
<p>In terms of implementation, the combination of samplers is obtained by chaining the samplers in a <code class="docutils literal notranslate"><span class="pre">pipeline</span></code>. The samplers can then be chained to a classifer. We illustrate below the chaining of an SMOTE oversampling to a random undersampling to a decision tree classifier.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sampler_list</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;sampler1&#39;</span><span class="p">,</span> <span class="n">imblearn</span><span class="o">.</span><span class="n">over_sampling</span><span class="o">.</span><span class="n">SMOTE</span><span class="p">(</span><span class="n">sampling_strategy</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span>
                <span class="p">(</span><span class="s1">&#39;sampler2&#39;</span><span class="p">,</span> <span class="n">imblearn</span><span class="o">.</span><span class="n">under_sampling</span><span class="o">.</span><span class="n">RandomUnderSampler</span><span class="p">(</span><span class="n">sampling_strategy</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
               <span class="p">]</span>

<span class="n">classifier</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">estimators</span> <span class="o">=</span> <span class="n">sampler_list</span><span class="o">.</span><span class="n">extend</span><span class="p">([(</span><span class="s1">&#39;clf&#39;</span><span class="p">,</span> <span class="n">classifier</span><span class="p">)])</span>
    
<span class="n">pipe</span> <span class="o">=</span> <span class="n">imblearn</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">estimators</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">kfold_cv_with_sampler_and_classifier</span></code> takes the <code class="docutils literal notranslate"><span class="pre">sampler_list</span></code> and the <code class="docutils literal notranslate"><span class="pre">classifier</span></code> as two separate arguments, and takes care of chaining the samplers and classifier together. We can therefore follow the same template as before for assessing the performances of a classifier based on a chain of resampling techniques. The samplers are provided as a list with the <code class="docutils literal notranslate"><span class="pre">sampler_list</span></code> variable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span>
<span class="n">sampler_list</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;sampler1&#39;</span><span class="p">,</span> <span class="n">imblearn</span><span class="o">.</span><span class="n">over_sampling</span><span class="o">.</span><span class="n">SMOTE</span><span class="p">(</span><span class="n">sampling_strategy</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span>
                <span class="p">(</span><span class="s1">&#39;sampler2&#39;</span><span class="p">,</span> <span class="n">imblearn</span><span class="o">.</span><span class="n">under_sampling</span><span class="o">.</span><span class="n">RandomUnderSampler</span><span class="p">(</span><span class="n">sampling_strategy</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
               <span class="p">]</span>

<span class="n">classifier</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="p">(</span><span class="n">results_df_combined</span><span class="p">,</span> <span class="n">classifier_0</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span> <span class="o">=</span> <span class="n">kfold_cv_with_sampler_and_classifier</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> 
                                                                                              <span class="n">sampler_list</span><span class="p">,</span> 
                                                                                              <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
                                                                                              <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                                                                              <span class="n">strategy_name</span><span class="o">=</span><span class="s1">&#39;Decision tree - Combined SMOTE and RUS&#39;</span><span class="p">)</span>

<span class="n">fig_decision_boundary</span> <span class="o">=</span> <span class="n">plot_decision_boundary</span><span class="p">(</span><span class="n">classifier_0</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The SMOTE oversampling aimed at an imbalance ratio of 0.5. Since the original dataset contains 3784 sample of the majority class, SMOTE create new samples until the number of minority class samples reached <span class="math notranslate nohighlight">\(3784/2=1892\)</span> samples. The random undersampling aimed at an imbalance ratio of 1. Since the SMOTE resampled dataset contains 1892 samples of the minority class, samples of the majority class are removed until their number reached 1892 samples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    1892
1    1892
Name: Y, dtype: int64
</pre></div>
</div>
</div>
</div>
<p>The resulting decision boundary is close to that obtained with SMOTE, except that a slightly larger region is now considered to be of class 1 by the classifier. This is coherent since less samples of the minority class were created.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig_decision_boundary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Resampling_63_0.png" src="../_images/Resampling_63_0.png" />
</div>
</div>
<p>The resulting performances are on par with those of SMOTE. For larger dataset, one should however expect faster training times than SMOTE, since the training set size is decreased thanks to undersampling.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">results_df_dt_baseline</span><span class="p">,</span> 
           <span class="n">results_df_ROS</span><span class="p">,</span>
           <span class="n">results_df_SMOTE</span><span class="p">,</span>
           <span class="n">results_df_RUS</span><span class="p">,</span>
           <span class="n">results_df_ENN</span><span class="p">,</span>
           <span class="n">results_df_combined</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fit time (s)</th>
      <th>Score time (s)</th>
      <th>AUC ROC</th>
      <th>Average Precision</th>
      <th>Balanced accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Decision tree - Baseline</th>
      <td>0.008+/-0.002</td>
      <td>0.008+/-0.005</td>
      <td>0.906+/-0.025</td>
      <td>0.528+/-0.072</td>
      <td>0.786+/-0.046</td>
    </tr>
    <tr>
      <th>Decision tree - ROS</th>
      <td>0.019+/-0.01</td>
      <td>0.008+/-0.003</td>
      <td>0.88+/-0.038</td>
      <td>0.456+/-0.062</td>
      <td>0.888+/-0.03</td>
    </tr>
    <tr>
      <th>Decision tree - SMOTE</th>
      <td>0.022+/-0.012</td>
      <td>0.008+/-0.003</td>
      <td>0.913+/-0.032</td>
      <td>0.499+/-0.056</td>
      <td>0.91+/-0.019</td>
    </tr>
    <tr>
      <th>Decision tree - RUS</th>
      <td>0.005+/-0.001</td>
      <td>0.006+/-0.002</td>
      <td>0.913+/-0.02</td>
      <td>0.408+/-0.058</td>
      <td>0.896+/-0.023</td>
    </tr>
    <tr>
      <th>Decision tree - ENN</th>
      <td>0.023+/-0.004</td>
      <td>0.009+/-0.005</td>
      <td>0.879+/-0.038</td>
      <td>0.474+/-0.08</td>
      <td>0.857+/-0.041</td>
    </tr>
    <tr>
      <th>Decision tree - Combined SMOTE and RUS</th>
      <td>0.019+/-0.005</td>
      <td>0.008+/-0.001</td>
      <td>0.915+/-0.012</td>
      <td>0.494+/-0.062</td>
      <td>0.912+/-0.005</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
</div>
<div class="section" id="transaction-data">
<span id="resampling-strategies-transaction-data"></span><h2><span class="section-number">3.2. </span>Transaction data<a class="headerlink" href="#transaction-data" title="Permalink to this headline">¶</a></h2>
<p>Let us now apply resampling techniques to the simulated dataset of transaction data. We reuse the methodology of <a class="reference internal" href="../Chapter_5_ModelValidationAndSelection/ModelSelection.html#model-selection"><span class="std std-ref">Chapter 5, Model Selection</span></a>, using prequential validation as the validation strategy.</p>
<div class="section" id="load-data">
<h3><span class="section-number">3.2.1. </span>Load data<a class="headerlink" href="#load-data" title="Permalink to this headline">¶</a></h3>
<p>The loading of data and initialization of the parameters follow the same template as in <a class="reference internal" href="../Chapter_5_ModelValidationAndSelection/ModelSelection.html#model-selection"><span class="std std-ref">Chapter 5, Model Selection</span></a>.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load data from the 2018-07-11 to the 2018-09-14</span>

<span class="n">DIR_INPUT</span> <span class="o">=</span> <span class="s1">&#39;simulated-data-transformed/data/&#39;</span> 

<span class="n">BEGIN_DATE</span> <span class="o">=</span> <span class="s2">&quot;2018-06-11&quot;</span>
<span class="n">END_DATE</span> <span class="o">=</span> <span class="s2">&quot;2018-09-14&quot;</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Load  files&quot;</span><span class="p">)</span>
<span class="o">%</span><span class="k">time</span> transactions_df = read_from_files(DIR_INPUT, BEGIN_DATE, END_DATE)
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{0}</span><span class="s2"> transactions loaded, containing </span><span class="si">{1}</span><span class="s2"> fraudulent transactions&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">),</span><span class="n">transactions_df</span><span class="o">.</span><span class="n">TX_FRAUD</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>


<span class="c1"># Number of folds for the prequential validation</span>
<span class="n">n_folds</span> <span class="o">=</span> <span class="mi">4</span>

<span class="c1"># Set the starting day for the training period, and the deltas</span>
<span class="n">start_date_training</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">strptime</span><span class="p">(</span><span class="s2">&quot;2018-07-25&quot;</span><span class="p">,</span> <span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">delta_train</span> <span class="o">=</span> <span class="n">delta_delay</span> <span class="o">=</span> <span class="n">delta_test</span> <span class="o">=</span> <span class="n">delta_valid</span> <span class="o">=</span> <span class="n">delta_assessment</span> <span class="o">=</span> <span class="mi">7</span>

<span class="n">start_date_training_for_valid</span> <span class="o">=</span> <span class="n">start_date_training</span><span class="o">+</span><span class="n">datetime</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=-</span><span class="p">(</span><span class="n">delta_delay</span><span class="o">+</span><span class="n">delta_valid</span><span class="p">))</span>
<span class="n">start_date_training_for_test</span> <span class="o">=</span> <span class="n">start_date_training</span><span class="o">+</span><span class="n">datetime</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="p">(</span><span class="n">n_folds</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">delta_test</span><span class="p">)</span>

<span class="n">output_feature</span> <span class="o">=</span> <span class="s2">&quot;TX_FRAUD&quot;</span>

<span class="n">input_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;TX_AMOUNT&#39;</span><span class="p">,</span><span class="s1">&#39;TX_DURING_WEEKEND&#39;</span><span class="p">,</span> <span class="s1">&#39;TX_DURING_NIGHT&#39;</span><span class="p">,</span> <span class="s1">&#39;CUSTOMER_ID_NB_TX_1DAY_WINDOW&#39;</span><span class="p">,</span>
       <span class="s1">&#39;CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW&#39;</span><span class="p">,</span> <span class="s1">&#39;CUSTOMER_ID_NB_TX_7DAY_WINDOW&#39;</span><span class="p">,</span>
       <span class="s1">&#39;CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW&#39;</span><span class="p">,</span> <span class="s1">&#39;CUSTOMER_ID_NB_TX_30DAY_WINDOW&#39;</span><span class="p">,</span>
       <span class="s1">&#39;CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW&#39;</span><span class="p">,</span> <span class="s1">&#39;TERMINAL_ID_NB_TX_1DAY_WINDOW&#39;</span><span class="p">,</span>
       <span class="s1">&#39;TERMINAL_ID_RISK_1DAY_WINDOW&#39;</span><span class="p">,</span> <span class="s1">&#39;TERMINAL_ID_NB_TX_7DAY_WINDOW&#39;</span><span class="p">,</span>
       <span class="s1">&#39;TERMINAL_ID_RISK_7DAY_WINDOW&#39;</span><span class="p">,</span> <span class="s1">&#39;TERMINAL_ID_NB_TX_30DAY_WINDOW&#39;</span><span class="p">,</span>
       <span class="s1">&#39;TERMINAL_ID_RISK_30DAY_WINDOW&#39;</span><span class="p">]</span>


<span class="c1"># Only keep columns that are needed as argument to the custom scoring function</span>
<span class="c1"># (in order to reduce the serialization time of transaction dataset)</span>
<span class="n">transactions_df_scorer</span> <span class="o">=</span> <span class="n">transactions_df</span><span class="p">[[</span><span class="s1">&#39;CUSTOMER_ID&#39;</span><span class="p">,</span> <span class="s1">&#39;TX_FRAUD&#39;</span><span class="p">,</span><span class="s1">&#39;TX_TIME_DAYS&#39;</span><span class="p">]]</span>

<span class="n">card_precision_top_100</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">make_scorer</span><span class="p">(</span><span class="n">card_precision_top_k_custom</span><span class="p">,</span> 
                                                     <span class="n">needs_proba</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                                     <span class="n">top_k</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
                                                     <span class="n">transactions_df</span><span class="o">=</span><span class="n">transactions_df_scorer</span><span class="p">)</span>

<span class="n">performance_metrics_list_grid</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="s1">&#39;average_precision&#39;</span><span class="p">,</span> <span class="s1">&#39;card_precision@100&#39;</span><span class="p">]</span>
<span class="n">performance_metrics_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">,</span> <span class="s1">&#39;Average precision&#39;</span><span class="p">,</span> <span class="s1">&#39;Card Precision@100&#39;</span><span class="p">]</span>

<span class="n">scoring</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">:</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span>
           <span class="s1">&#39;average_precision&#39;</span><span class="p">:</span> <span class="s1">&#39;average_precision&#39;</span><span class="p">,</span>
           <span class="s1">&#39;card_precision@100&#39;</span><span class="p">:</span> <span class="n">card_precision_top_100</span><span class="p">,</span>
           <span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Load  files
CPU times: user 812 ms, sys: 580 ms, total: 1.39 s
Wall time: 1.63 s
919767 transactions loaded, containing 8195 fraudulent transactions
</pre></div>
</div>
</div>
</div>
<p>As a baseline, let us compute the fraud detection performances with a decision tree of depth 5 without any resampling.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define classifier</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">()</span>

<span class="c1"># Set of parameters for which to assess model performances</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;clf__max_depth&#39;</span><span class="p">:[</span><span class="mi">5</span><span class="p">],</span> <span class="s1">&#39;clf__random_state&#39;</span><span class="p">:[</span><span class="mi">0</span><span class="p">]}</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="c1"># Fit models and assess performances for all parameters</span>
<span class="n">performances_df</span><span class="o">=</span><span class="n">model_selection_wrapper</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> 
                                        <span class="n">input_features</span><span class="p">,</span> <span class="n">output_feature</span><span class="p">,</span>
                                        <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> 
                                        <span class="n">start_date_training_for_valid</span><span class="p">,</span>
                                        <span class="n">start_date_training_for_test</span><span class="p">,</span>
                                        <span class="n">n_folds</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span>
                                        <span class="n">delta_train</span><span class="o">=</span><span class="n">delta_train</span><span class="p">,</span> 
                                        <span class="n">delta_delay</span><span class="o">=</span><span class="n">delta_delay</span><span class="p">,</span> 
                                        <span class="n">delta_assessment</span><span class="o">=</span><span class="n">delta_assessment</span><span class="p">,</span>
                                        <span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="n">performance_metrics_list_grid</span><span class="p">,</span>
                                        <span class="n">performance_metrics_list</span><span class="o">=</span><span class="n">performance_metrics_list</span><span class="p">,</span>
                                        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">execution_time_dt</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start_time</span>

<span class="c1"># Select parameter of interest (max_depth)</span>
<span class="n">parameters_dict</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters&#39;</span><span class="p">])</span>
<span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters summary&#39;</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="n">parameters_dict</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;clf__max_depth&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">))]</span>

<span class="c1"># Rename to performances_df_dt for model performance comparison at the end of this notebook</span>
<span class="n">performances_df_dt</span><span class="o">=</span><span class="n">performances_df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary_performances_dt</span><span class="o">=</span><span class="n">get_summary_performances</span><span class="p">(</span><span class="n">performances_df_dt</span><span class="p">,</span> <span class="n">parameter_column_name</span><span class="o">=</span><span class="s2">&quot;Parameters summary&quot;</span><span class="p">)</span>
<span class="n">summary_performances_dt</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AUC ROC</th>
      <th>Average precision</th>
      <th>Card Precision@100</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Best estimated parameters</th>
      <td>5</td>
      <td>5</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Validation performance</th>
      <td>0.804+/-0.02</td>
      <td>0.546+/-0.04</td>
      <td>0.268+/-0.01</td>
    </tr>
    <tr>
      <th>Test performance</th>
      <td>0.81+/-0.01</td>
      <td>0.6+/-0.02</td>
      <td>0.284+/-0.0</td>
    </tr>
    <tr>
      <th>Optimal parameter(s)</th>
      <td>5</td>
      <td>5</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Optimal test performance</th>
      <td>0.81+/-0.01</td>
      <td>0.6+/-0.02</td>
      <td>0.284+/-0.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>This baseline will be used at the end of the notebook to assess the benefits of different resampling techniques.</p>
</div>
<div class="section" id="prequential-validation-with-resampling">
<h3><span class="section-number">3.2.2. </span>Prequential validation with resampling<a class="headerlink" href="#prequential-validation-with-resampling" title="Permalink to this headline">¶</a></h3>
<p>The addition of resampling to the prequential validation simply consists in extending the pipeline defined in <a class="reference internal" href="../Chapter_5_ModelValidationAndSelection/ValidationStrategies.html#sklearn-validation-pipeline"><span class="std std-ref">Chapter 5, Validation Strategies</span></a> with the sampler objects. We add this step at the beginning of the <code class="docutils literal notranslate"><span class="pre">prequential_grid_search</span></code> function and rename it as <code class="docutils literal notranslate"><span class="pre">prequential_grid_search_with_sampler</span></code>. Note that the pipeline is created with the <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> object from the <code class="docutils literal notranslate"><span class="pre">imblearn</span></code> module so that samplers are properly processed.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prequential_grid_search_with_sampler</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span> 
                                         <span class="n">classifier</span><span class="p">,</span> <span class="n">sampler_list</span><span class="p">,</span>
                                         <span class="n">input_features</span><span class="p">,</span> <span class="n">output_feature</span><span class="p">,</span> 
                                         <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> 
                                         <span class="n">start_date_training</span><span class="p">,</span> 
                                         <span class="n">n_folds</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                                         <span class="n">expe_type</span><span class="o">=</span><span class="s1">&#39;Test&#39;</span><span class="p">,</span>
                                         <span class="n">delta_train</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> 
                                         <span class="n">delta_delay</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> 
                                         <span class="n">delta_assessment</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
                                         <span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">],</span>
                                         <span class="n">performance_metrics_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">],</span>
                                         <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
    
    <span class="n">estimators</span> <span class="o">=</span> <span class="n">sampler_list</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">estimators</span><span class="o">.</span><span class="n">extend</span><span class="p">([(</span><span class="s1">&#39;clf&#39;</span><span class="p">,</span> <span class="n">classifier</span><span class="p">)])</span>
    
    <span class="n">pipe</span> <span class="o">=</span> <span class="n">imblearn</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">estimators</span><span class="p">)</span>
    
    <span class="n">prequential_split_indices</span> <span class="o">=</span> <span class="n">prequentialSplit</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span>
                                                 <span class="n">start_date_training</span><span class="o">=</span><span class="n">start_date_training</span><span class="p">,</span> 
                                                 <span class="n">n_folds</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span> 
                                                 <span class="n">delta_train</span><span class="o">=</span><span class="n">delta_train</span><span class="p">,</span> 
                                                 <span class="n">delta_delay</span><span class="o">=</span><span class="n">delta_delay</span><span class="p">,</span> 
                                                 <span class="n">delta_assessment</span><span class="o">=</span><span class="n">delta_assessment</span><span class="p">)</span>
    
    <span class="n">grid_search</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">model_selection</span><span class="o">.</span><span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">prequential_split_indices</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">)</span>
    
    <span class="n">X</span> <span class="o">=</span> <span class="n">transactions_df</span><span class="p">[</span><span class="n">input_features</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">transactions_df</span><span class="p">[</span><span class="n">output_feature</span><span class="p">]</span>

    <span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    
    <span class="n">performances_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">performance_metrics_list_grid</span><span class="p">)):</span>
        <span class="n">performances_df</span><span class="p">[</span><span class="n">performance_metrics_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="s1">&#39; &#39;</span><span class="o">+</span><span class="n">expe_type</span><span class="p">]</span><span class="o">=</span><span class="n">grid_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_&#39;</span><span class="o">+</span><span class="n">performance_metrics_list_grid</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
        <span class="n">performances_df</span><span class="p">[</span><span class="n">performance_metrics_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="s1">&#39; &#39;</span><span class="o">+</span><span class="n">expe_type</span><span class="o">+</span><span class="s1">&#39; Std&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">grid_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;std_test_&#39;</span><span class="o">+</span><span class="n">performance_metrics_list_grid</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>

    <span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]</span>
    <span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Execution time&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_fit_time&#39;</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">performances_df</span>
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">model_selection_wrapper</span></code> function is also modified into a <code class="docutils literal notranslate"><span class="pre">model_selection_wrapper_with_sampler</span></code> function, which calls the <code class="docutils literal notranslate"><span class="pre">prequential_grid_search_with_sampler</span></code> function for prequential grid search.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">model_selection_wrapper_with_sampler</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span> 
                                         <span class="n">classifier</span><span class="p">,</span> 
                                         <span class="n">sampler_list</span><span class="p">,</span>
                                         <span class="n">input_features</span><span class="p">,</span> <span class="n">output_feature</span><span class="p">,</span>
                                         <span class="n">parameters</span><span class="p">,</span> 
                                         <span class="n">scoring</span><span class="p">,</span> 
                                         <span class="n">start_date_training_for_valid</span><span class="p">,</span>
                                         <span class="n">start_date_training_for_test</span><span class="p">,</span>
                                         <span class="n">n_folds</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                                         <span class="n">delta_train</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> 
                                         <span class="n">delta_delay</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> 
                                         <span class="n">delta_assessment</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
                                         <span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">],</span>
                                         <span class="n">performance_metrics_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">],</span>
                                         <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>

    <span class="c1"># Get performances on the validation set using prequential validation</span>
    <span class="n">performances_df_validation</span> <span class="o">=</span> <span class="n">prequential_grid_search_with_sampler</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> <span class="n">sampler_list</span><span class="p">,</span>
                            <span class="n">input_features</span><span class="p">,</span> <span class="n">output_feature</span><span class="p">,</span>
                            <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> 
                            <span class="n">start_date_training</span><span class="o">=</span><span class="n">start_date_training_for_valid</span><span class="p">,</span>
                            <span class="n">n_folds</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span>
                            <span class="n">expe_type</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">,</span>
                            <span class="n">delta_train</span><span class="o">=</span><span class="n">delta_train</span><span class="p">,</span> 
                            <span class="n">delta_delay</span><span class="o">=</span><span class="n">delta_delay</span><span class="p">,</span> 
                            <span class="n">delta_assessment</span><span class="o">=</span><span class="n">delta_assessment</span><span class="p">,</span>
                            <span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="n">performance_metrics_list_grid</span><span class="p">,</span>
                            <span class="n">performance_metrics_list</span><span class="o">=</span><span class="n">performance_metrics_list</span><span class="p">,</span>
                            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">)</span>
    
    <span class="c1"># Get performances on the test set using prequential validation</span>
    <span class="n">performances_df_test</span> <span class="o">=</span> <span class="n">prequential_grid_search_with_sampler</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> <span class="n">sampler_list</span><span class="p">,</span>
                            <span class="n">input_features</span><span class="p">,</span> <span class="n">output_feature</span><span class="p">,</span>
                            <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> 
                            <span class="n">start_date_training</span><span class="o">=</span><span class="n">start_date_training_for_test</span><span class="p">,</span>
                            <span class="n">n_folds</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span>
                            <span class="n">expe_type</span><span class="o">=</span><span class="s1">&#39;Test&#39;</span><span class="p">,</span>
                            <span class="n">delta_train</span><span class="o">=</span><span class="n">delta_train</span><span class="p">,</span> 
                            <span class="n">delta_delay</span><span class="o">=</span><span class="n">delta_delay</span><span class="p">,</span> 
                            <span class="n">delta_assessment</span><span class="o">=</span><span class="n">delta_assessment</span><span class="p">,</span>
                            <span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="n">performance_metrics_list_grid</span><span class="p">,</span>
                            <span class="n">performance_metrics_list</span><span class="o">=</span><span class="n">performance_metrics_list</span><span class="p">,</span>
                            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">)</span>
    
    <span class="c1"># Bind the two resulting DataFrames</span>
    <span class="n">performances_df_validation</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Parameters&#39;</span><span class="p">,</span><span class="s1">&#39;Execution time&#39;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">performances_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">performances_df_test</span><span class="p">,</span><span class="n">performances_df_validation</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># And return as a single DataFrame</span>
    <span class="k">return</span> <span class="n">performances_df</span>
</pre></div>
</div>
</div>
</div>
<p>Model selection with resampling can now be performed by calling the <code class="docutils literal notranslate"><span class="pre">model_selection_wrapper_with_sampler</span></code> function, following the same methodology as in <a class="reference internal" href="../Chapter_5_ModelValidationAndSelection/ModelSelection.html#model-selection"><span class="std std-ref">Chapter 5</span></a>.</p>
</div>
<div class="section" id="resampling-strategies-transaction-data-oversampling">
<span id="id33"></span><h3><span class="section-number">3.2.3. </span>Oversampling<a class="headerlink" href="#resampling-strategies-transaction-data-oversampling" title="Permalink to this headline">¶</a></h3>
<p>Let us illustrate its use with SMOTE oversampling. We create a <code class="docutils literal notranslate"><span class="pre">SMOTE</span></code> object and store it in a <code class="docutils literal notranslate"><span class="pre">sampler_list</span></code> list. The list is passed as an argument to the <code class="docutils literal notranslate"><span class="pre">model_selection_wrapper_with_sampler</span></code> function. Additionally, the <code class="docutils literal notranslate"><span class="pre">sampling_strategy</span></code> parameter to the <code class="docutils literal notranslate"><span class="pre">SMOTE</span></code> object (imbalance ratio) is parametrized to take values in the set <span class="math notranslate nohighlight">\([0.01, 0.05, 0.1, 0.5, 1]\)</span> for the model selection procedure.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define classifier</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">()</span>

<span class="c1"># Define sampling strategy</span>
<span class="n">sampler_list</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;sampler&#39;</span><span class="p">,</span> <span class="n">imblearn</span><span class="o">.</span><span class="n">over_sampling</span><span class="o">.</span><span class="n">SMOTE</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">))]</span>

<span class="c1"># Set of parameters for which to assess model performances</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;clf__max_depth&#39;</span><span class="p">:[</span><span class="mi">5</span><span class="p">],</span> <span class="s1">&#39;clf__random_state&#39;</span><span class="p">:[</span><span class="mi">0</span><span class="p">],</span>
              <span class="s1">&#39;sampler__sampling_strategy&#39;</span><span class="p">:[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;sampler__random_state&#39;</span><span class="p">:[</span><span class="mi">0</span><span class="p">]}</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="c1"># Fit models and assess performances for all parameters</span>
<span class="n">performances_df</span><span class="o">=</span><span class="n">model_selection_wrapper_with_sampler</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> <span class="n">sampler_list</span><span class="p">,</span> 
                                                     <span class="n">input_features</span><span class="p">,</span> <span class="n">output_feature</span><span class="p">,</span>
                                                     <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> 
                                                     <span class="n">start_date_training_for_valid</span><span class="p">,</span>
                                                     <span class="n">start_date_training_for_test</span><span class="p">,</span>
                                                     <span class="n">n_folds</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span>
                                                     <span class="n">delta_train</span><span class="o">=</span><span class="n">delta_train</span><span class="p">,</span> 
                                                     <span class="n">delta_delay</span><span class="o">=</span><span class="n">delta_delay</span><span class="p">,</span> 
                                                     <span class="n">delta_assessment</span><span class="o">=</span><span class="n">delta_assessment</span><span class="p">,</span>
                                                     <span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="n">performance_metrics_list_grid</span><span class="p">,</span>
                                                     <span class="n">performance_metrics_list</span><span class="o">=</span><span class="n">performance_metrics_list</span><span class="p">,</span>
                                                     <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">execution_time_dt_SMOTE</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start_time</span>
</pre></div>
</div>
</div>
</div>
<p>We then retrieve the performances for each of the tested imbalance ratios (<code class="docutils literal notranslate"><span class="pre">sampling_strategy</span></code> value) and store the results in a <code class="docutils literal notranslate"><span class="pre">performances_df_SMOTE</span></code> DataFrame.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Select parameter of interest (sampling_strategy)</span>
<span class="n">parameters_dict</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters&#39;</span><span class="p">])</span>
<span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters summary&#39;</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="n">parameters_dict</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;sampler__sampling_strategy&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">))]</span>

<span class="c1"># Rename to performances_df_SMOTE for model performance comparison at the end of this notebook</span>
<span class="n">performances_df_SMOTE</span> <span class="o">=</span> <span class="n">performances_df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">performances_df_SMOTE</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AUC ROC Test</th>
      <th>AUC ROC Test Std</th>
      <th>Average precision Test</th>
      <th>Average precision Test Std</th>
      <th>Card Precision@100 Test</th>
      <th>Card Precision@100 Test Std</th>
      <th>Parameters</th>
      <th>Execution time</th>
      <th>AUC ROC Validation</th>
      <th>AUC ROC Validation Std</th>
      <th>Average precision Validation</th>
      <th>Average precision Validation Std</th>
      <th>Card Precision@100 Validation</th>
      <th>Card Precision@100 Validation Std</th>
      <th>Parameters summary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.805165</td>
      <td>0.005955</td>
      <td>0.587136</td>
      <td>0.010773</td>
      <td>0.282143</td>
      <td>0.007389</td>
      <td>{'clf__max_depth': 5, 'clf__random_state': 0, ...</td>
      <td>0.559659</td>
      <td>0.803468</td>
      <td>0.014269</td>
      <td>0.554155</td>
      <td>0.032957</td>
      <td>0.267500</td>
      <td>0.014120</td>
      <td>0.01</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.823732</td>
      <td>0.006235</td>
      <td>0.572835</td>
      <td>0.024824</td>
      <td>0.285357</td>
      <td>0.012753</td>
      <td>{'clf__max_depth': 5, 'clf__random_state': 0, ...</td>
      <td>0.542496</td>
      <td>0.809590</td>
      <td>0.018765</td>
      <td>0.558479</td>
      <td>0.027820</td>
      <td>0.271429</td>
      <td>0.010785</td>
      <td>0.05</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.827219</td>
      <td>0.010190</td>
      <td>0.544275</td>
      <td>0.037686</td>
      <td>0.290357</td>
      <td>0.010070</td>
      <td>{'clf__max_depth': 5, 'clf__random_state': 0, ...</td>
      <td>0.569432</td>
      <td>0.807543</td>
      <td>0.016324</td>
      <td>0.537672</td>
      <td>0.040918</td>
      <td>0.268214</td>
      <td>0.013224</td>
      <td>0.10</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.842985</td>
      <td>0.018418</td>
      <td>0.558118</td>
      <td>0.033607</td>
      <td>0.289286</td>
      <td>0.015860</td>
      <td>{'clf__max_depth': 5, 'clf__random_state': 0, ...</td>
      <td>0.829486</td>
      <td>0.849501</td>
      <td>0.015830</td>
      <td>0.495635</td>
      <td>0.052593</td>
      <td>0.279286</td>
      <td>0.018028</td>
      <td>0.50</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.845270</td>
      <td>0.008136</td>
      <td>0.545954</td>
      <td>0.031952</td>
      <td>0.294643</td>
      <td>0.011401</td>
      <td>{'clf__max_depth': 5, 'clf__random_state': 0, ...</td>
      <td>1.091997</td>
      <td>0.857367</td>
      <td>0.012183</td>
      <td>0.493752</td>
      <td>0.049094</td>
      <td>0.278571</td>
      <td>0.014463</td>
      <td>1.00</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let us summarize the performances to highlight the optimal imbalance ratios.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary_performances_SMOTE</span> <span class="o">=</span> <span class="n">get_summary_performances</span><span class="p">(</span><span class="n">performances_df_SMOTE</span><span class="p">,</span> <span class="n">parameter_column_name</span><span class="o">=</span><span class="s2">&quot;Parameters summary&quot;</span><span class="p">)</span>
<span class="n">summary_performances_SMOTE</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AUC ROC</th>
      <th>Average precision</th>
      <th>Card Precision@100</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Best estimated parameters</th>
      <td>1.0</td>
      <td>0.05</td>
      <td>0.5</td>
    </tr>
    <tr>
      <th>Validation performance</th>
      <td>0.857+/-0.01</td>
      <td>0.558+/-0.03</td>
      <td>0.279+/-0.02</td>
    </tr>
    <tr>
      <th>Test performance</th>
      <td>0.845+/-0.01</td>
      <td>0.573+/-0.02</td>
      <td>0.289+/-0.02</td>
    </tr>
    <tr>
      <th>Optimal parameter(s)</th>
      <td>1.0</td>
      <td>0.01</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Optimal test performance</th>
      <td>0.845+/-0.01</td>
      <td>0.587+/-0.01</td>
      <td>0.295+/-0.01</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We note conflicting results, as the optimal imbalance ratio depends on the performance metric. For better visualization, let us plot the performances as a function of the imbalance ratio for the three performance metrics.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">get_performances_plots</span><span class="p">(</span><span class="n">performances_df_SMOTE</span><span class="p">,</span> 
                       <span class="n">performance_metrics_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">,</span> <span class="s1">&#39;Average precision&#39;</span><span class="p">,</span> <span class="s1">&#39;Card Precision@100&#39;</span><span class="p">],</span> 
                       <span class="n">expe_type_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Test&#39;</span><span class="p">,</span><span class="s1">&#39;Validation&#39;</span><span class="p">],</span> <span class="n">expe_type_color_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;#008000&#39;</span><span class="p">,</span><span class="s1">&#39;#FF0000&#39;</span><span class="p">],</span>
                       <span class="n">parameter_name</span><span class="o">=</span><span class="s2">&quot;Imbalance ratio&quot;</span><span class="p">,</span>
                       <span class="n">summary_performances</span><span class="o">=</span><span class="n">summary_performances_SMOTE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Resampling_86_0.png" src="../_images/Resampling_86_0.png" />
</div>
</div>
<p>The performances tend to increase with the imbalance ratio for AUC ROC and CP&#64;100. The opposite is however observed for Average Precision. The creation of synthetic samples with SMOTE is therefore beneficial to AUC ROC and CP&#64;100, but detrimental to the Average Precision.</p>
</div>
<div class="section" id="resampling-strategies-transaction-data-rus">
<span id="id34"></span><h3><span class="section-number">3.2.4. </span>Undersampling<a class="headerlink" href="#resampling-strategies-transaction-data-rus" title="Permalink to this headline">¶</a></h3>
<p>Let us follow the same methodology using random undersampling. The <code class="docutils literal notranslate"><span class="pre">RandomUnderSampler</span></code> object is used, and models are assessed for imbalance ratios taking values in the set <span class="math notranslate nohighlight">\([0.01, 0.05, 0.1, 0.5, 1]\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define classifier</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">()</span>

<span class="c1"># Define sampling strategy</span>
<span class="n">sampler_list</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;sampler&#39;</span><span class="p">,</span> <span class="n">imblearn</span><span class="o">.</span><span class="n">under_sampling</span><span class="o">.</span><span class="n">RandomUnderSampler</span><span class="p">())]</span>

<span class="c1"># Set of parameters for which to assess model performances</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;clf__max_depth&#39;</span><span class="p">:[</span><span class="mi">5</span><span class="p">],</span> <span class="s1">&#39;clf__random_state&#39;</span><span class="p">:[</span><span class="mi">0</span><span class="p">],</span>
              <span class="s1">&#39;sampler__sampling_strategy&#39;</span><span class="p">:[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;sampler__random_state&#39;</span><span class="p">:[</span><span class="mi">0</span><span class="p">]}</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="c1"># Fit models and assess performances for all parameters</span>
<span class="n">performances_df</span><span class="o">=</span><span class="n">model_selection_wrapper_with_sampler</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> <span class="n">sampler_list</span><span class="p">,</span> 
                                                     <span class="n">input_features</span><span class="p">,</span> <span class="n">output_feature</span><span class="p">,</span>
                                                     <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> 
                                                     <span class="n">start_date_training_for_valid</span><span class="p">,</span>
                                                     <span class="n">start_date_training_for_test</span><span class="p">,</span>
                                                     <span class="n">n_folds</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span>
                                                     <span class="n">delta_train</span><span class="o">=</span><span class="n">delta_train</span><span class="p">,</span> 
                                                     <span class="n">delta_delay</span><span class="o">=</span><span class="n">delta_delay</span><span class="p">,</span> 
                                                     <span class="n">delta_assessment</span><span class="o">=</span><span class="n">delta_assessment</span><span class="p">,</span>
                                                     <span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="n">performance_metrics_list_grid</span><span class="p">,</span>
                                                     <span class="n">performance_metrics_list</span><span class="o">=</span><span class="n">performance_metrics_list</span><span class="p">,</span>
                                                     <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">execution_time_dt_RUS</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start_time</span>

<span class="c1"># Select parameter of interest (sampling_strategy)</span>
<span class="n">parameters_dict</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters&#39;</span><span class="p">])</span>
<span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters summary&#39;</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="n">parameters_dict</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;sampler__sampling_strategy&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">))]</span>

<span class="c1"># Rename to performances_df_RUS for model performance comparison at the end of this notebook</span>
<span class="n">performances_df_RUS</span> <span class="o">=</span> <span class="n">performances_df</span>
</pre></div>
</div>
</div>
</div>
<p>Let us summarize the performances to highlight the optimal imbalance ratios, and plot the performances as a function of the imbalance ratio.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary_performances_RUS</span><span class="o">=</span><span class="n">get_summary_performances</span><span class="p">(</span><span class="n">performances_df_RUS</span><span class="p">,</span> <span class="n">parameter_column_name</span><span class="o">=</span><span class="s2">&quot;Parameters summary&quot;</span><span class="p">)</span>
<span class="n">summary_performances_RUS</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AUC ROC</th>
      <th>Average precision</th>
      <th>Card Precision@100</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Best estimated parameters</th>
      <td>1.0</td>
      <td>0.01</td>
      <td>0.1</td>
    </tr>
    <tr>
      <th>Validation performance</th>
      <td>0.845+/-0.01</td>
      <td>0.535+/-0.04</td>
      <td>0.269+/-0.01</td>
    </tr>
    <tr>
      <th>Test performance</th>
      <td>0.83+/-0.01</td>
      <td>0.594+/-0.02</td>
      <td>0.277+/-0.01</td>
    </tr>
    <tr>
      <th>Optimal parameter(s)</th>
      <td>1.0</td>
      <td>0.01</td>
      <td>0.5</td>
    </tr>
    <tr>
      <th>Optimal test performance</th>
      <td>0.83+/-0.01</td>
      <td>0.594+/-0.02</td>
      <td>0.292+/-0.01</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">get_performances_plots</span><span class="p">(</span><span class="n">performances_df_RUS</span><span class="p">,</span> 
                       <span class="n">performance_metrics_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">,</span> <span class="s1">&#39;Average precision&#39;</span><span class="p">,</span> <span class="s1">&#39;Card Precision@100&#39;</span><span class="p">],</span> 
                       <span class="n">expe_type_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Test&#39;</span><span class="p">,</span><span class="s1">&#39;Validation&#39;</span><span class="p">],</span> <span class="n">expe_type_color_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;#008000&#39;</span><span class="p">,</span><span class="s1">&#39;#FF0000&#39;</span><span class="p">],</span>
                       <span class="n">parameter_name</span><span class="o">=</span><span class="s2">&quot;Imbalance ratio&quot;</span><span class="p">,</span>
                       <span class="n">summary_performances</span><span class="o">=</span><span class="n">summary_performances_RUS</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Resampling_92_0.png" src="../_images/Resampling_92_0.png" />
</div>
</div>
<p>As with oversampling, rebalancing the dataset leads to an increase in performance in terms of AUC ROC, but to a strong decrease of performance in terms of AP. The results in terms of CP&#64;100 follow an intermediate trend: The performance first slightly increases with the imbalance ratio, and then decreases with more aggressive undersampling.</p>
</div>
<div class="section" id="combining">
<span id="resampling-strategies-transaction-data-combining"></span><h3><span class="section-number">3.2.5. </span>Combining<a class="headerlink" href="#combining" title="Permalink to this headline">¶</a></h3>
<p>We finally illustrate the combination of oversampling and undersampling with SMOTE and random undersampling. A <code class="docutils literal notranslate"><span class="pre">SMOTE</span></code> and <code class="docutils literal notranslate"><span class="pre">RandomUnderSampler</span></code> objects are instantiated and stored in the <code class="docutils literal notranslate"><span class="pre">sampler_list</span></code> list. We parametrize the <code class="docutils literal notranslate"><span class="pre">SMOTE</span></code> sampler with a target imbalance ratio of <span class="math notranslate nohighlight">\(0.1\)</span>, and the <code class="docutils literal notranslate"><span class="pre">RandomUnderSampler</span></code> to take values in the set <span class="math notranslate nohighlight">\([0.1, 0.5, 1]\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define classifier</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">()</span>

<span class="c1"># Define sampling strategy</span>
<span class="n">sampler_list</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;sampler1&#39;</span><span class="p">,</span> <span class="n">imblearn</span><span class="o">.</span><span class="n">over_sampling</span><span class="o">.</span><span class="n">SMOTE</span><span class="p">()),</span>
                <span class="p">(</span><span class="s1">&#39;sampler2&#39;</span><span class="p">,</span> <span class="n">imblearn</span><span class="o">.</span><span class="n">under_sampling</span><span class="o">.</span><span class="n">RandomUnderSampler</span><span class="p">())</span>
               <span class="p">]</span>

<span class="c1"># Set of parameters for which to assess model performances</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;clf__max_depth&#39;</span><span class="p">:[</span><span class="mi">5</span><span class="p">],</span> <span class="s1">&#39;clf__random_state&#39;</span><span class="p">:[</span><span class="mi">0</span><span class="p">],</span>
              <span class="s1">&#39;sampler1__sampling_strategy&#39;</span><span class="p">:[</span><span class="mf">0.1</span><span class="p">],</span> 
              <span class="s1">&#39;sampler2__sampling_strategy&#39;</span><span class="p">:[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
              <span class="s1">&#39;sampler1__random_state&#39;</span><span class="p">:[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;sampler2__random_state&#39;</span><span class="p">:[</span><span class="mi">0</span><span class="p">]}</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="c1"># Fit models and assess performances for all parameters</span>
<span class="n">performances_df</span> <span class="o">=</span> <span class="n">model_selection_wrapper_with_sampler</span><span class="p">(</span><span class="n">transactions_df</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> <span class="n">sampler_list</span><span class="p">,</span> 
                                                     <span class="n">input_features</span><span class="p">,</span> <span class="n">output_feature</span><span class="p">,</span>
                                                     <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> 
                                                     <span class="n">start_date_training_for_valid</span><span class="p">,</span>
                                                     <span class="n">start_date_training_for_test</span><span class="p">,</span>
                                                     <span class="n">n_folds</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span>
                                                     <span class="n">delta_train</span><span class="o">=</span><span class="n">delta_train</span><span class="p">,</span> 
                                                     <span class="n">delta_delay</span><span class="o">=</span><span class="n">delta_delay</span><span class="p">,</span> 
                                                     <span class="n">delta_assessment</span><span class="o">=</span><span class="n">delta_assessment</span><span class="p">,</span>
                                                     <span class="n">performance_metrics_list_grid</span><span class="o">=</span><span class="n">performance_metrics_list_grid</span><span class="p">,</span>
                                                     <span class="n">performance_metrics_list</span><span class="o">=</span><span class="n">performance_metrics_list</span><span class="p">,</span>
                                                     <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">execution_time_dt_combined</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start_time</span>

<span class="c1"># Select parameter of interest (max_depth)</span>
<span class="n">parameters_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters&#39;</span><span class="p">])</span>
<span class="n">performances_df</span><span class="p">[</span><span class="s1">&#39;Parameters summary&#39;</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="n">parameters_dict</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;sampler2__sampling_strategy&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">))]</span>

<span class="c1"># Rename to performances_df_combined for model performance comparison at the end of this notebook</span>
<span class="n">performances_df_combined</span> <span class="o">=</span> <span class="n">performances_df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">performances_df_combined</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AUC ROC Test</th>
      <th>AUC ROC Test Std</th>
      <th>Average precision Test</th>
      <th>Average precision Test Std</th>
      <th>Card Precision@100 Test</th>
      <th>Card Precision@100 Test Std</th>
      <th>Parameters</th>
      <th>Execution time</th>
      <th>AUC ROC Validation</th>
      <th>AUC ROC Validation Std</th>
      <th>Average precision Validation</th>
      <th>Average precision Validation Std</th>
      <th>Card Precision@100 Validation</th>
      <th>Card Precision@100 Validation Std</th>
      <th>Parameters summary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.827219</td>
      <td>0.010190</td>
      <td>0.544275</td>
      <td>0.037686</td>
      <td>0.290357</td>
      <td>0.010070</td>
      <td>{'clf__max_depth': 5, 'clf__random_state': 0, ...</td>
      <td>0.608622</td>
      <td>0.807543</td>
      <td>0.016324</td>
      <td>0.537672</td>
      <td>0.040918</td>
      <td>0.268214</td>
      <td>0.013224</td>
      <td>0.1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.848464</td>
      <td>0.008701</td>
      <td>0.471467</td>
      <td>0.010144</td>
      <td>0.299643</td>
      <td>0.011968</td>
      <td>{'clf__max_depth': 5, 'clf__random_state': 0, ...</td>
      <td>0.395396</td>
      <td>0.841237</td>
      <td>0.015297</td>
      <td>0.428576</td>
      <td>0.050091</td>
      <td>0.279286</td>
      <td>0.010903</td>
      <td>0.5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.847110</td>
      <td>0.010754</td>
      <td>0.385133</td>
      <td>0.064916</td>
      <td>0.287857</td>
      <td>0.018364</td>
      <td>{'clf__max_depth': 5, 'clf__random_state': 0, ...</td>
      <td>0.384152</td>
      <td>0.856399</td>
      <td>0.012189</td>
      <td>0.342964</td>
      <td>0.020342</td>
      <td>0.280357</td>
      <td>0.017420</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let us summarize the performances to highlight the optimal imbalance ratios, and plot the performances as a function of the imbalance ratio.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary_performances_combined</span> <span class="o">=</span> <span class="n">get_summary_performances</span><span class="p">(</span><span class="n">performances_df</span><span class="o">=</span><span class="n">performances_df_combined</span><span class="p">,</span> 
                                                         <span class="n">parameter_column_name</span><span class="o">=</span><span class="s2">&quot;Parameters summary&quot;</span><span class="p">)</span>
<span class="n">summary_performances_combined</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AUC ROC</th>
      <th>Average precision</th>
      <th>Card Precision@100</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Best estimated parameters</th>
      <td>1.0</td>
      <td>0.1</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Validation performance</th>
      <td>0.856+/-0.01</td>
      <td>0.538+/-0.04</td>
      <td>0.28+/-0.02</td>
    </tr>
    <tr>
      <th>Test performance</th>
      <td>0.847+/-0.01</td>
      <td>0.544+/-0.04</td>
      <td>0.288+/-0.02</td>
    </tr>
    <tr>
      <th>Optimal parameter(s)</th>
      <td>0.5</td>
      <td>0.1</td>
      <td>0.5</td>
    </tr>
    <tr>
      <th>Optimal test performance</th>
      <td>0.848+/-0.01</td>
      <td>0.544+/-0.04</td>
      <td>0.3+/-0.01</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">get_performances_plots</span><span class="p">(</span><span class="n">performances_df_combined</span><span class="p">,</span> 
                       <span class="n">performance_metrics_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AUC ROC&#39;</span><span class="p">,</span> <span class="s1">&#39;Average precision&#39;</span><span class="p">,</span> <span class="s1">&#39;Card Precision@100&#39;</span><span class="p">],</span> 
                       <span class="n">expe_type_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Test&#39;</span><span class="p">,</span><span class="s1">&#39;Validation&#39;</span><span class="p">],</span> <span class="n">expe_type_color_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;#008000&#39;</span><span class="p">,</span><span class="s1">&#39;#FF0000&#39;</span><span class="p">],</span>
                       <span class="n">parameter_name</span><span class="o">=</span><span class="s2">&quot;Imbalance ratio&quot;</span><span class="p">,</span>
                       <span class="n">summary_performances</span><span class="o">=</span><span class="n">summary_performances_combined</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Resampling_100_0.png" src="../_images/Resampling_100_0.png" />
</div>
</div>
<p>The results follow the same trends as with oversampling and undersampling: Rebalancing improves the performances in terms of AUC ROC, but decreases the performances in terms of Average Precision. The impact of rebalancing on CP&#64;100 is mitigated.</p>
<p>Let us finally compare the test performances obtained with the oversampling, undersampling, and combined resampling, and compare them to the baseline classifier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary_test_performances</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">summary_performances_dt</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">2</span><span class="p">,:],</span>
                                       <span class="n">summary_performances_SMOTE</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">2</span><span class="p">,:],</span>
                                       <span class="n">summary_performances_RUS</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">2</span><span class="p">,:],</span>
                                       <span class="n">summary_performances_combined</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">2</span><span class="p">,:],</span>
                                      <span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">summary_test_performances</span><span class="o">.</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Baseline&#39;</span><span class="p">,</span> <span class="s1">&#39;SMOTE&#39;</span><span class="p">,</span> <span class="s1">&#39;RUS&#39;</span><span class="p">,</span> <span class="s1">&#39;Combined&#39;</span><span class="p">]</span>
<span class="n">summary_test_performances</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Baseline</th>
      <th>SMOTE</th>
      <th>RUS</th>
      <th>Combined</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>AUC ROC</th>
      <td>0.81+/-0.01</td>
      <td>0.845+/-0.01</td>
      <td>0.83+/-0.01</td>
      <td>0.847+/-0.01</td>
    </tr>
    <tr>
      <th>Average precision</th>
      <td>0.6+/-0.02</td>
      <td>0.573+/-0.02</td>
      <td>0.594+/-0.02</td>
      <td>0.544+/-0.04</td>
    </tr>
    <tr>
      <th>Card Precision@100</th>
      <td>0.284+/-0.0</td>
      <td>0.289+/-0.02</td>
      <td>0.277+/-0.01</td>
      <td>0.288+/-0.02</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Compared to the baseline classifier, all resampling techniques managed to improve the performances in terms of AUC ROC. All of them however led to a decrease in Average Precision. Slight improvements in terms of CP&#64;100 could be achieved with SMOTE and the combined approach, but not with undersampling.</p>
</div>
</div>
<div class="section" id="summary">
<h2><span class="section-number">3.3. </span>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>The experiments carried out in this section illustrated that the benefits of resampling techniques depend on the performance metric that is used. While resampling can generally be beneficial to AUC ROC, we observed that they led in almost all cases to a decrease of performances in terms of Average Precision. It is worth noting that the results are coherent with those obtained using cost-sensitive techniques in <a class="reference internal" href="CostSensitive.html#cost-sensitive-learning"><span class="std std-ref">the previous section</span></a>.</p>
</div>
<div class="section" id="saving-of-results">
<h2><span class="section-number">3.4. </span>Saving of results<a class="headerlink" href="#saving-of-results" title="Permalink to this headline">¶</a></h2>
<p>Let us finally save the performance results and execution times.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">performances_df_dictionary</span><span class="o">=</span><span class="p">{</span>
    <span class="s2">&quot;SMOTE&quot;</span><span class="p">:</span> <span class="n">performances_df_SMOTE</span><span class="p">,</span>
    <span class="s2">&quot;RUS&quot;</span><span class="p">:</span> <span class="n">performances_df_RUS</span><span class="p">,</span>
    <span class="s2">&quot;Combined&quot;</span><span class="p">:</span> <span class="n">performances_df_combined</span>
<span class="p">}</span>

<span class="n">execution_times</span><span class="o">=</span><span class="p">[</span><span class="n">execution_time_dt_SMOTE</span><span class="p">,</span>
                 <span class="n">execution_time_dt_RUS</span><span class="p">,</span>
                 <span class="n">execution_time_dt_combined</span><span class="p">,</span>
                <span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">filehandler</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;performances_resampling.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> 
<span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">((</span><span class="n">performances_df_dictionary</span><span class="p">,</span> <span class="n">execution_times</span><span class="p">),</span> <span class="n">filehandler</span><span class="p">)</span>
<span class="n">filehandler</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Chapter_6_ImbalancedLearning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="CostSensitive.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">2. </span>Cost-sensitive learning</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Ensembling.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">4. </span>Ensemble methods</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By <a href="https://mlg.ulb.ac.be/wordpress/">Machine Learning Group (Université Libre de Bruxelles - ULB)</a>.<br/>
        
          <div class="extra_footer">
            <p>
Code released under a <a href="https://www.gnu.org/licenses/gpl-3.0.en.html">GNU GPL v3.0 license</a>. 
Prose and pictures released under a <a href="https://creativecommons.org/licenses/by-sa/4.0/"> CC BY-SA 4.0 license</a>.
</p>

          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>